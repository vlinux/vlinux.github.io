import{_ as d}from"./ValaxyMain.vue_vue_type_style_index_0_lang-41597f62.js";import{_ as h,c as u,w as a,o as p,b as e,d as l,e as s,r as i,f as k,p as _}from"./app-3e08b1b2.js";import"./YunFooter.vue_vue_type_script_setup_true_lang-8ff0d66c.js";import"./YunCard.vue_vue_type_style_index_0_lang-6b4cf038.js";import"./YunPageHeader.vue_vue_type_script_setup_true_lang-5d677271.js";const Ka=JSON.parse('{"title":"Kafka运维笔记","description":"","frontmatter":{"title":"Kafka运维笔记","categories":"DevOps","tags":["Kafka"],"date":"2022-03-11T11:05:00.000Z"},"headers":[{"level":3,"title":"什么是 MQ","slug":"什么是-mq","link":"#什么是-mq","children":[]},{"level":3,"title":"有 Broker 的 MQ","slug":"有-broker-的-mq","link":"#有-broker-的-mq","children":[]},{"level":3,"title":"重 Topic","slug":"重-topic","link":"#重-topic","children":[]},{"level":3,"title":"轻 Topic","slug":"轻-topic","link":"#轻-topic","children":[]},{"level":3,"title":"无 Broker 的 MQ","slug":"无-broker-的-mq","link":"#无-broker-的-mq","children":[]},{"level":2,"title":"1.Kafka的使用场景","slug":"_1-kafka的使用场景","link":"#_1-kafka的使用场景","children":[]},{"level":2,"title":"2.Kafka基本概念","slug":"_2-kafka基本概念","link":"#_2-kafka基本概念","children":[]},{"level":2,"title":"1.安装前的环境准备","slug":"_1-安装前的环境准备","link":"#_1-安装前的环境准备","children":[]},{"level":2,"title":"3.创建主题topic","slug":"_3-创建主题topic","link":"#_3-创建主题topic","children":[]},{"level":2,"title":"4.发送消息","slug":"_4-发送消息","link":"#_4-发送消息","children":[]},{"level":2,"title":"[5.消费消息","slug":"_5-消费消息","link":"#_5-消费消息","children":[{"level":3,"title":"几个注意点：","slug":"几个注意点：","link":"#几个注意点：","children":[]}]},{"level":2,"title":"1.消息的顺序存储","slug":"_1-消息的顺序存储","link":"#_1-消息的顺序存储","children":[]},{"level":2,"title":"[2. 单播消息的实现","slug":"_2-单播消息的实现","link":"#_2-单播消息的实现","children":[]},{"level":2,"title":"3.多播消息的实现","slug":"_3-多播消息的实现","link":"#_3-多播消息的实现","children":[{"level":3,"title":"在一些业务场景中需要让一条消息被多个消费者消费，那么就可以使用多播模式。","slug":"在一些业务场景中需要让一条消息被多个消费者消费，那么就可以使用多播模式。","link":"#在一些业务场景中需要让一条消息被多个消费者消费，那么就可以使用多播模式。","children":[]}]},{"level":2,"title":"4.查看消费组及信息","slug":"_4-查看消费组及信息","link":"#_4-查看消费组及信息","children":[]},{"level":2,"title":"1.主题Topic","slug":"_1-主题topic","link":"#_1-主题topic","children":[]},{"level":2,"title":"2.partition分区","slug":"_2-partition分区","link":"#_2-partition分区","children":[{"level":3,"title":"为一个主题创建多个分区","slug":"为一个主题创建多个分区","link":"#为一个主题创建多个分区","children":[]},{"level":3,"title":"分区的作用：","slug":"分区的作用：","link":"#分区的作用：","children":[]}]},{"level":2,"title":"1.搭建kafka集群， 3 个broker","slug":"_1-搭建kafka集群，-3-个broker","link":"#_1-搭建kafka集群，-3-个broker","children":[]},{"level":2,"title":"2.副本的概念","slug":"_2-副本的概念","link":"#_2-副本的概念","children":[]},{"level":2,"title":"3.broker、主题、分区、副本","slug":"_3-broker、主题、分区、副本","link":"#_3-broker、主题、分区、副本","children":[]},{"level":2,"title":"4.kafka集群消息的发送","slug":"_4-kafka集群消息的发送","link":"#_4-kafka集群消息的发送","children":[]},{"level":2,"title":"5.kafka集群消息的消费","slug":"_5-kafka集群消息的消费","link":"#_5-kafka集群消息的消费","children":[]},{"level":2,"title":"6.关于分区消费组消费者的细节","slug":"_6-关于分区消费组消费者的细节","link":"#_6-关于分区消费组消费者的细节","children":[]},{"level":2,"title":"1.Controller","slug":"_1-controller","link":"#_1-controller","children":[]},{"level":2,"title":"2.Rebalance机制","slug":"_2-rebalance机制","link":"#_2-rebalance机制","children":[]},{"level":2,"title":"3.HW和LEO","slug":"_3-hw和leo","link":"#_3-hw和leo","children":[]},{"level":2,"title":"1.如何防止消息丢失","slug":"_1-如何防止消息丢失","link":"#_1-如何防止消息丢失","children":[]},{"level":2,"title":"2.如何防止消息的重复消费","slug":"_2-如何防止消息的重复消费","link":"#_2-如何防止消息的重复消费","children":[{"level":3,"title":"幂等性如何保证：","slug":"幂等性如何保证：","link":"#幂等性如何保证：","children":[]}]},{"level":2,"title":"3.如何做到顺序消费RocketMQ","slug":"_3-如何做到顺序消费rocketmq","link":"#_3-如何做到顺序消费rocketmq","children":[]},{"level":2,"title":"4.解决消息积压问题","slug":"_4-解决消息积压问题","link":"#_4-解决消息积压问题","children":[]},{"level":2,"title":"5.延迟队列","slug":"_5-延迟队列","link":"#_5-延迟队列","children":[]},{"level":2,"title":"安装Kafka-eagle","slug":"安装kafka-eagle","link":"#安装kafka-eagle","children":[]}],"relativePath":"pages/posts/Kafka运维笔记.md","path":"/Users/vlinux/vlinux/blog/valaxy/vlinux.github.io/pages/posts/Kafka运维笔记.md","lastUpdated":1671090556000}'),o=JSON.parse('{"title":"Kafka运维笔记","description":"","frontmatter":{"title":"Kafka运维笔记","categories":"DevOps","tags":["Kafka"],"date":"2022-03-11T11:05:00.000Z"},"headers":[{"level":3,"title":"什么是 MQ","slug":"什么是-mq","link":"#什么是-mq","children":[]},{"level":3,"title":"有 Broker 的 MQ","slug":"有-broker-的-mq","link":"#有-broker-的-mq","children":[]},{"level":3,"title":"重 Topic","slug":"重-topic","link":"#重-topic","children":[]},{"level":3,"title":"轻 Topic","slug":"轻-topic","link":"#轻-topic","children":[]},{"level":3,"title":"无 Broker 的 MQ","slug":"无-broker-的-mq","link":"#无-broker-的-mq","children":[]},{"level":2,"title":"1.Kafka的使用场景","slug":"_1-kafka的使用场景","link":"#_1-kafka的使用场景","children":[]},{"level":2,"title":"2.Kafka基本概念","slug":"_2-kafka基本概念","link":"#_2-kafka基本概念","children":[]},{"level":2,"title":"1.安装前的环境准备","slug":"_1-安装前的环境准备","link":"#_1-安装前的环境准备","children":[]},{"level":2,"title":"3.创建主题topic","slug":"_3-创建主题topic","link":"#_3-创建主题topic","children":[]},{"level":2,"title":"4.发送消息","slug":"_4-发送消息","link":"#_4-发送消息","children":[]},{"level":2,"title":"[5.消费消息","slug":"_5-消费消息","link":"#_5-消费消息","children":[{"level":3,"title":"几个注意点：","slug":"几个注意点：","link":"#几个注意点：","children":[]}]},{"level":2,"title":"1.消息的顺序存储","slug":"_1-消息的顺序存储","link":"#_1-消息的顺序存储","children":[]},{"level":2,"title":"[2. 单播消息的实现","slug":"_2-单播消息的实现","link":"#_2-单播消息的实现","children":[]},{"level":2,"title":"3.多播消息的实现","slug":"_3-多播消息的实现","link":"#_3-多播消息的实现","children":[{"level":3,"title":"在一些业务场景中需要让一条消息被多个消费者消费，那么就可以使用多播模式。","slug":"在一些业务场景中需要让一条消息被多个消费者消费，那么就可以使用多播模式。","link":"#在一些业务场景中需要让一条消息被多个消费者消费，那么就可以使用多播模式。","children":[]}]},{"level":2,"title":"4.查看消费组及信息","slug":"_4-查看消费组及信息","link":"#_4-查看消费组及信息","children":[]},{"level":2,"title":"1.主题Topic","slug":"_1-主题topic","link":"#_1-主题topic","children":[]},{"level":2,"title":"2.partition分区","slug":"_2-partition分区","link":"#_2-partition分区","children":[{"level":3,"title":"为一个主题创建多个分区","slug":"为一个主题创建多个分区","link":"#为一个主题创建多个分区","children":[]},{"level":3,"title":"分区的作用：","slug":"分区的作用：","link":"#分区的作用：","children":[]}]},{"level":2,"title":"1.搭建kafka集群， 3 个broker","slug":"_1-搭建kafka集群，-3-个broker","link":"#_1-搭建kafka集群，-3-个broker","children":[]},{"level":2,"title":"2.副本的概念","slug":"_2-副本的概念","link":"#_2-副本的概念","children":[]},{"level":2,"title":"3.broker、主题、分区、副本","slug":"_3-broker、主题、分区、副本","link":"#_3-broker、主题、分区、副本","children":[]},{"level":2,"title":"4.kafka集群消息的发送","slug":"_4-kafka集群消息的发送","link":"#_4-kafka集群消息的发送","children":[]},{"level":2,"title":"5.kafka集群消息的消费","slug":"_5-kafka集群消息的消费","link":"#_5-kafka集群消息的消费","children":[]},{"level":2,"title":"6.关于分区消费组消费者的细节","slug":"_6-关于分区消费组消费者的细节","link":"#_6-关于分区消费组消费者的细节","children":[]},{"level":2,"title":"1.Controller","slug":"_1-controller","link":"#_1-controller","children":[]},{"level":2,"title":"2.Rebalance机制","slug":"_2-rebalance机制","link":"#_2-rebalance机制","children":[]},{"level":2,"title":"3.HW和LEO","slug":"_3-hw和leo","link":"#_3-hw和leo","children":[]},{"level":2,"title":"1.如何防止消息丢失","slug":"_1-如何防止消息丢失","link":"#_1-如何防止消息丢失","children":[]},{"level":2,"title":"2.如何防止消息的重复消费","slug":"_2-如何防止消息的重复消费","link":"#_2-如何防止消息的重复消费","children":[{"level":3,"title":"幂等性如何保证：","slug":"幂等性如何保证：","link":"#幂等性如何保证：","children":[]}]},{"level":2,"title":"3.如何做到顺序消费RocketMQ","slug":"_3-如何做到顺序消费rocketmq","link":"#_3-如何做到顺序消费rocketmq","children":[]},{"level":2,"title":"4.解决消息积压问题","slug":"_4-解决消息积压问题","link":"#_4-解决消息积压问题","children":[]},{"level":2,"title":"5.延迟队列","slug":"_5-延迟队列","link":"#_5-延迟队列","children":[]},{"level":2,"title":"安装Kafka-eagle","slug":"安装kafka-eagle","link":"#安装kafka-eagle","children":[]}],"relativePath":"pages/posts/Kafka运维笔记.md","path":"/Users/vlinux/vlinux/blog/valaxy/vlinux.github.io/pages/posts/Kafka运维笔记.md","lastUpdated":1671090556000}'),f={name:"pages/posts/Kafka运维笔记.md",data(){return{data:o,frontmatter:o.frontmatter}},setup(){_("pageData",o)}},g={id:"消息队列的流派",tabindex:"-1"},b={id:"什么是-mq",tabindex:"-1"},m=e("blockquote",null,[e("p",null,"Message Queue（MQ），消息队列中间件。很多人都说：MQ 通过将消息的发送和接收分离来实现应用程序的异步和解偶，这个给人的直觉是——MQ 是异步的，用来解耦的，但是这个只是 MQ 的效果而不是目的。MQ 真正的目的是为了通讯，屏蔽底层复杂的通讯协议，定义了一套应用层的、更加简单的通讯协议。一个分布式系统中两个模块之间通讯要么是HTTP，要么是自己开发的（rpc） TCP，但是这两种协议其实都是原始的协议。HTTP 协议很难实现两端通讯——模块 A 可以调用 B，B 也可以主动调用 A，如果要做到这个两端都要背上WebServer，而且还不支持⻓连接（HTTP 2.0 的库根本找不到）。TCP 就更加原始了，粘包、心跳、私有的协议，想一想头皮就发麻。MQ 所要做的就是在这些协议之上构建一个简单的“协议”——生产者/消费者模型。MQ 带给我的“协议”不是具体的通讯协议，而是更高层次通讯模型。它定义了两个对象——发送数据的叫生产者；接收数据的叫消费者， 提供一个SDK 让我们可以定义自己的生产者和消费者实现消息通讯而无视底层通讯协议")],-1),v={id:"有-broker-的-mq",tabindex:"-1"},A=e("blockquote",null,[e("p",null,"这个流派通常有一台服务器作为 Broker，所有的消息都通过它中转。生产者把消息发送给它就结束自己的任务了，Broker 则把消息主动推送给消费者（或者消费者主动轮询）")],-1),C={id:"重-topic",tabindex:"-1"},y=e("blockquote",null,[e("p",null,"kafka、JMS（ActiveMQ）就属于这个流派，生产者会发送 key 和数据到 Broker，由 Broker比较 key 之后决定给哪个消费者。这种模式是我们最常⻅的模式，是我们对 MQ 最多的印象。在这种模式下一个 topic 往往是一个比较大的概念，甚至一个系统中就可能只有一个topic，topic 某种意义上就是 queue，生产者发送 key 相当于说：“hi，把数据放到 key 的队列中”")],-1),x=e("blockquote",null,[e("p",null,"如上图所示，Broker 定义了三个队列，key1，key2，key3，生产者发送数据的时候会发送key1 和 data，Broker 在推送数据的时候则推送 data（也可能把 key 带上）。")],-1),D=e("blockquote",null,[e("p",null,"虽然架构一样但是 kafka 的性能要比 jms 的性能不知道高到多少倍，所以基本这种类型的MQ 只有 kafka 一种备选方案。如果你需要一条暴力的数据流（在乎性能而非灵活性）那么kafka 是最好的选择")],-1),q={id:"轻-topic",tabindex:"-1"},Q=e("blockquote",null,[e("p",null,"这种的代表是 RabbitMQ（或者说是 AMQP）。生产者发送 key 和数据，消费者定义订阅的队列，Broker 收到数据之后会通过一定的逻辑计算出 key 对应的队列，然后把数据交给队列")],-1),M=e("blockquote",null,[e("p",null,"这种模式下解耦了 key 和 queue，在这种架构中 queue 是非常轻量级的（在 RabbitMQ 中它的上限取决于你的内存），消费者关心的只是自己的 queue；生产者不必关心数据最终给谁只要指定 key 就行了，中间的那层映射在 AMQP 中叫 exchange（交换机）。")],-1),w=e("p",null,"AMQP 中有四种 exchange",-1),K=e("ul",null,[e("li",null,"Direct exchange：key 就等于 queue"),e("li",null,"Fanout exchange：无视 key，给所有的 queue 都来一份"),e("li",null,"Topic exchange：key 可以用“宽字符”模糊匹配 queue"),e("li",null,"Headers exchange：无视 key，通过查看消息的头部元数据来决定发给那个"),e("li",null,"queue（AMQP 头部元数据非常丰富而且可以自定义）")],-1),T=e("p",null,"这种结构的架构给通讯带来了很大的灵活性，我们能想到的通讯方式都可以用这四种exchange 表达出来。如果你需要一个企业数据总线（在乎灵活性）那么 RabbitMQ 绝对的值得一用",-1),B={id:"无-broker-的-mq",tabindex:"-1"},E=e("blockquote",null,[e("p",null,"无 Broker 的 MQ 的代表是 ZeroMQ。该作者非常睿智，他非常敏锐的意识到——MQ 是更高级的 Socket，它是解决通讯问题的。所以 ZeroMQ 被设计成了一个“库”而不是一个中间件，这种实现也可以达到——没有 Broker 的目的")],-1),P=e("blockquote",null,[e("p",null,"节点之间通讯的消息都是发送到彼此的队列中，每个节点都既是生产者又是消费者。ZeroMQ做的事情就是封装出一套类似于 Socket 的 API 可以完成发送数据，读取数据")],-1),H=e("blockquote",null,[e("p",null,"ZeroMQ 其实就是一个跨语言的、重量级的 Actor 模型邮箱库。你可以把自己的程序想象成一个 Actor，ZeroMQ 就是提供邮箱功能的库；ZeroMQ 可以实现同一台机器的 RPC 通讯也可以实现不同机器的 TCP、UDP 通讯，如果你需要一个强大的、灵活、野蛮的通讯能力，别犹豫 ZeroMQ")],-1),z={id:"一、kafka介绍",tabindex:"-1"},$=e("blockquote",null,[e("p",null,"Kafka是最初由Linkedin公司开发，是一个分布式、支持分区的（partition）、多副本的 （replica），基于zookeeper协调的分布式消息系统，它的最大的特性就是可以实时的处理 大量数据以满足各种需求场景：比如基于hadoop的批处理系统、低延迟的实时系统、 Storm/Spark流式处理引擎，web/nginx日志、访问日志，消息服务等等，用scala语言编 写，Linkedin于 2010 年贡献给了Apache基金会并成为顶级开源 项目。")],-1),S={id:"_1-kafka的使用场景",tabindex:"-1"},L=e("blockquote",null,[e("p",null,"日志收集：一个公司可以用Kafka收集各种服务的log，通过kafka以统一接口服务的方式 开放给各种consumer，例如hadoop、Hbase、Solr等。 消息系统：解耦和生产者和消费者、缓存消息等。 用户活动跟踪：Kafka经常被用来记录web用户或者app用户的各种活动，如浏览网⻚、 搜索、点击等活动，这些活动信息被各个服务器发布到kafka的topic中，然后订阅者通过 订阅这些topic来做实时的监控分析，或者装载到hadoop、数据仓库中做离线分析和挖 掘。 运营指标：Kafka也经常用来记录运营监控数据。包括收集各种分布式应用的数据，生产 各种操作的集中反馈，比如报警和报告。")],-1),O={id:"_2-kafka基本概念",tabindex:"-1"},R=e("blockquote",null,[e("p",null,[l("kafka是一个分布式的，分区的消息(官方称之为commit log)服务。它提供一个消息系统应该 具备的功能，但是确有着独特的设计。可以这样来说，Kafka借鉴了JMS规范的思想，但是确 并 "),e("code",null,"没有完全遵循JMS规范。")])],-1),W=e("p",null,"首先，让我们来看一下基础的消息(Message)相关术语：",-1),I=e("table",null,[e("thead",null,[e("tr",null,[e("th",null,"名称"),e("th",null,"解释")])]),e("tbody",null,[e("tr",null,[e("td",null,"Broker"),e("td",null,"消息中间件处理节点，⼀个Kafka节点就是⼀个broker，⼀个或者多个Broker可以组成⼀个Kafka集群")]),e("tr",null,[e("td",null,"Topic"),e("td",null,"Kafka根据topic对消息进⾏归类，发布到Kafka集群的每条消息都需要指定⼀个topic")]),e("tr",null,[e("td",null,"Producer"),e("td",null,"消息⽣产者，向Broker发送消息的客户端")]),e("tr",null,[e("td",null,"Consumer"),e("td",null,"消息消费者，从Broker读取消息的客户端")]),e("tr",null,[e("td",null,"ConsumerGroup"),e("td",null,"每个Consumer属于⼀个特定的Consumer Group，⼀条消息可以被多个不同的Consumer Group消费，但是⼀个Consumer Group中只能有⼀个Consumer能够消费该消息")]),e("tr",null,[e("td",null,"Partition"),e("td",null,"物理上的概念，⼀个topic可以分为多个partition，每个partition内部消息是有序的")])])],-1),N=e("p",null,[l("因此，从一个较高的层面上来看，producer通过网络发送消息到Kafka集群，然后consumer 来进行消费，如下图： "),e("img",{src:"https://cos.vlinux.cn/www-vlinux-cn-blog-img/images/QQ%E6%88%AA%E5%9B%BE20220110112502.png#mirages-width=1224&mirages-height=578&mirages-cdn-type=5",alt:"输入图片说明"})],-1),j=e("p",null,[l("服务端(brokers)和客户端(producer、consumer)之间通信通过 "),e("strong",null,"TCP协议"),l(" 来完成。")],-1),G={id:"二、kafka基本使用",tabindex:"-1"},Z={id:"_1-安装前的环境准备",tabindex:"-1"},J=e("li",null,[e("p",null,"安装jdk")],-1),V=e("li",null,[e("p",null,"安装zk")],-1),U=e("li",null,[e("p",null,"解压缩至如下路径"),e("div",{class:"language-"},[e("span",{class:"copy"}),e("pre",{class:"shiki material-theme-palenight",tabindex:"0"},[e("code",null,[e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}},"/usr/local/kafka/")]),l(`
`),e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}})])])])])],-1),X=e("p",null,"修改配置文件：/usr/local/kafka/kafka2.11-2.4/config/server.properties",-1),F=e("div",{class:"language-"},[e("span",{class:"copy"}),e("pre",{class:"shiki material-theme-palenight",tabindex:"0"},[e("code",null,[e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}},"#broker.id属性在kafka集群中必须要是唯一broker.id= 0#kafka部署的机器ip和提供服务的端口号listeners=PLAINTEXT://192.168.65.60:9092#kafka的消息存储文件log.dir=/usr/local/data/kafka-logs#kafka连接zookeeper的地址zookeeper.connect= 192.168.65.60:2181")]),l(`
`),e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}})])])])],-1),Y={id:"_2-启动kafka服务器",tabindex:"-1"},ee=e("p",null,"进入到bin目录下。使用命令来启动",-1),le=e("div",{class:"language-"},[e("span",{class:"copy"}),e("pre",{class:"shiki material-theme-palenight",tabindex:"0"},[e("code",null,[e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}},"./kafka-server-start.sh -daemon../config/server.properties")]),l(`
`),e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}})])])])],-1),ae=e("p",null,"验证是否启动成功：",-1),te=e("p",null,"进入到zk中的节点看id是 0 的broker有没有存在（上线）",-1),se=e("div",{class:"language-"},[e("span",{class:"copy"}),e("pre",{class:"shiki material-theme-palenight",tabindex:"0"},[e("code",null,[e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}},"ls /brokers/ids/")]),l(`
`),e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}})])])])],-1),ne=e("p",null,[e("strong",null,"server.properties核心配置详解：")],-1),ie=e("thead",null,[e("tr",null,[e("th",null,"Property"),e("th",null,"Default"),e("th",null,"Description")])],-1),oe=e("td",null,"0",-1),re=e("td",null,"每个broker都可以⽤⼀个唯⼀的⾮负整数id进⾏标识；这个id可以作为broker的“名字”，你可以选择任意你喜欢的数字作为id，只要id是唯⼀的即可。",-1),ce=e("tr",null,[e("td",null,"log.dirs"),e("td",null,"/tmp/kafka-logs"),e("td",null,"kafka存放数据的路径。这个路径并不是唯⼀的，可以是多个，路径之间只需要使⽤逗号分隔即可；每当创建新partition时，都会选择在包含最少partitions的路径下进⾏。")],-1),de=e("tr",null,[e("td",null,"listeners"),e("td",null,"PLAINTEXT://192.168.65.60:9092"),e("td",null,"server接受客户端连接的端⼝，ip配置kafka本机ip即可")],-1),he=e("tr",null,[e("td",null,"zookeeper.connect"),e("td",null,"localhost:2181"),e("td",null,"zooKeeper连接字符串的格式为：hostname:port，此处hostname和port分别是ZooKeeper集群中某个节点的host和port；zookeeper如果是集群，连接⽅式为hostname1:port1, hostname2:port2,hostname3:port3")],-1),ue=e("tr",null,[e("td",null,"log.retention.hours"),e("td",null,"168"),e("td",null,"每个⽇志⽂件删除之前保存的时间。默认数据保存时间对所有topic都⼀样。")],-1),pe=e("tr",null,[e("td",null,"num.partitions"),e("td",null,"1"),e("td",null,"创建topic的默认分区数")],-1),ke=e("tr",null,[e("td",null,"default.replication.factor"),e("td",null,"1"),e("td",null,"⾃动创建topic的默认副本数量，建议设置为⼤于等于2")],-1),_e=e("tr",null,[e("td",null,"min.insync.replicas"),e("td",null,"1"),e("td",null,"当producer设置acks为-1时，min.insync.replicas指定replicas的最⼩数⽬（必须确认每⼀个repica的写数据都是成功的），如果这个数⽬没有达到，producer发送消息会产⽣异常")],-1),fe=e("tr",null,[e("td",null,"delete.topic.enable"),e("td",null,"false"),e("td",null,"是否允许删除主题")],-1),ge={id:"_3-创建主题topic",tabindex:"-1"},be=e("blockquote",null,[e("p",null,"topic是什么概念？topic可以实现消息的分类，不同消费者订阅不同的topic。")],-1),me=e("p",null,[e("img",{src:"https://cos.vlinux.cn/www-vlinux-cn-blog-img/images/QQ%E6%88%AA%E5%9B%BE20220110122844.png",alt:"输入图片说明"})],-1),ve=e("p",null,"执行以下命令创建名为“test”的topic，这个topic只有一个partition，并且备份因子也设置为1",-1),Ae=e("div",{class:"language-"},[e("span",{class:"copy"}),e("pre",{class:"shiki material-theme-palenight",tabindex:"0"},[e("code",null,[e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}},"./kafka-topics.sh --create --zookeeper 172.16.253.35:2181 --replication-factor 1 --partitions 1 --topic test")]),l(`
`),e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}})])])])],-1),Ce=e("p",null,"查看当前kafka内有哪些topic",-1),ye=e("div",{class:"language-"},[e("span",{class:"copy"}),e("pre",{class:"shiki material-theme-palenight",tabindex:"0"},[e("code",null,[e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}},"./kafka-topics.sh --list --zookeeper 172.16.253.35:2181")]),l(`
`),e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}})])])])],-1),xe={id:"_4-发送消息",tabindex:"-1"},De=e("blockquote",null,[e("p",null,"kafka自带了一个producer命令客户端，可以从本地文件中读取内容，或者我们也可以以命令行中直接输入内容，并将这些内容以消息的形式发送到kafka集群中。在默认情况下，每一个行会被当做成一个独立的消息。使用kafka的发送消息的客户端，指定发送到的kafka服务器地址和topic")],-1),qe=e("div",{class:"language-"},[e("span",{class:"copy"}),e("pre",{class:"shiki material-theme-palenight",tabindex:"0"},[e("code",null,[e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}},"./kafka-console-producer.sh --broker-list 172.16.253.38:9092 --topic test")]),l(`
`),e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}})])])])],-1),Qe={id:"_5-消费消息",tabindex:"-1"},Me=e("p",null,[l("对于consumer，kafka同样也携带了一个命令行客户端，会将获取到内容在命令中进行输 出， "),e("strong",null,"默认是消费最新的消息"),l(" 。使用kafka的消费者消息的客户端，从指定kafka服务器的指定 topic中消费消息")],-1),we=e("p",null,"方式一：从最后一条消息的偏移量+1开始消费",-1),Ke=e("div",{class:"language-"},[e("span",{class:"copy"}),e("pre",{class:"shiki material-theme-palenight",tabindex:"0"},[e("code",null,[e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}},"./kafka-console-consumer.sh --bootstrap-server 172.16.253.38:9092 --topic test")]),l(`
`),e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}})])])])],-1),Te=e("p",null,"方式二：从头开始消费",-1),Be=e("div",{class:"language-"},[e("span",{class:"copy"}),e("pre",{class:"shiki material-theme-palenight",tabindex:"0"},[e("code",null,[e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}},"./kafka-console-consumer.sh --bootstrap-server 172.16.253.38:9092 --from-beginning --topic test")]),l(`
`),e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}})])])])],-1),Ee={id:"几个注意点：",tabindex:"-1"},Pe=e("ul",null,[e("li",null,"消息会被存储"),e("li",null,"消息是顺序存储"),e("li",null,"消息是有偏移量的"),e("li",null,"消费时可以指明偏移量进行消费")],-1),He={id:"三、kafka中的关键细节",tabindex:"-1"},ze={id:"_1-消息的顺序存储",tabindex:"-1"},$e=e("blockquote",null,[e("p",null,"消息的发送方会把消息发送到broker中，broker会存储消息，消息是按照发送的顺序进行存储。因此消费者在消费消息时可以指明主题中消息的偏移量。默认情况下，是从最后一个消息的下一个偏移量开始消费。")],-1),Se={id:"_2-单播消息的实现",tabindex:"-1"},Le=e("blockquote",null,[e("p",null,"单播消息：一个消费组里 只会有一个消费者能消费到某一个topic中的消息。于是可以创建多个消费者，这些消费者在同一个消费组中。")],-1),Oe=e("div",{class:"language-"},[e("span",{class:"copy"}),e("pre",{class:"shiki material-theme-palenight",tabindex:"0"},[e("code",null,[e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}},"./kafka-console-consumer.sh --bootstrap-server 10.31.167.10:9092 --consumer-property group.id=testGroup --topic test")]),l(`
`),e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}})])])])],-1),Re={id:"_3-多播消息的实现",tabindex:"-1"},We={id:"在一些业务场景中需要让一条消息被多个消费者消费，那么就可以使用多播模式。",tabindex:"-1"},Ie=e("p",null,"kafka实现多播，只需要让不同的消费者处于不同的消费组即可。",-1),Ne=e("div",{class:"language-"},[e("span",{class:"copy"}),e("pre",{class:"shiki material-theme-palenight",tabindex:"0"},[e("code",null,[e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}},"./kafka-console-consumer.sh --bootstrap-server 10.31.167.10:9092 --consumer-property group.id=testGroup1 --topic test./kafka-console-consumer.sh --bootstrap-server 10.31.167.10:9092 --consumer-property group.id=testGroup2 --topic test")]),l(`
`),e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}})])])])],-1),je={id:"_4-查看消费组及信息",tabindex:"-1"},Ge=e("div",{class:"language-"},[e("span",{class:"copy"}),e("pre",{class:"shiki material-theme-palenight",tabindex:"0"},[e("code",null,[e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}},"# 查看当前主题下有哪些消费组./kafka-consumer-groups.sh --bootstrap-server 10.31.167.10:9092 --list# 查看消费组中的具体信息：比如当前偏移量、最后一条消息的偏移量、堆积的消息数量./kafka-consumer-groups.sh --bootstrap-server 172.16.253.38:9092 --describe --group testGroup")]),l(`
`),e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}})])])])],-1),Ze=e("p",null,[e("img",{src:"https://cos.vlinux.cn/www-vlinux-cn-blog-img/images/QQ%E6%88%AA%E5%9B%BE20220110125233.png",alt:"输入图片说明"})],-1),Je=e("ul",null,[e("li",null,"Currennt-offset: 当前消费组的已消费偏移量"),e("li",null,"Log-end-offset: 主题对应分区消息的结束偏移量(HW)"),e("li",null,"Lag: 当前消费组未消费的消息数")],-1),Ve={id:"四、主题、分区的概念",tabindex:"-1"},Ue={id:"_1-主题topic",tabindex:"-1"},Xe=e("p",null,"主题Topic可以理解成是一个类别的名称。",-1),Fe={id:"_2-partition分区",tabindex:"-1"},Ye=e("p",null,[e("img",{src:"https://cos.vlinux.cn/www-vlinux-cn-blog-img/images/QQ%E6%88%AA%E5%9B%BE20220110125413.png",alt:"输入图片说明"})],-1),el=e("blockquote",null,[e("p",null,"一个主题中的消息量是非常大的，因此可以通过分区的设置，来分布式存储这些消息。比如一个topic创建了 3 个分区。那么topic中的消息就会分别存放在这三个分区中。")],-1),ll={id:"为一个主题创建多个分区",tabindex:"-1"},al=e("div",{class:"language-"},[e("span",{class:"copy"}),e("pre",{class:"shiki material-theme-palenight",tabindex:"0"},[e("code",null,[e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}},"./kafka-topics.sh --create --zookeeper localhost:2181 --partitions 2 --topic test1")]),l(`
`),e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}})])])])],-1),tl=e("p",null,[e("strong",null,"可以通过这样的命令查看topic的分区信息")],-1),sl=e("div",{class:"language-"},[e("span",{class:"copy"}),e("pre",{class:"shiki material-theme-palenight",tabindex:"0"},[e("code",null,[e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}},"./kafka-topics.sh --describe --zookeeper localhost:2181 --topic test1")]),l(`
`),e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}})])])])],-1),nl={id:"分区的作用：",tabindex:"-1"},il=e("ul",null,[e("li",null,"可以分布式存储"),e("li",null,"可以并行写")],-1),ol=e("p",null,"实际上是存在data/kafka-logs/test-0 和 test-1中的0000000.log文件中",-1),rl=e("p",null,"小细节：",-1),cl=e("blockquote",null,[e("p",null,"定期将自己消费分区的offset提交给kafka内部topic：__consumer_offsets，提交过去的 时候，key是consumerGroupId+topic+分区号，value就是当前offset的值，kafka会定 期清理topic里的消息，最后就保留最新的那条数据 因为__consumer_offsets可能会接收高并发的请求，kafka默认给其分配 50 个分区(可以 通过offsets.topic.num.partitions设置)，这样可以通过加机器的方式抗大并发。 通过如下公式可以选出consumer消费的offset要提交到__consumer_offsets的哪个分区 公式：hash(consumerGroupId) % __consumer_offsets主题的分区数")],-1),dl={id:"五、kafka集群及副本的概念",tabindex:"-1"},hl={id:"_1-搭建kafka集群，-3-个broker",tabindex:"-1"},ul=e("p",null,"准备 3 个server.properties文件",-1),pl=e("p",null,"每个文件中的这些内容要调整",-1),kl=e("li",null,[e("p",null,"server.properties"),e("div",{class:"language-"},[e("span",{class:"copy"}),e("pre",{class:"shiki material-theme-palenight",tabindex:"0"},[e("code",null,[e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}},"broker.id= 0listeners=PLAINTEXT://192.168.65.60:log.dir=/usr/local/data/kafka-logs")]),l(`
`),e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}})])])])])],-1),_l=e("li",null,[e("p",null,"server1.properties"),e("div",{class:"language-"},[e("span",{class:"copy"}),e("pre",{class:"shiki material-theme-palenight",tabindex:"0"},[e("code",null,[e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}},"broker.id= 1listeners=PLAINTEXT://192.168.65.60:log.dir=/usr/local/data/kafka-logs-")]),l(`
`),e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}})])])])])],-1),fl=e("p",null,"server2.properties",-1),gl=e("div",{class:"language-"},[e("span",{class:"copy"}),e("pre",{class:"shiki material-theme-palenight",tabindex:"0"},[e("code",null,[e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}},"broker.id= 2listeners=PLAINTEXT://192.168.65.60:log.dir=/usr/local/data/kafka-logs-")]),l(`
`),e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}})])])])],-1),bl={id:"使用如下命令来启动-3-台服务器",tabindex:"-1"},ml=e("div",{class:"language-"},[e("span",{class:"copy"}),e("pre",{class:"shiki material-theme-palenight",tabindex:"0"},[e("code",null,[e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}},"./kafka-server-start.sh -daemon../config/server0.properties./kafka-server-start.sh -daemon../config/server1.properties./kafka-server-start.sh -daemon../config/server2.properties")]),l(`
`),e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}})])])])],-1),vl=e("p",null,"搭建完后通过查看zk中的/brokers/ids 看是否启动成功",-1),Al={id:"_2-副本的概念",tabindex:"-1"},Cl=e("blockquote",null,[e("p",null,"副本是对分区的备份。在集群中，不同的副本会被部署在不同的broker上。下面例子：创建 1个主题， 2 个分区、 3 个副本。")],-1),yl=e("div",{class:"language-"},[e("span",{class:"copy"}),e("pre",{class:"shiki material-theme-palenight",tabindex:"0"},[e("code",null,[e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}},"./kafka-topics.sh --create --zookeeper 172.16.253.35:2181 --replication-factor 3 --partitions 2 --topic my-replicated-topic")]),l(`
`),e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}})])])])],-1),xl=e("p",null,[e("img",{src:"https://cos.vlinux.cn/www-vlinux-cn-blog-img/images/QQ%E6%88%AA%E5%9B%BE20220110133849.png",alt:"输入图片说明"})],-1),Dl=e("p",null,"通过查看主题信息，其中的关键数据：",-1),ql=e("ul",null,[e("li",null,"replicas：当前副本存在的broker节点"),e("li",null,[l("leader：副本里的概念 "),e("ul",null,[e("li",null,"每个partition都有一个broker作为leader。"),e("li",null,"消息发送方要把消息发给哪个broker？就看副本的leader是在哪个broker上面。副本里的leader专⻔用来接收消息。"),e("li",null,"接收到消息，其他follower通过poll的方式来同步数据。")])]),e("li",null,"follower：leader处理所有针对这个partition的读写请求，而follower被动复制leader，不提供读写（主要是为了保证多副本数据与消费的一致性），如果leader所在的broker挂掉，那么就会进行新leader的选举，至于怎么选，在之后的controller的概念中介绍。")],-1),Ql=e("p",null,"通过kill掉leader后再查看主题情况",-1),Ml=e("div",{class:"language-"},[e("span",{class:"copy"}),e("pre",{class:"shiki material-theme-palenight",tabindex:"0"},[e("code",null,[e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}},"# kill掉leaderps -aux | grep server.propertieskill 17631# 查看topic情况./kafka-topics.sh --describe --zookeeper 172.16.253.35:2181 --topic my-replicated-topic")]),l(`
`),e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}})])])])],-1),wl=e("p",null,"isr： 可以同步的broker节点和已同步的broker节点，存放在isr集合中。",-1),Kl={id:"_3-broker、主题、分区、副本",tabindex:"-1"},Tl=e("ul",null,[e("li",null,"kafka集群中由多个broker组成"),e("li",null,"一个broker中存放一个topic的不同partition——副本")],-1),Bl=e("p",null,[e("img",{src:"https://cos.vlinux.cn/www-vlinux-cn-blog-img/images/QQ%E6%88%AA%E5%9B%BE20220110134554.png",alt:"输入图片说明"})],-1),El={id:"_4-kafka集群消息的发送",tabindex:"-1"},Pl=e("div",{class:"language-"},[e("span",{class:"copy"}),e("pre",{class:"shiki material-theme-palenight",tabindex:"0"},[e("code",null,[e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}},"./kafka-console-producer.sh --broker-list 172.16.253.38:9092,172.16.253.38:9093,172.16.253.38:9094 --topic my-replicated-topic")]),l(`
`),e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}})])])])],-1),Hl={id:"_5-kafka集群消息的消费",tabindex:"-1"},zl=e("div",{class:"language-"},[e("span",{class:"copy"}),e("pre",{class:"shiki material-theme-palenight",tabindex:"0"},[e("code",null,[e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}},"./kafka-console-consumer.sh --bootstrap-server 172.16.253.38:9092,172.16.253.38:9093,172.16.253.38:9094 --from-beginning --topic my-replicated-topic")]),l(`
`),e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}})])])])],-1),$l={id:"_6-关于分区消费组消费者的细节",tabindex:"-1"},Sl=e("p",null,[e("img",{src:"https://cos.vlinux.cn/www-vlinux-cn-blog-img/images/QQ%E6%88%AA%E5%9B%BE20220110134734.png",alt:"输入图片说明"})],-1),Ll=e("blockquote",null,[e("p",null,"图中Kafka集群有两个broker，每个broker中有多个partition。一个partition只能被一个消费组里的某一个消费者消费，从而保证消费顺序。Kafka只在partition的范围内保证消息消费的局部顺序性，不能在同一个topic中的多个partition中保证总的消费顺序性。一个消费者可以消费多个partition。")],-1),Ol=e("div",{class:"language-"},[e("span",{class:"copy"}),e("pre",{class:"shiki material-theme-palenight",tabindex:"0"},[e("code",null,[e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}},"消费组中消费者的数量不能比一个topic中的partition数量多，否则多出来的消费者消费不到消息。")]),l(`
`),e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}})])])])],-1),Rl={id:"六、kafka集群controller、rebalance和hw",tabindex:"-1"},Wl={id:"",tabindex:"-1"},Il={id:"_1-controller",tabindex:"-1"},Nl=e("ul",null,[e("li",null,[l("Kafka集群中的broker在zk中创建临时序号节点，序号最小的节点（最先创建的节点）将作为集群的controller，负责管理整个集群中的所有分区和副本的状态： "),e("ul",null,[e("li",null,"当某个分区的leader副本出现故障时，由控制器负责为该分区选举新的leader副本。"),e("li",null,"当检测到某个分区的ISR集合发生变化时，由控制器负责通知所有broker更新其元数据信息。"),e("li",null,"当使用kafka-topics.sh脚本为某个topic增加分区数量时，同样还是由控制器负责让新分区被其他节点感知到。")])])],-1),jl={id:"_2-rebalance机制",tabindex:"-1"},Gl=e("p",null,"前提是：消费者没有指明分区消费。当消费组里消费者和分区的关系发生变化，那么就会触发rebalance机制。",-1),Zl=e("p",null,"这个机制会重新调整消费者消费哪个分区。",-1),Jl=e("p",null,"在触发rebalance机制之前，消费者消费哪个分区有三种策略：",-1),Vl=e("ul",null,[e("li",null,"range：通过公示来计算某个消费者消费哪个分区"),e("li",null,"轮询：大家轮着消费"),e("li",null,"sticky：在触发了rebalance后，在消费者消费的原分区不变的基础上进行调整。")],-1),Ul={id:"_3-hw和leo",tabindex:"-1"},Xl=e("blockquote",null,[e("p",null,"HW俗称高水位，HighWatermark的缩写，取一个partition对应的ISR中最小的LEO(log-end-offset)作为HW，consumer最多只能消费到HW所在的位置。另外每个replica都有HW,leader和follower各自负责更新自己的HW的状态。对于leader新写入的消息，consumer不能立刻消费，leader会等待该消息被所有ISR中的replicas同步后更新HW，此时消息才能被consumer消费。这样就保证了如果leader所在的broker失效，该消息仍然可以从新选举的leader中获取。")],-1),Fl={id:"七、kafka线上问题优化",tabindex:"-1"},Yl={id:"_1-如何防止消息丢失",tabindex:"-1"},ea=e("ul",null,[e("li",null,"发送方： ack是 1 或者-1/all 可以防止消息丢失，如果要做到99.9999%，ack设成all，把min.insync.replicas配置成分区备份数"),e("li",null,"消费方：把自动提交改为手动提交。")],-1),la={id:"_2-如何防止消息的重复消费",tabindex:"-1"},aa=e("blockquote",null,[e("p",null,"一条消息被消费者消费多次。如果为了消息的不重复消费，而把生产端的重试机制关闭、消费端的手动提交改成自动提交，这样反而会出现消息丢失，那么可以直接在防治消息丢失的手段上再加上消费消息时的幂等性保证，就能解决消息的重复消费问题。")],-1),ta={id:"幂等性如何保证：",tabindex:"-1"},sa=e("ul",null,[e("li",null,"mysql 插入业务id作为主键，主键是唯一的，所以一次只能插入一条"),e("li",null,"使用redis或zk的分布式锁（主流的方案）")],-1),na={id:"_3-如何做到顺序消费rocketmq",tabindex:"-1"},ia=e("ul",null,[e("li",null,"发送方：在发送时将ack不能设置 0 ，关闭重试，使用同步发送，等到发送成功再发送下一条。确保消息是顺序发送的。"),e("li",null,"接收方：消息是发送到一个分区中，只能有一个消费组的消费者来接收消息。因此，kafka的顺序消费会牺牲掉性能。")],-1),oa={id:"_4-解决消息积压问题",tabindex:"-1"},ra=e("blockquote",null,[e("p",null,"消息积压会导致很多问题，比如磁盘被打满、生产端发消息导致kafka性能过慢，就容易出现服务雪崩，就需要有相应的手段：")],-1),ca=e("ul",null,[e("li",null,"方案一：在一个消费者中启动多个线程，让多个线程同时消费。——提升一个消费者的消费能力（增加分区增加消费者）。"),e("li",null,"方案二：如果方案一还不够的话，这个时候可以启动多个消费者，多个消费者部署在不同的服务器上。其实多个消费者部署在同一服务器上也可以提高消费能力——充分利用服务器的cpu资源。"),e("li",null,"方案三：让一个消费者去把收到的消息往另外一个topic上发，另一个topic设置多个分区和多个消费者 ，进行具体的业务消费。")],-1),da={id:"_5-延迟队列",tabindex:"-1"},ha=e("p",null,"延迟队列的应用场景：在订单创建成功后如果超过 30 分钟没有付款，则需要取消订单，此时可用延时队列来实现",-1),ua=e("ul",null,[e("li",null,[l("创建多个topic，每个topic表示延时的间隔 "),e("ul",null,[e("li",null,"topic_5s: 延时5s执行的队列"),e("li",null,"topic_1m: 延时 1 分钟执行的队列"),e("li",null,"topic_30m: 延时 30 分钟执行的队列")])]),e("li",null,"消息发送者发送消息到相应的topic，并带上消息的发送时间"),e("li",null,[l("消费者订阅相应的topic，消费时轮询消费整个topic中的消息 "),e("ul",null,[e("li",null,"如果消息的发送时间，和消费的当前时间超过预设的值，比如 30 分钟"),e("li",null,"如果消息的发送时间，和消费的当前时间没有超过预设的值，则不消费当前的offset及之后的offset的所有消息都消费"),e("li",null,"下次继续消费该offset处的消息，判断时间是否已满足预设值")])])],-1),pa={id:"八、kafka-eagle监控平台",tabindex:"-1"},ka={id:"安装kafka-eagle",tabindex:"-1"},_a=e("ul",null,[e("li",null,"安装jdk"),e("li",null,"解压缩后修改配置文件 system-config.properties")],-1),fa=e("div",{class:"language-"},[e("span",{class:"copy"}),e("pre",{class:"shiki material-theme-palenight",tabindex:"0"},[e("code",null,[e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}},"# 配置zk  去掉cluster2efak.zk.cluster.alias=cluster1cluster1.zk.list=172.16.253.35:2181# cluster2.zk.list=xdn10:2181,xdn11:2181,xdn12:2181# 配置mysqlkafka.eagle.driver=com.mysql.cj.jdbc.Driverkafka.eagle.url=jdbc:mysql://172.16.253.22:3306/ke?useUnicode=true&characterEncoding=UTF-8&zeroDateTimeBehavior=convertToNullkafka.eagle.username=rootkafka.eagle.password= 123456")]),l(`
`),e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}})])])])],-1),ga=e("ul",null,[e("li",null,[e("p",null,"修改/etc/profile"),e("div",{class:"language-"},[e("span",{class:"copy"}),e("pre",{class:"shiki material-theme-palenight",tabindex:"0"},[e("code",null,[e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}},"export  JAVA_HOME=/usr/local/jdk/jdk1.8.0_191CLASSPATH=.:$JAVA_HOME/lib/tools.jar:$JAVA_HOME/lib/dt.jarexport KE_HOME=/home/aisys/efak-web-2.0.9export PATH=$PATH:$KE_HOME/bin:$JAVA_HOME/bin")]),l(`
`),e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}})])])])])]),e("li",null,[e("p",null,"刷新配置"),e("div",{class:"language-"},[e("span",{class:"copy"}),e("pre",{class:"shiki material-theme-palenight",tabindex:"0"},[e("code",null,[e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}},"source /etc/profile")]),l(`
`),e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}})])])])])]),e("li",null,[e("p",null,"进入到bin目录，为ke.sh增加可执行的权限")])],-1),ba=e("div",{class:"language-"},[e("span",{class:"copy"}),e("pre",{class:"shiki material-theme-palenight",tabindex:"0"},[e("code",null,[e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}},"chmod +x ke.sh")]),l(`
`),e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}})])])])],-1),ma=e("ul",null,[e("li",null,[e("p",null,"启动kafka-eagle"),e("div",{class:"language-"},[e("span",{class:"copy"}),e("pre",{class:"shiki material-theme-palenight",tabindex:"0"},[e("code",null,[e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}},"./ke.sh start")]),l(`
`),e("span",{class:"line"},[e("span",{style:{color:"#A6ACCD"}})])])])])])],-1);function va(n,Aa,Ca,ya,r,xa){const t=k,c=d;return p(),u(c,{frontmatter:r.frontmatter,data:r.data},{"main-content-md":a(()=>[e("h1",g,[l("消息队列的流派 "),s(t,{class:"header-anchor",href:"#消息队列的流派","aria-hidden":"true"},{default:a(()=>[l("#")]),_:1})]),e("h3",b,[l("什么是 MQ "),s(t,{class:"header-anchor",href:"#什么是-mq","aria-hidden":"true"},{default:a(()=>[l("#")]),_:1})]),m,e("h3",v,[l("有 Broker 的 MQ "),s(t,{class:"header-anchor",href:"#有-broker-的-mq","aria-hidden":"true"},{default:a(()=>[l("#")]),_:1})]),A,e("h3",C,[l("重 Topic "),s(t,{class:"header-anchor",href:"#重-topic","aria-hidden":"true"},{default:a(()=>[l("#")]),_:1})]),y,x,D,e("h3",q,[l("轻 Topic "),s(t,{class:"header-anchor",href:"#轻-topic","aria-hidden":"true"},{default:a(()=>[l("#")]),_:1})]),Q,M,w,K,T,e("h3",B,[l("无 Broker 的 MQ "),s(t,{class:"header-anchor",href:"#无-broker-的-mq","aria-hidden":"true"},{default:a(()=>[l("#")]),_:1})]),E,P,H,e("h1",z,[l("一、Kafka介绍 "),s(t,{class:"header-anchor",href:"#一、kafka介绍","aria-hidden":"true"},{default:a(()=>[l("#")]),_:1})]),$,e("h2",S,[l("1.Kafka的使用场景 "),s(t,{class:"header-anchor",href:"#_1-kafka的使用场景","aria-hidden":"true"},{default:a(()=>[l("#")]),_:1})]),L,e("h2",O,[l("2.Kafka基本概念 "),s(t,{class:"header-anchor",href:"#_2-kafka基本概念","aria-hidden":"true"},{default:a(()=>[l("#")]),_:1})]),R,W,I,N,j,e("h1",G,[l("二、kafka基本使用 "),s(t,{class:"header-anchor",href:"#二、kafka基本使用","aria-hidden":"true"},{default:a(()=>[l("#")]),_:1})]),e("h2",Z,[l("1.安装前的环境准备 "),s(t,{class:"header-anchor",href:"#_1-安装前的环境准备","aria-hidden":"true"},{default:a(()=>[l("#")]),_:1})]),e("ul",null,[J,V,e("li",null,[e("p",null,[l("官网下载kafka的压缩包:"),s(t,{href:"http://kafka.apache.org/downloads",target:"_blank",rel:"noreferrer"},{default:a(()=>[l("http://kafka.apache.org/downloads")]),_:1})])]),U,e("li",null,[X,F,e("h2",Y,[l("2.启动kafka服务器 "),s(t,{class:"header-anchor",href:"#_2-启动kafka服务器","aria-hidden":"true"},{default:a(()=>[l("#")]),_:1})])])]),ee,le,ae,te,se,ne,e("table",null,[ie,e("tbody",null,[e("tr",null,[e("td",null,[s(t,{href:"http://broker.id",target:"_blank",rel:"noreferrer"},{default:a(()=>[l("broker.id")]),_:1})]),oe,re]),ce,de,he,ue,pe,ke,_e,fe])]),e("h2",ge,[l("3.创建主题topic "),s(t,{class:"header-anchor",href:"#_3-创建主题topic","aria-hidden":"true"},{default:a(()=>[l("#")]),_:1})]),be,me,ve,Ae,Ce,ye,e("h2",xe,[l("4.发送消息 "),s(t,{class:"header-anchor",href:"#_4-发送消息","aria-hidden":"true"},{default:a(()=>[l("#")]),_:1})]),De,qe,e("h2",Qe,[l("[5.消费消息 "),s(t,{class:"header-anchor",href:"#_5-消费消息","aria-hidden":"true"},{default:a(()=>[l("#")]),_:1})]),Me,we,Ke,Te,Be,e("h3",Ee,[l("几个注意点： "),s(t,{class:"header-anchor",href:"#几个注意点：","aria-hidden":"true"},{default:a(()=>[l("#")]),_:1})]),Pe,e("h1",He,[l("三、Kafka中的关键细节 "),s(t,{class:"header-anchor",href:"#三、kafka中的关键细节","aria-hidden":"true"},{default:a(()=>[l("#")]),_:1})]),e("h2",ze,[l("1.消息的顺序存储 "),s(t,{class:"header-anchor",href:"#_1-消息的顺序存储","aria-hidden":"true"},{default:a(()=>[l("#")]),_:1})]),$e,e("h2",Se,[l("[2. 单播消息的实现 "),s(t,{class:"header-anchor",href:"#_2-单播消息的实现","aria-hidden":"true"},{default:a(()=>[l("#")]),_:1})]),Le,Oe,e("h2",Re,[l("3.多播消息的实现 "),s(t,{class:"header-anchor",href:"#_3-多播消息的实现","aria-hidden":"true"},{default:a(()=>[l("#")]),_:1})]),e("h3",We,[l("在一些业务场景中需要让一条消息被多个消费者消费，那么就可以使用多播模式。 "),s(t,{class:"header-anchor",href:"#在一些业务场景中需要让一条消息被多个消费者消费，那么就可以使用多播模式。","aria-hidden":"true"},{default:a(()=>[l("#")]),_:1})]),Ie,Ne,e("h2",je,[l("4.查看消费组及信息 "),s(t,{class:"header-anchor",href:"#_4-查看消费组及信息","aria-hidden":"true"},{default:a(()=>[l("#")]),_:1})]),Ge,Ze,Je,e("h1",Ve,[l("四、主题、分区的概念 "),s(t,{class:"header-anchor",href:"#四、主题、分区的概念","aria-hidden":"true"},{default:a(()=>[l("#")]),_:1})]),e("h2",Ue,[l("1.主题Topic "),s(t,{class:"header-anchor",href:"#_1-主题topic","aria-hidden":"true"},{default:a(()=>[l("#")]),_:1})]),Xe,e("h2",Fe,[l("2.partition分区 "),s(t,{class:"header-anchor",href:"#_2-partition分区","aria-hidden":"true"},{default:a(()=>[l("#")]),_:1})]),Ye,el,e("h3",ll,[l("为一个主题创建多个分区 "),s(t,{class:"header-anchor",href:"#为一个主题创建多个分区","aria-hidden":"true"},{default:a(()=>[l("#")]),_:1})]),al,tl,sl,e("h3",nl,[l("分区的作用： "),s(t,{class:"header-anchor",href:"#分区的作用：","aria-hidden":"true"},{default:a(()=>[l("#")]),_:1})]),il,ol,rl,cl,e("h1",dl,[l("五、Kafka集群及副本的概念 "),s(t,{class:"header-anchor",href:"#五、kafka集群及副本的概念","aria-hidden":"true"},{default:a(()=>[l("#")]),_:1})]),e("h2",hl,[l("1.搭建kafka集群， 3 个broker "),s(t,{class:"header-anchor",href:"#_1-搭建kafka集群，-3-个broker","aria-hidden":"true"},{default:a(()=>[l("#")]),_:1})]),ul,pl,e("ul",null,[kl,_l,e("li",null,[fl,gl,e("h3",bl,[l("使用如下命令来启动 3 台服务器 "),s(t,{class:"header-anchor",href:"#使用如下命令来启动-3-台服务器","aria-hidden":"true"},{default:a(()=>[l("#")]),_:1})])])]),ml,vl,e("h2",Al,[l("2.副本的概念 "),s(t,{class:"header-anchor",href:"#_2-副本的概念","aria-hidden":"true"},{default:a(()=>[l("#")]),_:1})]),Cl,yl,xl,Dl,ql,Ql,Ml,wl,e("h2",Kl,[l("3.broker、主题、分区、副本 "),s(t,{class:"header-anchor",href:"#_3-broker、主题、分区、副本","aria-hidden":"true"},{default:a(()=>[l("#")]),_:1})]),Tl,Bl,e("h2",El,[l("4.kafka集群消息的发送 "),s(t,{class:"header-anchor",href:"#_4-kafka集群消息的发送","aria-hidden":"true"},{default:a(()=>[l("#")]),_:1})]),Pl,e("h2",Hl,[l("5.kafka集群消息的消费 "),s(t,{class:"header-anchor",href:"#_5-kafka集群消息的消费","aria-hidden":"true"},{default:a(()=>[l("#")]),_:1})]),zl,e("h2",$l,[l("6.关于分区消费组消费者的细节 "),s(t,{class:"header-anchor",href:"#_6-关于分区消费组消费者的细节","aria-hidden":"true"},{default:a(()=>[l("#")]),_:1})]),Sl,Ll,Ol,e("h1",Rl,[l("六、Kafka集群Controller、Rebalance和HW "),s(t,{class:"header-anchor",href:"#六、kafka集群controller、rebalance和hw","aria-hidden":"true"},{default:a(()=>[l("#")]),_:1})]),e("h1",Wl,[s(t,{class:"header-anchor",href:"#","aria-hidden":"true"},{default:a(()=>[l("#")]),_:1})]),e("h2",Il,[l("1.Controller "),s(t,{class:"header-anchor",href:"#_1-controller","aria-hidden":"true"},{default:a(()=>[l("#")]),_:1})]),Nl,e("h2",jl,[l("2.Rebalance机制 "),s(t,{class:"header-anchor",href:"#_2-rebalance机制","aria-hidden":"true"},{default:a(()=>[l("#")]),_:1})]),Gl,Zl,Jl,Vl,e("h2",Ul,[l("3.HW和LEO "),s(t,{class:"header-anchor",href:"#_3-hw和leo","aria-hidden":"true"},{default:a(()=>[l("#")]),_:1})]),Xl,e("h1",Fl,[l("七、Kafka线上问题优化 "),s(t,{class:"header-anchor",href:"#七、kafka线上问题优化","aria-hidden":"true"},{default:a(()=>[l("#")]),_:1})]),e("h2",Yl,[l("1.如何防止消息丢失 "),s(t,{class:"header-anchor",href:"#_1-如何防止消息丢失","aria-hidden":"true"},{default:a(()=>[l("#")]),_:1})]),ea,e("h2",la,[l("2.如何防止消息的重复消费 "),s(t,{class:"header-anchor",href:"#_2-如何防止消息的重复消费","aria-hidden":"true"},{default:a(()=>[l("#")]),_:1})]),aa,e("h3",ta,[l("幂等性如何保证： "),s(t,{class:"header-anchor",href:"#幂等性如何保证：","aria-hidden":"true"},{default:a(()=>[l("#")]),_:1})]),sa,e("h2",na,[l("3.如何做到顺序消费RocketMQ "),s(t,{class:"header-anchor",href:"#_3-如何做到顺序消费rocketmq","aria-hidden":"true"},{default:a(()=>[l("#")]),_:1})]),ia,e("h2",oa,[l("4.解决消息积压问题 "),s(t,{class:"header-anchor",href:"#_4-解决消息积压问题","aria-hidden":"true"},{default:a(()=>[l("#")]),_:1})]),ra,ca,e("h2",da,[l("5.延迟队列 "),s(t,{class:"header-anchor",href:"#_5-延迟队列","aria-hidden":"true"},{default:a(()=>[l("#")]),_:1})]),ha,ua,e("h1",pa,[l("八、Kafka-eagle监控平台 "),s(t,{class:"header-anchor",href:"#八、kafka-eagle监控平台","aria-hidden":"true"},{default:a(()=>[l("#")]),_:1})]),e("h2",ka,[l("安装Kafka-eagle "),s(t,{class:"header-anchor",href:"#安装kafka-eagle","aria-hidden":"true"},{default:a(()=>[l("#")]),_:1})]),e("p",null,[s(t,{href:"http://www.kafka-eagle.org/",target:"_blank",rel:"noreferrer"},{default:a(()=>[l("http://www.kafka-eagle.org/")]),_:1})]),_a,fa,ga,ba,ma]),"main-header":a(()=>[i(n.$slots,"main-header")]),"main-header-after":a(()=>[i(n.$slots,"main-header-after")]),"main-nav":a(()=>[i(n.$slots,"main-nav")]),"main-content":a(()=>[i(n.$slots,"main-content")]),"main-content-after":a(()=>[i(n.$slots,"main-content-after")]),"main-nav-before":a(()=>[i(n.$slots,"main-nav-before")]),"main-nav-after":a(()=>[i(n.$slots,"main-nav-after")]),comment:a(()=>[i(n.$slots,"comment")]),footer:a(()=>[i(n.$slots,"footer")]),aside:a(()=>[i(n.$slots,"aside")]),"aside-custom":a(()=>[i(n.$slots,"aside-custom")]),default:a(()=>[i(n.$slots,"default")]),_:3},8,["frontmatter","data"])}const Ta=h(f,[["render",va]]);export{Ka as __pageData,Ta as default};
