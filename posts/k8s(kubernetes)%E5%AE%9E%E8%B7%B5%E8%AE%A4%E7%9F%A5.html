<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1"><link rel="icon" href="/favicon.svg"><script>const prefersDark=window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches,colorSchemeSetting=localStorage.getItem("vueuse-color-scheme")||"auto";("dark"===colorSchemeSetting||prefersDark&&"light"!==colorSchemeSetting)&&document.documentElement.classList.toggle("dark",!0)</script><script>const locale=localStorage.getItem("valaxy-locale")||"zh-CN";document.documentElement.setAttribute("lang",locale)</script><script type="module" async="" crossorigin="" src="/assets/app-201ed505.js"></script><style>@charset "UTF-8";.back-to-top{position:fixed;right:-1.5rem;bottom:1rem;z-index:var(--yun-z-go-up-btn);opacity:0;pointer-events:none;color:var(--va-c-primary);transform:translate(0) rotate(270deg);transition:transform var(--va-transition-duration),opacity var(--va-transition-duration-fast)!important}.progress-circle{transition:.3s stroke-dashoffset;transform:rotate(-90deg);transform-origin:50% 50%}.progress-circle-container{position:absolute}.menu-btn{display:inline-flex;position:fixed;left:.8rem;top:.6rem;line-height:1;z-index:var(--yun-z-menu-btn);cursor:pointer}.sidebar .links{display:flex;justify-content:center}.sidebar .link-item{display:inline-flex}.sidebar .link-item .icon{width:2rem;height:2rem}.links-of-author{display:flex;flex-wrap:wrap;justify-content:center}.links-of-author .icon{width:1.5rem;height:1.5rem}.links-of-author-item{line-height:1;font-size:.9rem}.site-nav{display:flex;justify-content:center;overflow:hidden;line-height:1.5;white-space:nowrap;text-align:center;margin-top:1rem}.site-link-item{display:flex;padding:0 15px;align-items:center;border-left:1px solid var(--va-c-gray);flex-direction:column;color:var(--va-c-text)}.site-link-item:first-child,.site-link-item:last-child{line-height:1;padding:0}.site-link-item:first-child{border-left:none;border-right:1px solid var(--va-c-gray)}.site-link-item:last-child{border-left:1px solid var(--va-c-gray)}.site-link-item:nth-child(2){border:none}.site-link-item .count{color:var(--va-c-text);font-family:var(--va-font-sans);display:block;text-align:center;font-size:1rem}.site-link-item .icon{width:1.5rem;height:1.5rem}.site-link-item .icon:hover{color:var(--va-c-primary-light)}.sidebar-panel{padding:.5rem}.site-author-avatar{display:inline-block;line-height:0;position:relative}.site-author-avatar img{height:96px;width:96px;max-width:100%;margin:0;padding:4px;background-color:#fff;box-shadow:0 0 10px #0003;transition:.4s}.site-author-avatar img:hover{box-shadow:0 0 30px rgba(var(--va-c-primary-rgb),.2)}.site-author-name{margin-top:0;margin-bottom:1rem;line-height:1.5}.site-author-status{position:absolute;height:1.8rem;width:1.8rem;bottom:0;right:0;line-height:1.8rem;border-radius:50%;box-shadow:0 1px 2px #0003;background-color:var(--va-c-bg-light);border:1px solid rgba(255,255,255,.1)}.site-name{color:var(--va-c-text);font-family:var(--va-font-serif);font-weight:900}.site-subtitle{color:var(--va-c-gray);display:block}.site-description{color:var(--va-c-text);font-size:.8rem}.va-bg{position:fixed;width:100%;height:100%;z-index:-1;background-image:var(--va-bg-img);background-size:cover;background-position:center;background-repeat:no-repeat;background-attachment:fixed;animation-name:bgFadeIn;animation-duration:2s;opacity:var(--va-bg-img-opacity,1)}@supports (-webkit-touch-callout:none){.va-bg{background-attachment:scroll}}@keyframes bgFadeIn{0%{opacity:0}to{opacity:var(--va-bg-img-opacity,1)}}canvas.fireworks{position:fixed;left:0;top:0;z-index:1;pointer-events:none}*,:after,:before{box-sizing:border-box;border-width:0;border-style:solid;border-color:#e5e7eb}html{line-height:1.5;-webkit-text-size-adjust:100%;-moz-tab-size:4;tab-size:4;font-family:ui-sans-serif,system-ui,-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,Noto Sans,sans-serif,"Apple Color Emoji","Segoe UI Emoji",Segoe UI Symbol,"Noto Color Emoji"}body{margin:0;line-height:inherit}hr{height:0;color:inherit;border-top-width:1px}h1,h2,h3,h4{font-size:inherit;font-weight:inherit}a{color:inherit;text-decoration:inherit}strong{font-weight:bolder}code,pre{font-family:ui-monospace,SFMono-Regular,Menlo,Monaco,Consolas,Liberation Mono,Courier New,monospace;font-size:1em}table{text-indent:0;border-color:inherit;border-collapse:collapse}button{font-family:inherit;font-size:100%;font-weight:inherit;line-height:inherit;color:inherit;margin:0;padding:0}button{text-transform:none}[type=button],button{-webkit-appearance:button;background-color:transparent;background-image:none}blockquote,h1,h2,h3,h4,hr,p,pre{margin:0}ol,ul{list-style:none;margin:0;padding:0}button{cursor:pointer}canvas,img,svg{display:block;vertical-align:middle}img{max-width:100%;height:auto}body{counter-reset:katexEqnNo mmlEqnNo}html{-webkit-tap-highlight-color:transparent}a{color:var(--va-c-link);font-weight:500}*{outline:0}hr{opacity:.2;margin:1rem}.va-card{background-color:var(--va-c-bg-light)}.flex-center{display:flex;justify-content:center;align-items:center}.inline-flex-center{display:inline-flex;justify-content:center;align-items:center}#app,body,html{margin:0;padding:0;line-height:2}body{background-color:var(--va-c-bg)}a{cursor:pointer}@media screen and (max-width:640px){.markdown-body div[class*=language-]{margin:0 var(--va-code-mobile-margin-x,-1rem)}}@media (min-width:640px){.markdown-body div[class*=language-]{border-radius:6px;margin:16px 0}}.markdown-body code{font-size:.85em}.markdown-body div[class*=language-]{position:relative;background-color:var(--va-code-block-bg);overflow-x:auto}.markdown-body div[class*=language-] code{padding:0 24px;line-height:var(--va-code-line-height);font-size:var(--va-code-font-size);color:var(--va-code-block-color);transition:color .5s;width:fit-content;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none}.markdown-body div[class*=language-] pre{position:relative;z-index:1;margin:0;padding:1rem 0;background:0 0;overflow-x:auto}.markdown-body div[class*=language-] pre code{display:block}.markdown-body [class*=language-]>span.copy{position:absolute;top:8px;right:8px;z-index:2;display:block;justify-content:center;align-items:center;border-radius:4px;width:40px;height:40px;background-color:var(--va-code-block-bg);opacity:0;cursor:pointer;background-image:var(--va-icon-copy);background-position:50%;background-size:20px;background-repeat:no-repeat;transition:opacity .25s}.markdown-body [class*=language-]:hover>span.copy{opacity:1}.markdown-body [class*=language-]>span.copy:hover{background-color:var(--va-code-copy-code-hover-bg)}.markdown-body [class*=language-]:before{position:absolute;top:6px;right:12px;z-index:2;font-size:12px;font-weight:500;color:var(--va-c-text-dark-3);transition:color .5s,opacity .5s}.markdown-body [class*=language-]:hover:before{opacity:0}:root{--va-c-text-warning:#544500}.vt-hamburger{display:flex;justify-content:center;align-items:center}.vt-hamburger:hover .vt-hamburger-top{transform:translate(-5.5px)}.vt-hamburger:hover .vt-hamburger-middle{transform:translate(0)}.vt-hamburger:hover .vt-hamburger-bottom{transform:translate(-11px)}.vt-hamburger-container{position:relative;width:22px;height:20px;overflow:hidden}.vt-hamburger-bottom,.vt-hamburger-middle,.vt-hamburger-top{left:0;position:absolute;width:22px;height:2px;background-color:var(--va-c-primary);transition:top .25s,background-color .5s,transform .25s}.vt-hamburger-top{top:0;transform:translate(0)}.vt-hamburger-middle{top:9px;transform:translate(-11px)}.vt-hamburger-bottom{top:18px;transform:translate(-5.5px)}.sidebar{position:fixed;overflow-y:auto;top:0;bottom:0;left:0;width:calc(100vw - 64px);max-width:var(--va-sidebar-width);background-image:var(--yun-sidebar-bg-img);background-color:var(--yun-sidebar-bg-color);background-size:contain;background-repeat:no-repeat;background-position:bottom 1rem center;text-align:center;z-index:var(--yun-z-sidebar);transform:translate(-100%);transition:box-shadow var(--va-transition-duration),background-color var(--va-transition-duration),opacity .25s,transform var(--va-transition-duration) cubic-bezier(.19,1,.22,1)!important}h1:focus .header-anchor,h1:hover .header-anchor,h2:focus .header-anchor,h2:hover .header-anchor,h3:focus .header-anchor,h3:hover .header-anchor{visibility:visible;opacity:1}a.header-anchor{float:left;margin-top:.125em;margin-left:-.87em;padding-right:.23em;font-size:.85em;visibility:hidden;opacity:0;transition:opacity var(--va-transition-duration)}a.header-anchor:before{content:none}a.header-anchor:focus,a.header-anchor:hover{text-decoration:none}:root{--va-aside-width:256px;--va-sidebar-width:300px;--va-border-width:1px;--va-font-serif:"Noto Serif SC",STZhongsong,STKaiti,KaiTi,Roboto,serif;--va-font-sans:Inter,-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,Oxygen,Ubuntu,Cantarell,"Fira Sans","Droid Sans","Helvetica Neue",sans-serif;--va-font-mono:Menlo,Monaco,Consolas,"Courier New",monospace;--va-transition-duration-fast:.2s;--va-transition-duration:.4s;--va-transition-duration-slow:.6s;--va-transition:all var(--va-transition-duration-fast) ease-in-out}:root{--va-c-white:#ffffff;--va-c-black:#1a1a1a;--va-c-gray:#8e8e8e;--va-c-danger:#db2828;--va-c-warning:#f2711c;--va-c-text-light-1:#213547;--va-c-text-light-2:rgba(60, 60, 60, .7);--va-c-text-light-3:rgba(60, 60, 60, .33);--va-c-text-light-4:rgba(60, 60, 60, .18);--va-c-text-dark-1:rgba(255, 255, 255, .87);--va-c-text-dark-2:rgba(235, 235, 235, .6);--va-c-text-dark-3:rgba(235, 235, 235, .38);--va-c-text-dark-4:rgba(235, 235, 235, .18);--va-c-primary-light:#359eff;--va-c-primary-lighter:#81c2ff;--va-c-primary-dark:#006bce;--va-c-primary:#0078E7}:root{color-scheme:light;--va-c-brand:#0078E7;--va-border-color:#222;--va-c-bg:white;--va-c-bg-light:white;--va-c-bg-dark:#fafafa;--va-c-bg-opacity:rgba(255, 255, 255, .8);--va-c-bg-soft:#f9f9f9;--va-c-bg-alt:#f9f9f9;--va-c-bg-mute:#f1f1f1;--va-c-text:#333;--va-c-text-light:#555;--va-c-text-lighter:#666;--va-c-text-dark:#111;--va-c-primary-rgb:0,120,231;--va-c-link:var(--va-c-primary-dark);--va-c-divider:rgba(60, 60, 60, .2)}:root{--va-code-line-height:1.7;--va-code-font-size:.875em;--va-code-block-color:var(--va-c-text-dark-1);--va-code-block-bg:#282c34;--va-code-line-highlight-color:rgba(0, 0, 0, .5);--va-code-line-number-color:var(--va-c-text-dark-3);--va-code-copy-code-hover-bg:rgba(255, 255, 255, .05);--va-code-copy-code-active-text:var(--va-c-text-dark-2)}:root{--va-icon-copy:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' fill='none' height='20' width='20' stroke='rgba(128,128,128,1)' stroke-width='2' class='h-6 w-6' viewBox='0 0 24 24'%3E%3Cpath stroke-linecap='round' stroke-linejoin='round' d='M9 5H7a2 2 0 0 0-2 2v12a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V7a2 2 0 0 0-2-2h-2M9 5a2 2 0 0 0 2 2h2a2 2 0 0 0 2-2M9 5a2 2 0 0 1 2-2h2a2 2 0 0 1 2 2'/%3E%3C/svg%3E");--va-icon-copied:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' fill='none' height='20' width='20' stroke='rgba(128,128,128,1)' stroke-width='2' class='h-6 w-6' viewBox='0 0 24 24'%3E%3Cpath stroke-linecap='round' stroke-linejoin='round' d='M9 5H7a2 2 0 0 0-2 2v12a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V7a2 2 0 0 0-2-2h-2M9 5a2 2 0 0 0 2 2h2a2 2 0 0 0 2-2M9 5a2 2 0 0 1 2-2h2a2 2 0 0 1 2 2m-6 9 2 2 4-4'/%3E%3C/svg%3E")}.post-category{color:var(--va-c-text)}.post-tag{white-space:nowrap;color:var(--yun-tag-color)}.post-tag:hover{color:var(--va-c-primary)}html{overflow-y:scroll}.yun-main{padding-left:var(--va-sidebar-width);transition:padding-left var(--va-transition-duration);box-sizing:border-box}.yun-icon-btn{cursor:pointer;display:inline-flex;align-items:center;justify-content:center;border:none;width:3rem;height:3rem;border-radius:50%;transition:background-color var(--va-transition-duration)}.yun-icon-btn div{font-size:1.2rem}.yun-icon-btn:hover{background-color:rgba(var(--va-c-primary-rgb),.08)}.yun-icon-btn:active{background-color:rgba(var(--va-c-primary-rgb),.16)}:root{--smc-font-sans:Raleway,-apple-system,"PingFang SC","Microsoft YaHei",Arial,sans-serif;--smc-font-serif:"Songti SC","Noto Serif SC",STZhongsong,STKaiti,KaiTi,Roboto,serif;--smc-font-mono:Menlo,Monaco,Consolas,"Courier New",monospace}:root{--smc-c-primary-light:#4eaaff;--smc-c-primary-lighter:#9bcfff;--smc-c-primary:#0078E7;--smc-theme-name:yun;--smc-line-height:1.8;--smc-c-primary-rgb:0,120,231;--smc-c-text:#24292e;--smc-c-text-light:#555;--smc-c-text-lighter:#666;--smc-header-bottom-color:#eaecef;--smc-border-color:var(--smc-c-primary-light);--smc-code-bg-color:#f6f8fa;--smc-link-color:#005eb4}.markdown-body{-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%;background:var(--smc-bg-color);color:var(--smc-c-text);font-family:var(--smc-font-sans);font-size:1rem;line-height:var(--smc-line-height);overflow-wrap:break-word}.markdown-body *{box-sizing:border-box}.markdown-body a{background-color:transparent}.markdown-body a:active,.markdown-body a:hover{outline-width:0}.markdown-body hr{background-color:var(--smc-c-primary,#333);height:2px;margin:1.5rem 0}.markdown-body blockquote{margin:1rem 0;padding:0 1rem;border-left:.25em solid var(--smc-border-color)}.markdown-body code,.markdown-body pre{font-family:Source Code Pro,Consolas,Monaco,SFMono-Regular,Ubuntu Mono,Menlo,monospace}.markdown-body code{padding:3px 6px;font-size:.85rem;color:var(--smc-c-text-light);background:var(--smc-code-bg-color);border-radius:3px}.markdown-body pre{margin-top:0;margin-bottom:0;overflow-wrap:normal;padding:1rem;overflow:auto;background-color:var(--smc-code-bg-color);border-radius:3px}.markdown-body pre>code{font-size:.85rem;white-space:pre}.markdown-body pre code{display:block;padding:0;margin:0;overflow:visible;line-height:inherit;word-break:normal;background-color:transparent;border:0}.markdown-body img{display:block;margin:1rem auto;max-width:92%;max-height:600px;border-radius:.2rem;transition:.4s;--tw-shadow:0 1px 3px 0 rgb(0 0 0/.1),0 1px 2px -1px rgb(0 0 0/.1);--tw-shadow-colored:0 1px 3px 0 var(--tw-shadow-color),0 1px 2px -1px var(--tw-shadow-color);-webkit-box-shadow:var(--tw-ring-offset-shadow,0 0 transparent),var(--tw-ring-shadow,0 0 transparent),var(--tw-shadow);box-shadow:var(--tw-ring-offset-shadow,0 0 transparent),var(--tw-ring-shadow,0 0 transparent),var(--tw-shadow)}.markdown-body img:hover{--tw-shadow:0 4px 6px -1px rgb(0 0 0/.1),0 2px 4px -2px rgb(0 0 0/.1);--tw-shadow-colored:0 4px 6px -1px var(--tw-shadow-color),0 2px 4px -2px var(--tw-shadow-color)}.markdown-body img:before{content:"「 LOADING ERROR 」"}@media screen and (min-width:1600px){.markdown-body img{max-width:800px}}.markdown-body a{color:var(--smc-c-primary);text-decoration:none;border-bottom:1px solid transparent;transition:all .2s ease-in-out}.markdown-body a:hover{color:var(--smc-link-color);border-bottom:1px solid var(--smc-link-color)}.markdown-body ol,.markdown-body ul{padding-left:2em}.markdown-body li{overflow-wrap:break-all;margin-top:.25em}.markdown-body li>p{margin-top:16px}.markdown-body table{width:100%;overflow:auto;border-spacing:0;border-collapse:collapse}.markdown-body table td,.markdown-body table th{padding:6px 13px;border:1px solid var(--smc-c-primary-light,#999)}.markdown-body table thead th{font-weight:600}.markdown-body table>tbody>tr:hover{background-color:rgba(var(--smc-c-primary-rgb),.1)}.markdown-body strong{font-family:var(--smc-font-serif);font-weight:900}.markdown-body p{margin-top:1rem;margin-bottom:1rem;overflow-x:auto;overflow-y:hidden}.markdown-body h1,.markdown-body h2,.markdown-body h3{margin-top:1.5rem;margin-bottom:1rem;font-weight:300;line-height:1.5}.markdown-body h1{font-size:2.5rem;border-bottom:1px solid var(--smc-header-bottom-color)}.markdown-body h2{font-size:2.2rem;border-bottom:1px solid var(--smc-header-bottom-color)}.markdown-body h3{font-size:1.9rem}@media screen and (max-width:768px){.markdown-body h1{font-size:2rem}.markdown-body h2{font-size:1.8rem}.markdown-body h3{font-size:1.6rem}}.markdown-body{--smc-font-family:var(--va-font-sans);--c-toc-link:var(--va-c-text-light)}.markdown-body{word-wrap:break-word}.markdown-body h1,.markdown-body h2,.markdown-body h3{font-family:var(--va-font-serif);font-weight:900}.markdown-body ul{list-style:initial}.markdown-body ul li>p{margin-bottom:0}.markdown-body ol li{list-style:decimal}.markdown-body img{margin:auto}.markdown-body p{overflow:unset}:root{--yun-post-card-max-width:900px;--yun-c-cloud:white;--yun-z-toc-btn:7;--yun-z-cloud:7;--yun-z-go-down:9;--yun-z-backdrop:9;--yun-z-sidebar:10;--yun-z-fireworks:11;--yun-z-menu-btn:20;--yun-z-go-up-btn:20;--yun-z-search-popup:30;--yun-z-search-btn:31;--va-z-overlay:var(--yun-z-backdrop)}:root{--yun-bg-img:url(https://cdn.yunyoujun.cn/img/bg/stars-timing-0-blur-30px.jpg);--yun-sidebar-bg-color:var(--va-c-bg-light);--yun-sidebar-bg-img:url(https://cdn.yunyoujun.cn/img/bg/alpha-stars-timing-1.webp)}:root{--va-font-serif:"Noto Serif SC",STZhongsong,STKaiti,KaiTi,Roboto,serif;--va-font-sans:Inter,-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,Oxygen,Ubuntu,Cantarell,"Fira Sans","Droid Sans","Helvetica Neue",sans-serif;--va-font-mono:Menlo,Monaco,Consolas,"Courier New",monospace}*,:after,:before{--un-rotate:0;--un-rotate-x:0;--un-rotate-y:0;--un-rotate-z:0;--un-scale-x:1;--un-scale-y:1;--un-scale-z:1;--un-skew-x:0;--un-skew-y:0;--un-translate-x:0;--un-translate-y:0;--un-translate-z:0;--un-scroll-snap-strictness:proximity;--un-border-spacing-x:0;--un-border-spacing-y:0;--un-ring-offset-shadow:0 0 rgba(0,0,0,0);--un-ring-shadow:0 0 rgba(0,0,0,0);--un-shadow:0 0 rgba(0,0,0,0);--un-ring-offset-width:0px;--un-ring-offset-color:#fff;--un-ring-width:0px;--un-ring-color:rgba(147,197,253,.5)}.i-ri-alipay-line{--un-icon:url("data:image/svg+xml;utf8,%3Csvg viewBox='0 0 24 24' width='1.2em' height='1.2em' xmlns='http://www.w3.org/2000/svg' %3E%3Cpath fill='currentColor' d='M18.408 16.79c-2.173-.95-3.72-1.646-4.64-2.086c-1.4 1.696-2.872 2.72-5.08 2.72S5 16.064 5.176 14.392c.12-1.096.872-2.888 4.128-2.576c1.72.16 2.504.48 3.912.944c.36-.664.664-1.4.888-2.176H7.88v-.616h3.072V8.864H7.2v-.68h3.752V6.592s.032-.248.312-.248H12.8v1.848h4v.68h-4v1.104h3.264a12.41 12.41 0 0 1-1.32 3.32c.51.182 2.097.676 4.76 1.482a8 8 0 1 0-1.096 2.012ZM12 22C6.477 22 2 17.523 2 12S6.477 2 12 2s10 4.477 10 10s-4.477 10-10 10Zm-3.568-5.632c1.44 0 2.824-.872 3.96-2.352c-1.608-.776-2.944-1.16-4.44-1.16c-1.304 0-1.984.8-2.104 1.416c-.12.616.248 2.096 2.584 2.096Z'/%3E%3C/svg%3E");-webkit-mask:var(--un-icon) no-repeat;mask:var(--un-icon) no-repeat;-webkit-mask-size:100% 100%;mask-size:100% 100%;background-color:currentColor;color:inherit;width:1.2em;height:1.2em}[i-ri-archive-line=""]{--un-icon:url("data:image/svg+xml;utf8,%3Csvg viewBox='0 0 24 24' width='1.2em' height='1.2em' xmlns='http://www.w3.org/2000/svg' %3E%3Cpath fill='currentColor' d='M3 10H2V4.003C2 3.449 2.455 3 2.992 3h18.016A.99.99 0 0 1 22 4.003V10h-1v10.002a.996.996 0 0 1-.993.998H3.993A.996.996 0 0 1 3 20.002V10Zm16 0H5v9h14v-9ZM4 5v3h16V5H4Zm5 7h6v2H9v-2Z'/%3E%3C/svg%3E");-webkit-mask:var(--un-icon) no-repeat;mask:var(--un-icon) no-repeat;-webkit-mask-size:100% 100%;mask-size:100% 100%;background-color:currentColor;color:inherit;width:1.2em;height:1.2em}[i-ri-arrow-left-s-line=""]{--un-icon:url("data:image/svg+xml;utf8,%3Csvg viewBox='0 0 24 24' width='1.2em' height='1.2em' xmlns='http://www.w3.org/2000/svg' %3E%3Cpath fill='currentColor' d='m10.828 12l4.95 4.95l-1.414 1.415L8 12l6.364-6.364l1.414 1.414l-4.95 4.95Z'/%3E%3C/svg%3E");-webkit-mask:var(--un-icon) no-repeat;mask:var(--un-icon) no-repeat;-webkit-mask-size:100% 100%;mask-size:100% 100%;background-color:currentColor;color:inherit;width:1.2em;height:1.2em}[i-ri-arrow-right-s-line=""]{--un-icon:url("data:image/svg+xml;utf8,%3Csvg viewBox='0 0 24 24' width='1.2em' height='1.2em' xmlns='http://www.w3.org/2000/svg' %3E%3Cpath fill='currentColor' d='m13.171 12l-4.95-4.95l1.415-1.413L16 12l-6.364 6.364l-1.414-1.415l4.95-4.95Z'/%3E%3C/svg%3E");-webkit-mask:var(--un-icon) no-repeat;mask:var(--un-icon) no-repeat;-webkit-mask-size:100% 100%;mask-size:100% 100%;background-color:currentColor;color:inherit;width:1.2em;height:1.2em}[i-ri-arrow-up-s-line=""]{--un-icon:url("data:image/svg+xml;utf8,%3Csvg viewBox='0 0 24 24' width='1.2em' height='1.2em' xmlns='http://www.w3.org/2000/svg' %3E%3Cpath fill='currentColor' d='m12 10.828l-4.95 4.95l-1.414-1.414L12 8l6.364 6.364l-1.415 1.414l-4.95-4.95Z'/%3E%3C/svg%3E");-webkit-mask:var(--un-icon) no-repeat;mask:var(--un-icon) no-repeat;-webkit-mask-size:100% 100%;mask-size:100% 100%;background-color:currentColor;color:inherit;width:1.2em;height:1.2em}[i-ri-calendar-2-line=""]{--un-icon:url("data:image/svg+xml;utf8,%3Csvg viewBox='0 0 24 24' width='1.2em' height='1.2em' xmlns='http://www.w3.org/2000/svg' %3E%3Cpath fill='currentColor' d='M9 1v2h6V1h2v2h4a1 1 0 0 1 1 1v16a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V4a1 1 0 0 1 1-1h4V1h2Zm11 10H4v8h16v-8ZM8 13v2H6v-2h2Zm5 0v2h-2v-2h2Zm5 0v2h-2v-2h2ZM7 5H4v4h16V5h-3v2h-2V5H9v2H7V5Z'/%3E%3C/svg%3E");-webkit-mask:var(--un-icon) no-repeat;mask:var(--un-icon) no-repeat;-webkit-mask-size:100% 100%;mask-size:100% 100%;background-color:currentColor;color:inherit;width:1.2em;height:1.2em}[i-ri-calendar-line=""]{--un-icon:url("data:image/svg+xml;utf8,%3Csvg viewBox='0 0 24 24' width='1.2em' height='1.2em' xmlns='http://www.w3.org/2000/svg' %3E%3Cpath fill='currentColor' d='M9 1v2h6V1h2v2h4a1 1 0 0 1 1 1v16a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V4a1 1 0 0 1 1-1h4V1h2Zm11 10H4v8h16v-8ZM7 5H4v4h16V5h-3v2h-2V5H9v2H7V5Z'/%3E%3C/svg%3E");-webkit-mask:var(--un-icon) no-repeat;mask:var(--un-icon) no-repeat;-webkit-mask-size:100% 100%;mask-size:100% 100%;background-color:currentColor;color:inherit;width:1.2em;height:1.2em}.i-ri-clipboard-line{--un-icon:url("data:image/svg+xml;utf8,%3Csvg viewBox='0 0 24 24' width='1.2em' height='1.2em' xmlns='http://www.w3.org/2000/svg' %3E%3Cpath fill='currentColor' d='M7 4V2h10v2h3.007c.548 0 .993.445.993.993v16.014a.994.994 0 0 1-.993.993H3.993A.993.993 0 0 1 3 21.007V4.993C3 4.445 3.445 4 3.993 4H7Zm0 2H5v14h14V6h-2v2H7V6Zm2-2v2h6V4H9Z'/%3E%3C/svg%3E");-webkit-mask:var(--un-icon) no-repeat;mask:var(--un-icon) no-repeat;-webkit-mask-size:100% 100%;mask-size:100% 100%;background-color:currentColor;color:inherit;width:1.2em;height:1.2em}.i-ri-cloud-line{--un-icon:url("data:image/svg+xml;utf8,%3Csvg viewBox='0 0 24 24' width='1.2em' height='1.2em' xmlns='http://www.w3.org/2000/svg' %3E%3Cpath fill='currentColor' d='M12 2a7 7 0 0 1 6.992 7.339A6 6 0 0 1 17 21H7A6 6 0 0 1 5.008 9.339A7 7 0 0 1 12 2Zm0 2a5 5 0 0 0-4.994 5.243l.07 1.488l-1.404.494A4.002 4.002 0 0 0 7 19h10a4 4 0 1 0-3.796-5.265l-1.898-.633A6.003 6.003 0 0 1 17 9a5 5 0 0 0-5-5Z'/%3E%3C/svg%3E");-webkit-mask:var(--un-icon) no-repeat;mask:var(--un-icon) no-repeat;-webkit-mask-size:100% 100%;mask-size:100% 100%;background-color:currentColor;color:inherit;width:1.2em;height:1.2em}.i-ri-download-cloud-2-fill{--un-icon:url("data:image/svg+xml;utf8,%3Csvg viewBox='0 0 24 24' width='1.2em' height='1.2em' xmlns='http://www.w3.org/2000/svg' %3E%3Cpath fill='currentColor' d='M13 13v5.585l1.828-1.828l1.415 1.415L12 22.414l-4.243-4.242l1.415-1.415L11 18.585V13h2ZM12 2a7.001 7.001 0 0 1 6.954 6.194A5.5 5.5 0 0 1 18 18.978V17a6 6 0 0 0-11.996-.225L6 17v1.978a5.5 5.5 0 0 1-.954-10.784A7 7 0 0 1 12 2Z'/%3E%3C/svg%3E");-webkit-mask:var(--un-icon) no-repeat;mask:var(--un-icon) no-repeat;-webkit-mask-size:100% 100%;mask-size:100% 100%;background-color:currentColor;color:inherit;width:1.2em;height:1.2em}[i-ri-file-list-line=""]{--un-icon:url("data:image/svg+xml;utf8,%3Csvg viewBox='0 0 24 24' width='1.2em' height='1.2em' xmlns='http://www.w3.org/2000/svg' %3E%3Cpath fill='currentColor' d='M20 22H4a1 1 0 0 1-1-1V3a1 1 0 0 1 1-1h16a1 1 0 0 1 1 1v18a1 1 0 0 1-1 1Zm-1-2V4H5v16h14ZM8 7h8v2H8V7Zm0 4h8v2H8v-2Zm0 4h8v2H8v-2Z'/%3E%3C/svg%3E");-webkit-mask:var(--un-icon) no-repeat;mask:var(--un-icon) no-repeat;-webkit-mask-size:100% 100%;mask-size:100% 100%;background-color:currentColor;color:inherit;width:1.2em;height:1.2em}[i-ri-file-word-line=""]{--un-icon:url("data:image/svg+xml;utf8,%3Csvg viewBox='0 0 24 24' width='1.2em' height='1.2em' xmlns='http://www.w3.org/2000/svg' %3E%3Cpath fill='currentColor' d='M16 8v8h-2l-2-2l-2 2H8V8h2v5l2-2l2 2V8h1V4H5v16h14V8h-3ZM3 2.992C3 2.444 3.447 2 3.998 2H16l5 5v13.992A1 1 0 0 1 20.007 22H3.993A1 1 0 0 1 3 21.008V2.992Z'/%3E%3C/svg%3E");-webkit-mask:var(--un-icon) no-repeat;mask:var(--un-icon) no-repeat;-webkit-mask-size:100% 100%;mask-size:100% 100%;background-color:currentColor;color:inherit;width:1.2em;height:1.2em}[i-ri-folder-2-line=""]{--un-icon:url("data:image/svg+xml;utf8,%3Csvg viewBox='0 0 24 24' width='1.2em' height='1.2em' xmlns='http://www.w3.org/2000/svg' %3E%3Cpath fill='currentColor' d='M12.414 5H21a1 1 0 0 1 1 1v14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V4a1 1 0 0 1 1-1h7.414l2 2ZM20 11H4v8h16v-8Zm0-2V7h-8.414l-2-2H4v4h16Z'/%3E%3C/svg%3E");-webkit-mask:var(--un-icon) no-repeat;mask:var(--un-icon) no-repeat;-webkit-mask-size:100% 100%;mask-size:100% 100%;background-color:currentColor;color:inherit;width:1.2em;height:1.2em}.i-ri-gamepad-line{--un-icon:url("data:image/svg+xml;utf8,%3Csvg viewBox='0 0 24 24' width='1.2em' height='1.2em' xmlns='http://www.w3.org/2000/svg' %3E%3Cpath fill='currentColor' d='M17 4a6 6 0 0 1 6 6v4a6 6 0 0 1-6 6H7a6 6 0 0 1-6-6v-4a6 6 0 0 1 6-6h10Zm0 2H7a4 4 0 0 0-3.995 3.8L3 10v4a4 4 0 0 0 3.8 3.995L7 18h10a4 4 0 0 0 3.995-3.8L21 14v-4a4 4 0 0 0-3.8-3.995L17 6Zm-7 3v2h2v2H9.999L10 15H8l-.001-2H6v-2h2V9h2Zm8 4v2h-2v-2h2Zm-2-4v2h-2V9h2Z'/%3E%3C/svg%3E");-webkit-mask:var(--un-icon) no-repeat;mask:var(--un-icon) no-repeat;-webkit-mask-size:100% 100%;mask-size:100% 100%;background-color:currentColor;color:inherit;width:1.2em;height:1.2em}.i-ri-genderless-line{--un-icon:url("data:image/svg+xml;utf8,%3Csvg viewBox='0 0 24 24' width='1.2em' height='1.2em' xmlns='http://www.w3.org/2000/svg' %3E%3Cpath fill='currentColor' d='M13 7.066A7.501 7.501 0 0 1 12 22a7.5 7.5 0 0 1-1-14.934V1h2v6.066ZM12 20a5.5 5.5 0 1 0 0-11a5.5 5.5 0 0 0 0 11Z'/%3E%3C/svg%3E");-webkit-mask:var(--un-icon) no-repeat;mask:var(--un-icon) no-repeat;-webkit-mask-size:100% 100%;mask-size:100% 100%;background-color:currentColor;color:inherit;width:1.2em;height:1.2em}.i-ri-github-line{--un-icon:url("data:image/svg+xml;utf8,%3Csvg viewBox='0 0 24 24' width='1.2em' height='1.2em' xmlns='http://www.w3.org/2000/svg' %3E%3Cpath fill='currentColor' d='M5.884 18.653c-.3-.2-.558-.456-.86-.816a50.59 50.59 0 0 1-.466-.579c-.463-.575-.755-.841-1.056-.95a1 1 0 1 1 .675-1.882c.752.27 1.261.735 1.947 1.588c-.094-.117.34.427.433.539c.19.227.33.365.44.438c.204.137.588.196 1.15.14c.024-.382.094-.753.202-1.096c-2.968-.725-4.648-2.64-4.648-6.396c0-1.238.37-2.355 1.058-3.291c-.218-.894-.185-1.975.302-3.192a1 1 0 0 1 .63-.583c.081-.024.127-.034.208-.047c.803-.123 1.937.17 3.415 1.097a11.731 11.731 0 0 1 2.687-.308c.912 0 1.819.103 2.684.308c1.477-.933 2.614-1.227 3.422-1.097c.085.014.158.032.218.051a1 1 0 0 1 .616.58c.487 1.215.52 2.296.302 3.19c.691.936 1.058 2.045 1.058 3.292c0 3.758-1.674 5.666-4.642 6.393c.125.415.19.878.19 1.38c0 .664-.002 1.299-.007 2.01c0 .19-.002.394-.005.706a1 1 0 0 1-.018 1.957c-1.14.228-1.984-.532-1.984-1.524l.002-.447l.005-.705c.005-.707.008-1.338.008-1.997c0-.697-.184-1.152-.426-1.361c-.661-.57-.326-1.654.541-1.751c2.966-.334 4.336-1.483 4.336-4.66c0-.955-.312-1.745-.913-2.405a1 1 0 0 1-.189-1.044c.166-.415.236-.957.095-1.614l-.01.002c-.491.14-1.11.44-1.858.95a1 1 0 0 1-.833.135a9.626 9.626 0 0 0-2.592-.35c-.89 0-1.772.12-2.592.35a1 1 0 0 1-.829-.133c-.753-.507-1.374-.807-1.87-.947c-.143.653-.072 1.194.093 1.607a1 1 0 0 1-.189 1.044c-.597.656-.913 1.459-.913 2.404c0 3.172 1.371 4.33 4.322 4.66c.865.098 1.202 1.178.545 1.749c-.193.167-.43.732-.43 1.364v3.149c0 .986-.834 1.726-1.96 1.529a1 1 0 0 1-.04-1.963v-.99c-.91.062-1.661-.087-2.254-.484Z'/%3E%3C/svg%3E");-webkit-mask:var(--un-icon) no-repeat;mask:var(--un-icon) no-repeat;-webkit-mask-size:100% 100%;mask-size:100% 100%;background-color:currentColor;color:inherit;width:1.2em;height:1.2em}[i-ri-heart-line=""]{--un-icon:url("data:image/svg+xml;utf8,%3Csvg viewBox='0 0 24 24' width='1.2em' height='1.2em' xmlns='http://www.w3.org/2000/svg' %3E%3Cpath fill='currentColor' d='M12.001 4.529a5.998 5.998 0 0 1 8.242.228a6 6 0 0 1 .236 8.236l-8.48 8.492l-8.478-8.492a6 6 0 0 1 8.48-8.464Zm6.826 1.641a3.998 3.998 0 0 0-5.49-.153l-1.335 1.198l-1.336-1.197a4 4 0 0 0-5.686 5.605L12 18.654l7.02-7.03a4 4 0 0 0-.193-5.454Z'/%3E%3C/svg%3E");-webkit-mask:var(--un-icon) no-repeat;mask:var(--un-icon) no-repeat;-webkit-mask-size:100% 100%;mask-size:100% 100%;background-color:currentColor;color:inherit;width:1.2em;height:1.2em}[i-ri-home-4-line=""]{--un-icon:url("data:image/svg+xml;utf8,%3Csvg viewBox='0 0 24 24' width='1.2em' height='1.2em' xmlns='http://www.w3.org/2000/svg' %3E%3Cpath fill='currentColor' d='M19 21H5a1 1 0 0 1-1-1v-9H1l10.327-9.388a1 1 0 0 1 1.346 0L23 11h-3v9a1 1 0 0 1-1 1Zm-6-2h5V9.158l-6-5.455l-6 5.455V19h5v-6h2v6Z'/%3E%3C/svg%3E");-webkit-mask:var(--un-icon) no-repeat;mask:var(--un-icon) no-repeat;-webkit-mask-size:100% 100%;mask-size:100% 100%;background-color:currentColor;color:inherit;width:1.2em;height:1.2em}.i-ri-mail-line{--un-icon:url("data:image/svg+xml;utf8,%3Csvg viewBox='0 0 24 24' width='1.2em' height='1.2em' xmlns='http://www.w3.org/2000/svg' %3E%3Cpath fill='currentColor' d='M3 3h18a1 1 0 0 1 1 1v16a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V4a1 1 0 0 1 1-1Zm17 4.238l-7.928 7.1L4 7.216V19h16V7.238ZM4.511 5l7.55 6.662L19.502 5H4.511Z'/%3E%3C/svg%3E");-webkit-mask:var(--un-icon) no-repeat;mask:var(--un-icon) no-repeat;-webkit-mask-size:100% 100%;mask-size:100% 100%;background-color:currentColor;color:inherit;width:1.2em;height:1.2em}.i-ri-money-cny-circle-line{--un-icon:url("data:image/svg+xml;utf8,%3Csvg viewBox='0 0 24 24' width='1.2em' height='1.2em' xmlns='http://www.w3.org/2000/svg' %3E%3Cpath fill='currentColor' d='M12.005 22.003c-5.523 0-10-4.477-10-10s4.477-10 10-10s10 4.477 10 10s-4.477 10-10 10Zm0-2a8 8 0 1 0 0-16a8 8 0 0 0 0 16Zm1-7h3v2h-3v2h-2v-2h-3v-2h3v-1h-3v-2h2.586L8.469 7.882l1.415-1.415l2.12 2.122l2.122-2.122l1.414 1.415l-2.12 2.12h2.585v2h-3v1Z'/%3E%3C/svg%3E");-webkit-mask:var(--un-icon) no-repeat;mask:var(--un-icon) no-repeat;-webkit-mask-size:100% 100%;mask-size:100% 100%;background-color:currentColor;color:inherit;width:1.2em;height:1.2em}[i-ri-price-tag-3-line=""]{--un-icon:url("data:image/svg+xml;utf8,%3Csvg viewBox='0 0 24 24' width='1.2em' height='1.2em' xmlns='http://www.w3.org/2000/svg' %3E%3Cpath fill='currentColor' d='m10.904 2.1l9.9 1.414l1.414 9.9l-9.193 9.192a1 1 0 0 1-1.414 0l-9.9-9.9a1 1 0 0 1 0-1.413L10.905 2.1Zm.707 2.121L3.833 12l8.485 8.485l7.779-7.778l-1.061-7.425l-7.425-1.06Zm2.122 6.364a2 2 0 1 1 2.828-2.828a2 2 0 0 1-2.828 2.828Z'/%3E%3C/svg%3E");-webkit-mask:var(--un-icon) no-repeat;mask:var(--un-icon) no-repeat;-webkit-mask-size:100% 100%;mask-size:100% 100%;background-color:currentColor;color:inherit;width:1.2em;height:1.2em}.i-ri-qq-line{--un-icon:url("data:image/svg+xml;utf8,%3Csvg viewBox='0 0 24 24' width='1.2em' height='1.2em' xmlns='http://www.w3.org/2000/svg' %3E%3Cpath fill='currentColor' d='m17.536 12.514l-.696-1.796c0-.021.01-.375.01-.558C16.85 7.088 15.447 4 12 4c-3.446 0-4.848 3.088-4.848 6.16c0 .183.009.537.01.557l-.696 1.797c-.19.514-.38 1.05-.517 1.51c-.657 2.189-.444 3.095-.282 3.115c.348.043 1.354-1.648 1.354-1.648c0 .98.487 2.258 1.542 3.18c-.394.127-.878.32-1.188.557c-.28.214-.245.431-.194.52c.22.385 3.79.245 4.82.125c1.03.12 4.599.26 4.82-.126c.05-.088.085-.305-.194-.519c-.311-.237-.795-.43-1.19-.556c1.055-.923 1.542-2.202 1.542-3.181c0 0 1.007 1.691 1.355 1.648c.162-.02.378-.928-.283-3.116a26.91 26.91 0 0 0-.516-1.509Zm1.021 8.227c-.373.652-.833.892-1.438 1.057a4.91 4.91 0 0 1-.794.138c-.44.045-.986.065-1.613.064a33.217 33.217 0 0 1-2.71-.116c-.692.065-1.785.114-2.71.116a16.048 16.048 0 0 1-1.614-.064a4.917 4.917 0 0 1-.793-.138c-.605-.164-1.065-.405-1.44-1.059a2.274 2.274 0 0 1-.239-1.652c-.592-.132-1.001-.482-1.279-.911a2.43 2.43 0 0 1-.309-.71a4.027 4.027 0 0 1-.116-1.106c.013-.785.187-1.762.532-2.912c.14-.466.327-1.008.567-1.655l.554-1.43a15.362 15.362 0 0 1-.002-.203C5.153 5.605 7.589 2 12 2c4.413 0 6.848 3.605 6.848 8.16l-.001.203l.553 1.43l.01.026c.225.606.413 1.153.556 1.626c.348 1.15.522 2.128.535 2.916c.007.407-.03.776-.118 1.108c-.066.246-.161.48-.31.708c-.276.427-.684.776-1.277.91c.13.554.055 1.14-.24 1.654Z'/%3E%3C/svg%3E");-webkit-mask:var(--un-icon) no-repeat;mask:var(--un-icon) no-repeat;-webkit-mask-size:100% 100%;mask-size:100% 100%;background-color:currentColor;color:inherit;width:1.2em;height:1.2em}.i-ri-speaker-fill{--un-icon:url("data:image/svg+xml;utf8,%3Csvg viewBox='0 0 24 24' width='1.2em' height='1.2em' xmlns='http://www.w3.org/2000/svg' %3E%3Cpath fill='currentColor' d='M4 2h16a1 1 0 0 1 1 1v18a1 1 0 0 1-1 1H4a1 1 0 0 1-1-1V3a1 1 0 0 1 1-1Zm8 18a5 5 0 1 0 0-10a5 5 0 0 0 0 10Zm0-12a1.5 1.5 0 1 0 0-3a1.5 1.5 0 0 0 0 3Zm0 10a3 3 0 1 1 0-6a3 3 0 0 1 0 6Z'/%3E%3C/svg%3E");-webkit-mask:var(--un-icon) no-repeat;mask:var(--un-icon) no-repeat;-webkit-mask-size:100% 100%;mask-size:100% 100%;background-color:currentColor;color:inherit;width:1.2em;height:1.2em}[i-ri-timer-line=""]{--un-icon:url("data:image/svg+xml;utf8,%3Csvg viewBox='0 0 24 24' width='1.2em' height='1.2em' xmlns='http://www.w3.org/2000/svg' %3E%3Cpath fill='currentColor' d='m17.618 5.968l1.453-1.453l1.414 1.414l-1.453 1.453A9 9 0 1 1 12 4c2.125 0 4.078.736 5.618 1.968ZM12 20a7 7 0 1 0 0-14a7 7 0 0 0 0 14ZM11 8h2v6h-2V8ZM8 1h8v2H8V1Z'/%3E%3C/svg%3E");-webkit-mask:var(--un-icon) no-repeat;mask:var(--un-icon) no-repeat;-webkit-mask-size:100% 100%;mask-size:100% 100%;background-color:currentColor;color:inherit;width:1.2em;height:1.2em}[i-ri-translate=""]{--un-icon:url("data:image/svg+xml;utf8,%3Csvg viewBox='0 0 24 24' width='1.2em' height='1.2em' xmlns='http://www.w3.org/2000/svg' %3E%3Cpath fill='currentColor' d='M5 15v2a2 2 0 0 0 1.85 1.994L7 19h3v2H7a4 4 0 0 1-4-4v-2h2Zm13-5l4.4 11h-2.155l-1.201-3h-4.09l-1.199 3h-2.154L16 10h2Zm-1 2.885L15.753 16h2.492L17 12.885ZM8 2v2h4v7H8v3H6v-3H2V4h4V2h2Zm9 1a4 4 0 0 1 4 4v2h-2V7a2 2 0 0 0-2-2h-3V3h3ZM6 6H4v3h2V6Zm4 0H8v3h2V6Z'/%3E%3C/svg%3E");-webkit-mask:var(--un-icon) no-repeat;mask:var(--un-icon) no-repeat;-webkit-mask-size:100% 100%;mask-size:100% 100%;background-color:currentColor;color:inherit;width:1.2em;height:1.2em}.i-ri-wechat-2-line{--un-icon:url("data:image/svg+xml;utf8,%3Csvg viewBox='0 0 24 24' width='1.2em' height='1.2em' xmlns='http://www.w3.org/2000/svg' %3E%3Cpath fill='currentColor' d='M8.667 11.512a1.276 1.276 0 0 1-1.285-1.286c0-.718.568-1.286 1.285-1.286c.718 0 1.285.568 1.285 1.286c0 .717-.567 1.286-1.285 1.286Zm6.667 0a1.276 1.276 0 0 1-1.285-1.286c0-.718.568-1.286 1.285-1.286s1.285.568 1.285 1.286c0 .717-.568 1.286-1.285 1.286Zm-8.511 7.704l.715-.437a4 4 0 0 1 2.706-.536c.211.033.385.059.52.077c.406.053.819.08 1.237.08c4.42 0 7.9-3.022 7.9-6.6c0-3.577-3.48-6.6-7.9-6.6c-4.421 0-7.9 3.023-7.9 6.6c0 1.366.5 2.673 1.431 3.781c.049.058.12.137.215.235a4 4 0 0 1 1.1 3.102l-.024.298Zm-.63 2.726a1 1 0 0 1-1.527-.93l.189-2.26a2 2 0 0 0-.55-1.551a6.935 6.935 0 0 1-.303-.332C2.806 15.447 2.1 13.695 2.1 11.8c0-4.75 4.432-8.6 9.9-8.6c5.467 0 9.9 3.85 9.9 8.6s-4.433 8.6-9.9 8.6c-.51 0-1.01-.033-1.5-.098c-.152-.02-.342-.048-.568-.084a2 2 0 0 0-1.353.269l-2.387 1.456Z'/%3E%3C/svg%3E");-webkit-mask:var(--un-icon) no-repeat;mask:var(--un-icon) no-repeat;-webkit-mask-size:100% 100%;mask-size:100% 100%;background-color:currentColor;color:inherit;width:1.2em;height:1.2em}.i-ri-wechat-pay-line{--un-icon:url("data:image/svg+xml;utf8,%3Csvg viewBox='0 0 24 24' width='1.2em' height='1.2em' xmlns='http://www.w3.org/2000/svg' %3E%3Cpath fill='currentColor' d='m19.146 8.993l-9.799 5.608l-.07.046a.647.647 0 0 1-.3.069a.655.655 0 0 1-.58-.345l-.046-.092l-1.831-3.95c-.023-.046-.023-.092-.023-.138c0-.183.139-.321.324-.321c.07 0 .139.023.209.069l2.155 1.515c.162.092.347.161.556.161a.938.938 0 0 0 .348-.069l8.274-3.648C16.935 6.273 14.635 5.2 12.001 5.2c-4.421 0-7.9 3.023-7.9 6.6c0 1.366.5 2.673 1.431 3.781c.049.058.12.137.215.235a4 4 0 0 1 1.1 3.102l-.024.298l.715-.437a4 4 0 0 1 2.706-.536c.211.033.385.059.52.077c.406.053.819.08 1.237.08c4.42 0 7.9-3.022 7.9-6.6c0-.996-.27-1.95-.755-2.807ZM6.193 21.943a1 1 0 0 1-1.527-.931l.189-2.26a2 2 0 0 0-.55-1.551a6.935 6.935 0 0 1-.303-.332C2.806 15.447 2.1 13.695 2.1 11.8c0-4.75 4.432-8.6 9.9-8.6c5.467 0 9.9 3.85 9.9 8.6s-4.433 8.6-9.9 8.6c-.51 0-1.01-.033-1.5-.098c-.152-.02-.342-.048-.568-.084a2 2 0 0 0-1.353.269l-2.387 1.456Z'/%3E%3C/svg%3E");-webkit-mask:var(--un-icon) no-repeat;mask:var(--un-icon) no-repeat;-webkit-mask-size:100% 100%;mask-size:100% 100%;background-color:currentColor;color:inherit;width:1.2em;height:1.2em}.i-ri-women-line{--un-icon:url("data:image/svg+xml;utf8,%3Csvg viewBox='0 0 24 24' width='1.2em' height='1.2em' xmlns='http://www.w3.org/2000/svg' %3E%3Cpath fill='currentColor' d='M11 15.934A7.501 7.501 0 0 1 12 1a7.5 7.5 0 0 1 1 14.934V18h5v2h-5v4h-2v-4H6v-2h5v-2.066ZM12 14a5.5 5.5 0 1 0 0-11a5.5 5.5 0 0 0 0 11Z'/%3E%3C/svg%3E");-webkit-mask:var(--un-icon) no-repeat;mask:var(--un-icon) no-repeat;-webkit-mask-size:100% 100%;mask-size:100% 100%;background-color:currentColor;color:inherit;width:1.2em;height:1.2em}[i~=ri-sun-line]{--un-icon:url("data:image/svg+xml;utf8,%3Csvg viewBox='0 0 24 24' width='1.2em' height='1.2em' xmlns='http://www.w3.org/2000/svg' %3E%3Cpath fill='currentColor' d='M12 18a6 6 0 1 1 0-12a6 6 0 0 1 0 12Zm0-2a4 4 0 1 0 0-8a4 4 0 0 0 0 8ZM11 1h2v3h-2V1Zm0 19h2v3h-2v-3ZM3.515 4.929l1.414-1.414L7.05 5.636L5.636 7.05L3.515 4.93ZM16.95 18.364l1.414-1.414l2.121 2.121l-1.414 1.414l-2.121-2.121Zm2.121-14.85l1.414 1.415l-2.121 2.121l-1.414-1.414l2.121-2.121ZM5.636 16.95l1.414 1.414l-2.121 2.121l-1.414-1.414l2.121-2.121ZM23 11v2h-3v-2h3ZM4 11v2H1v-2h3Z'/%3E%3C/svg%3E");-webkit-mask:var(--un-icon) no-repeat;mask:var(--un-icon) no-repeat;-webkit-mask-size:100% 100%;mask-size:100% 100%;background-color:currentColor;color:inherit;width:1.2em;height:1.2em}.yun-card{margin:auto;--un-shadow:var(--un-shadow-inset) 0 1px 3px 0 var(--un-shadow-color, rgba(0,0,0,.1)),var(--un-shadow-inset) 0 1px 2px -1px var(--un-shadow-color, rgba(0,0,0,.1));box-shadow:var(--un-ring-offset-shadow),var(--un-ring-shadow),var(--un-shadow);transition-property:color,background-color,border-color,outline-color,text-decoration-color,fill,stroke,opacity,box-shadow,transform,filter,backdrop-filter;transition-timing-function:cubic-bezier(.4,0,.2,1);transition-duration:.15s;transition-duration:var(--va-transition-duration)}.va-card{--un-shadow:var(--un-shadow-inset) 0 1px 3px 0 var(--un-shadow-color, rgba(0,0,0,.1)),var(--un-shadow-inset) 0 1px 2px -1px var(--un-shadow-color, rgba(0,0,0,.1));box-shadow:var(--un-ring-offset-shadow),var(--un-ring-shadow),var(--un-shadow)}.va-card:hover,.yun-card:hover{--un-shadow:var(--un-shadow-inset) 0 10px 15px -3px var(--un-shadow-color, rgba(0,0,0,.1)),var(--un-shadow-inset) 0 4px 6px -4px var(--un-shadow-color, rgba(0,0,0,.1));box-shadow:var(--un-ring-offset-shadow),var(--un-ring-shadow),var(--un-shadow)}@media (max-width:767.9px){.yun-main{padding-left:0}}.fixed{position:fixed}.relative{position:relative}[bottom~="19"]{bottom:4.75rem}[right~="2"]{right:.5rem}.z-1{z-index:1}.z-350{z-index:350}[m~="0"]{margin:0}[m~="2"]{margin:.5rem}[m~=y-4]{margin-top:1rem;margin-bottom:1rem}.my-1{margin-top:.25rem;margin-bottom:.25rem}[m~=x-1]{margin-left:.25rem;margin-right:.25rem}[mx~="2"],[m~=x-2]{margin-left:.5rem;margin-right:.5rem}[m~=y-2]{margin-top:.5rem;margin-bottom:.5rem}[mb~="4"]{margin-bottom:1rem}.mb-2,[m~=b-2]{margin-bottom:.5rem}[m~=l-1]{margin-left:.25rem}[m~=t-4]{margin-top:1rem}[mt-6=""],[m~=t-6]{margin-top:1.5rem}[m~=l-4]{margin-left:1rem}[m~=r-1]{margin-right:.25rem}[mt~="2"]{margin-top:.5rem}.block{display:block}.inline-block{display:inline-block}[h~="8"]{height:2rem}[w~="8"]{width:2rem}[w~=full]{width:100%}.flex,[flex~="~"]{display:flex}.inline-flex,[inline-flex=""]{display:inline-flex}.flex-grow,[flex~=grow]{flex-grow:1}.flex-col,[flex~=col]{flex-direction:column}.transform{transform:translate(var(--un-translate-x)) translateY(var(--un-translate-y)) translateZ(var(--un-translate-z)) rotate(var(--un-rotate)) rotateX(var(--un-rotate-x)) rotateY(var(--un-rotate-y)) rotate(var(--un-rotate-z)) skew(var(--un-skew-x)) skewY(var(--un-skew-y)) scaleX(var(--un-scale-x)) scaleY(var(--un-scale-y)) scaleZ(var(--un-scale-z))}@keyframes fade-in{0%{opacity:0}to{opacity:1}}@keyframes pulse{0%,to{opacity:1}50%{opacity:.5}}.animate-fade-in{animation:fade-in 1s linear 1}.animate-pulse{animation:pulse 2s cubic-bezier(.4,0,.6,1) infinite}.animate-iteration-1{animation-iteration-count:1}.items-center,[items~=center]{align-items:center}.justify-center,[justify~=center]{justify-content:center}.justify-around{justify-content:space-around}.gap-2{grid-gap:.5rem;gap:.5rem}[overflow~=auto]{overflow:auto}.truncate{overflow:hidden;text-overflow:ellipsis;white-space:nowrap}[border~="~"]{border-width:1px}[border~=rounded]{border-radius:.25rem}.rounded-full{border-radius:9999px}[stroke-width~="2"]{stroke-width:2px}.p-4,[p~="4"]{padding:1rem}[p~="1"]{padding:.25rem}[p~="2"]{padding:.5rem}[p~=x-4]{padding-left:1rem;padding-right:1rem}[py~="1"]{padding-top:.25rem;padding-bottom:.25rem}[p~=b-8]{padding-bottom:2rem}[p~=l-4]{padding-left:1rem}[text~=center]{text-align:center}[text~="2xl"]{font-size:1.5rem;line-height:2rem}[text-xl=""],[text~=xl]{font-size:1.25rem;line-height:1.75rem}[text~=xs]{font-size:.75rem;line-height:1rem}[text~=sm]{font-size:.875rem;line-height:1.25rem}[font~=black]{font-weight:900}.leading-none{line-height:1}.text-\$va-c-text-light{color:var(--va-c-text-light)}[text~=red-400]{--un-text-opacity:1;color:rgba(248,113,113,var(--un-text-opacity))}.hover\:shadow-md:hover{--un-shadow:var(--un-shadow-inset) 0 4px 6px -1px var(--un-shadow-color, rgba(0,0,0,.1)),var(--un-shadow-inset) 0 2px 4px -2px var(--un-shadow-color, rgba(0,0,0,.1));box-shadow:var(--un-ring-offset-shadow),var(--un-ring-shadow),var(--un-shadow)}.shadow{--un-shadow:var(--un-shadow-inset) 0 1px 3px 0 var(--un-shadow-color, rgba(0,0,0,.1)),var(--un-shadow-inset) 0 1px 2px -1px var(--un-shadow-color, rgba(0,0,0,.1));box-shadow:var(--un-ring-offset-shadow),var(--un-ring-shadow),var(--un-shadow)}.transition{transition-property:color,background-color,border-color,outline-color,text-decoration-color,fill,stroke,opacity,box-shadow,transform,filter,backdrop-filter;transition-timing-function:cubic-bezier(.4,0,.2,1);transition-duration:.15s}[font~=serif]{font-family:var(--va-font-serif)}@media (max-width:767.9px){.lt-md\:ml-0{margin-left:0}[p~="lt-md:0"]{padding:0}}@media (min-width:640px){.sm\:p-6{padding:1.5rem}.sm\:px-6{padding-left:1.5rem;padding-right:1.5rem}}@media (min-width:768px){.md\:hidden{display:none}.md\:translate-x-0{--un-translate-x:0;transform:translate(var(--un-translate-x)) translateY(var(--un-translate-y)) translateZ(var(--un-translate-z)) rotate(var(--un-rotate)) rotateX(var(--un-rotate-x)) rotateY(var(--un-rotate-y)) rotate(var(--un-rotate-z)) skew(var(--un-skew-x)) skewY(var(--un-skew-y)) scaleX(var(--un-scale-x)) scaleY(var(--un-scale-y)) scaleZ(var(--un-scale-z))}}@media (min-width:1024px){.lg\:px-12{padding-left:3rem;padding-right:3rem}}@media (min-width:1280px){.xl\:hidden{display:none}.xl\:px-16{padding-left:4rem;padding-right:4rem}}.post-copyright{font-size:.9rem;padding:.5rem 1rem;border-left:4px solid #ff5252;background-color:var(--va-c-bg-dark);list-style:none;word-break:break-all;position:relative;overflow:hidden}.post-copyright:after{pointer-events:none;position:absolute;color:#fff;background:url("data:image/svg+xml;charset=utf-8,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 496 512'%3E%3Cpath fill='gray' d='M245.8 214.9l-33.2 17.3c-9.4-19.6-25.2-20-27.4-20-22.2 0-33.3 14.6-33.3 43.9 0 23.5 9.2 43.8 33.3 43.8 14.4 0 24.6-7 30.5-21.3l30.6 15.5a73.2 73.2 0 01-65.1 39c-22.6 0-74-10.3-74-77 0-58.7 43-77 72.6-77 30.8-.1 52.7 11.9 66 35.8zm143 0l-32.7 17.3c-9.5-19.8-25.7-20-27.9-20-22.1 0-33.2 14.6-33.2 43.9 0 23.5 9.2 43.8 33.2 43.8 14.5 0 24.7-7 30.5-21.3l31 15.5c-2 3.8-21.3 39-65 39-22.7 0-74-9.9-74-77 0-58.7 43-77 72.6-77C354 179 376 191 389 214.8zM247.7 8C104.7 8 0 123 0 256c0 138.4 113.6 248 247.6 248C377.5 504 496 403 496 256 496 118 389.4 8 247.6 8zm.8 450.8c-112.5 0-203.7-93-203.7-202.8 0-105.5 85.5-203.3 203.8-203.3A201.7 201.7 0 01451.3 256c0 121.7-99.7 202.9-202.9 202.9z'/%3E%3C/svg%3E");content:" ";height:10rem;width:10rem;right:-2rem;top:-2rem;opacity:.1}.sponsor-button{background-color:#ffffff1a}.sponsor-button div{transform:scale(1.1);transition:transform var(--va-transition-duration) ease-in-out}.sponsor-button:hover{background-color:#ffffffe6}.sponsor-button:hover div{transform:scale(1.2)}.qrcode-container{overflow:hidden;height:0;transition:height var(--va-transition-duration) ease-in-out}.sponsor-description{color:var(--va-c-gray)}.sponsor-method-img{width:12rem;max-width:90%;aspect-ratio:1}.va-toc[data-v-e1350763]{text-align:left}.content[data-v-e1350763]{position:relative;padding-left:16px;font-size:14px;text-align:left}.outline-marker[data-v-e1350763]{position:absolute;top:32px;left:-2px;z-index:0;opacity:0;width:4px;height:18px;background-color:var(--va-c-brand);transition:top .25s cubic-bezier(0,1,.5,1),background-color .5s,opacity .25s;border-top-right-radius:2px;border-bottom-right-radius:2px}.outline-title[data-v-e1350763]{letter-spacing:.4px;line-height:28px;font-size:14px;font-weight:600}.visually-hidden[data-v-e1350763]{position:absolute;width:1px;height:1px;white-space:nowrap;clip:rect(0 0 0 0);clip-path:inset(50%);overflow:hidden}.yun-aside{position:fixed;right:0;top:0;bottom:0;width:var(--va-sidebar-width,300px);transform:translate(100%);transition:box-shadow var(--va-transition-duration),background-color var(--va-transition-duration),opacity .25s,transform var(--va-transition-duration) cubic-bezier(.19,1,.22,1)}@media screen and (min-width:1280px){.yun-aside{transform:translate(0)}}.toc-btn{color:var(--va-c-primary);background-color:#fff;z-index:var(--yun-z-toc-btn)}.post-nav{display:flex;justify-content:space-between;align-items:center}.post-nav-item{display:inline-flex;justify-content:center;align-items:center;color:var(--va-c-primary);outline:0;font-size:1.5rem;font-weight:700;text-transform:uppercase;height:3rem;transition:.4s}.post-nav-item:hover{background-color:rgba(var(--va-c-primary-rgb),.1);box-shadow:0 0 15px #0000001a}.post-nav-prev{padding:0 .6rem 0 .1rem}.post-nav-next{padding:0 .1rem 0 .6rem}.post-nav-next,.post-nav-prev{display:inline-flex;align-items:center;height:3rem;font-size:1rem}.post-nav-next .title,.post-nav-prev .title{overflow:hidden;max-width:10rem}.post-nav-next .icon,.post-nav-prev .icon{width:1.2rem;height:1.2rem}@media screen and (min-width:1024px){.post-nav-next .title,.post-nav-prev .title{max-width:18rem}}@media screen and (min-width:1280px){.content{max-width:calc(100vw - 2 * var(--va-sidebar-width) - 1rem - 8px)}}</style><link rel="preload" href="/assets/index-c2c57308.css" as="style"><link rel="modulepreload" crossorigin="" href="/assets/post-e5041dfe.js"><link rel="preload" href="/assets/post-b195884f.css" as="style"><link rel="modulepreload" crossorigin="" href="/assets/K8S(kubernetes)实践认知-8a4e965a.js"><link rel="modulepreload" crossorigin="" href="/assets/ValaxyMain.vue_vue_type_style_index_0_lang-1c76cb4e.js"><link rel="preload" href="/assets/ValaxyMain-3beb7542.css" as="style"><title>K8S(kubernetes)实践认知 - 运维之境</title><link rel="icon" href="/favicon.svg" type="image/svg+xml"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#ffffff"><meta name="generator" content="Valaxy 0.14.28"><meta name="description" content="那你终将成为别人的一条裤衩"><meta property="og:description" content="那你终将成为别人的一条裤衩"><meta property="og:locale" content="zh-CN"><meta property="og:site_name" content="运维之境"><meta property="og:title" content="K8S(kubernetes)实践认知"><meta property="og:image" content="/favicon.svg"><meta property="og:url" content="https://www.vlinux.cn/"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@900&amp;display=swap"><link rel="preload" as="font" crossorigin="anonymous" href="/assets/KaTeX_AMS-Regular-0cdd387c.woff2"><link rel="preload" as="font" crossorigin="anonymous" href="/assets/KaTeX_Caligraphic-Bold-de7701e4.woff2"><link rel="preload" as="font" crossorigin="anonymous" href="/assets/KaTeX_Caligraphic-Regular-5d53e70a.woff2"><link rel="preload" as="font" crossorigin="anonymous" href="/assets/KaTeX_Fraktur-Bold-74444efd.woff2"><link rel="preload" as="font" crossorigin="anonymous" href="/assets/KaTeX_Fraktur-Regular-51814d27.woff2"><link rel="preload" as="font" crossorigin="anonymous" href="/assets/KaTeX_Main-Bold-0f60d1b8.woff2"><link rel="preload" as="font" crossorigin="anonymous" href="/assets/KaTeX_Main-BoldItalic-99cd42a3.woff2"><link rel="preload" as="font" crossorigin="anonymous" href="/assets/KaTeX_Main-Italic-97479ca6.woff2"><link rel="preload" as="font" crossorigin="anonymous" href="/assets/KaTeX_Main-Regular-c2342cd8.woff2"><link rel="preload" as="font" crossorigin="anonymous" href="/assets/KaTeX_Math-BoldItalic-dc47344d.woff2"><link rel="preload" as="font" crossorigin="anonymous" href="/assets/KaTeX_Math-Italic-7af58c5e.woff2"><link rel="preload" as="font" crossorigin="anonymous" href="/assets/KaTeX_SansSerif-Bold-e99ae511.woff2"><link rel="preload" as="font" crossorigin="anonymous" href="/assets/KaTeX_SansSerif-Italic-00b26ac8.woff2"><link rel="preload" as="font" crossorigin="anonymous" href="/assets/KaTeX_SansSerif-Regular-68e8c73e.woff2"><link rel="preload" as="font" crossorigin="anonymous" href="/assets/KaTeX_Script-Regular-036d4e95.woff2"><link rel="preload" as="font" crossorigin="anonymous" href="/assets/KaTeX_Size1-Regular-6b47c401.woff2"><link rel="preload" as="font" crossorigin="anonymous" href="/assets/KaTeX_Size2-Regular-d04c5421.woff2"><link rel="preload" as="font" crossorigin="anonymous" href="data:font/woff2;base64,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"><link rel="preload" as="font" crossorigin="anonymous" href="/assets/KaTeX_Size4-Regular-a4af7d41.woff2"><link rel="preload" as="font" crossorigin="anonymous" href="/assets/KaTeX_Typewriter-Regular-71d517d6.woff2"></head><body><div id="app" data-server-rendered="true"><!--[--><!--[--><canvas class="fireworks"></canvas><!--[--><div class="va-bg"></div><!--]--><!----><!--]--><!--[--><!--]--><!----><!--[--><!--[--><!----><button type="button" class="vt-hamburger menu-btn sidebar-toggle yun-icon-btn md:hidden" aria-label="mobile navigation" aria-expanded="false"><span class="vt-hamburger-container"><span class="vt-hamburger-top"></span><span class="vt-hamburger-middle"></span><span class="vt-hamburger-bottom"></span></span></button><aside class="md:translate-x-0 va-card transition sidebar"><!--[--><!--[--><!--[--><!----><div class=""><!--[--><div class="sidebar-panel"><div class="site-info" m="t-6"><a href="/about" class="site-author-avatar"><img class="rounded-full" src="https://cos.vlinux.cn/vlinux-logo/user.jpg" alt="avatar"><span class="site-author-status">🥺</span></a><div class="site-author-name"><a href="/about" class="">卷饼</a></div><a href="/about/site" class="site-name">运维之境</a><h4 class="site-subtitle block" text="xs">如果你太在意别人的话</h4><div class="site-description my-1">那你终将成为别人的一条裤衩</div></div><nav class="site-nav" text-xl="" mt-6=""><a href="/" class="site-link-item yun-icon-btn" title="首页"><div i-ri-home-4-line=""></div></a><a href="/archives/" class="site-link-item" title="归档"><div class="icon" i-ri-archive-line=""></div><span class="count">93</span></a><a href="/categories/" class="site-link-item" title="分类"><div class="icon" i-ri-folder-2-line=""></div><span class="count">17</span></a><a href="/tags/" class="site-link-item" title="标签"><div class="icon" i-ri-price-tag-3-line=""></div><span class="count">122</span></a><a href="/about" class="site-link-item yun-icon-btn" title="关于"><!--[--><div class="i-ri-clipboard-line"></div><!--]--></a></nav><hr m="t-4 b-2"><div class="links-of-author"><!--[--><a class="links-of-author-item yun-icon-btn" rel="noopener" href="https://wpa.qq.com/msgrd?v=3&amp;uin=38867033&amp;site=qq&amp;menu=yes&amp;jumpflag=1" title="QQ 38867033" target="_blank" style="color:#12b7f5"><div class="i-ri-qq-line icon"></div></a><a class="links-of-author-item yun-icon-btn" rel="noopener" href="https://github.com/vlinux" title="GitHub" target="_blank" style="color:#6e5494"><div class="i-ri-github-line icon"></div></a><a class="links-of-author-item yun-icon-btn" rel="noopener" href="https://repo.vlinux.cn/" title="杂物堆 Repo" target="_blank" style="color:#08c"><div class="i-ri-download-cloud-2-fill icon"></div></a><a class="links-of-author-item yun-icon-btn" rel="noopener" href="https://cos.vlinux.cn/www-vlinux-cn-blog-img/WechatIMG18.jpeg" title="微信公众号" target="_blank" style="color:#1aad19"><div class="i-ri-wechat-2-line icon"></div></a><a class="links-of-author-item yun-icon-btn" rel="noopener" href="https://www.vlinux.cn/music/" title="Music" target="_blank" style="color:#e6162d"><div class="i-ri-speaker-fill icon"></div></a><a class="links-of-author-item yun-icon-btn" rel="noopener" href="mailto:ilinux@88.com" title="E-Mail" target="_blank" style="color:#8e71c1"><div class="i-ri-mail-line icon"></div></a><a class="links-of-author-item yun-icon-btn" rel="noopener" href="https://www.vlinux.cn/play" title="Games" target="_blank" style="color:var(--va-c-text)"><div class="i-ri-gamepad-line icon"></div></a><!--]--></div><hr m="y-2"><div class="links"><!--[--><a href="/links/" class="link-item yun-icon-btn" title="我的小伙伴们" style="color:#1e90ff"><!--[--><div class="i-ri-genderless-line icon"></div><!--]--></a><a href="/bill" class="link-item yun-icon-btn" title="我的小账单" style="color:gold"><!--[--><div class="i-ri-money-cny-circle-line icon"></div><!--]--></a><a href="/girls/" class="link-item yun-icon-btn" title="喜欢的女孩子" style="color:#ff69b4"><!--[--><div class="i-ri-women-line icon"></div><!--]--></a><!--]--></div><br></div><div><button class="yun-icon-btn" title="切换深色模式" style="color:#f1cb64"><div i="ri-sun-line dark:ri-moon-line"></div></button><button class="yun-icon-btn" title="切换语言" style="color:var(--va-c-text)"><div i-ri-translate="" class="transition transform"></div></button></div><!--]--></div><!--]--><!--]--><!--]--></aside><!--]--><main class="yun-main lt-md:ml-0" flex="~"><div w="full" flex="~"><!--[--><div class="content" flex="~ col grow" w="full" p="l-4 lt-md:0"><div class="yun-card relative" m="0" style=""><!----><!----><!--[--><!--[--><header class="post-header mb-2" m="t-4"><h1 class="post-title flex-center" p="2" text="2xl center" font="serif black" style=""><!----><span inline-flex="" class="leading-none">K8S(kubernetes)实践认知</span></h1></header><!--]--><!--[--><!--[--><!--[--><!--[--><!----><!----><!----><div class="post-meta" flex="~ col" justify="center" items="center" text="sm" py="1"><div class="post-time flex items-center"><span class="inline-flex-center" title="发表于"><div class="inline-block" i-ri-calendar-line=""></div><time m="l-1">2020-03-09</time></span><span class="inline-flex-center" title="更新于"><span m="x-2">-</span><div i-ri-calendar-2-line=""></div><time m="l-1">2023-03-01</time></span></div><div class="post-counter flex items-center" mt="2"><span class="inline-flex-center" title="本文字数"><div class="inline-block" i-ri-file-word-line=""></div><time m="l-1">19.5k</time></span><span class="inline-flex-center" title="阅读时长"><span m="x-2">-</span><div i-ri-timer-line=""></div><time m="l-1">80m</time></span></div></div><!--[--><!--]--><!--]--><div flex="~" text="sm" py="1"><!----><!----></div><div class="inline-flex" text="sm" py="1"><a href="/categories/?category=DevOps" class="post-category inline-flex-center"><div m="x-1" inline-flex="" i-ri-folder-2-line=""></div><span>DevOps</span></a><span mx="2">-</span><!--[--><a href="/tags/?tag=K8s" class="post-tag inline-flex-center" m="x-1"><div m="r-1" i-ri-price-tag-3-line=""></div><span>K8s</span></a><!--]--></div><!--]--><!--]--><!--]--><div p="x-4 b-8" class="sm:px-6 lg:px-12 xl:px-16" w="full"><!--[--><article class="markdown-body"><!--[--><!----><!--[--><h1 id="kubernetes快速入门" tabindex="-1">Kubernetes快速入门 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#kubernetes快速入门" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h1><p>学习Kubernetes最权威的知识来源就是Kubernetes官方文档，而且对于初学者来说，官方文档可能不是最佳选择。本章将带你循循序渐进的学习Kubernetes，后面章节会通过大量的实践案例来理解和掌握Kubernetes的知识。</p><ul><li>Kubernetes官方文档：<a target="_blank" rel="noreferrer" href="https://kubernetes.io/docs/home/"><!--[-->https://kubernetes.io/docs/home/<!--]--><!----></a></li><li>Kuernetes Github：<a target="_blank" rel="noreferrer" href="https://github.com/kubernetes/"><!--[-->https://github.com/kubernetes/<!--]--><!----></a></li></ul><h2 id="kubernetes架构介绍" tabindex="-1">Kubernetes架构介绍 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#kubernetes架构介绍" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h2><p>Kubernetes 源于希腊语，意为 “舵手” 或 “飞行员”，是用于自动部署，扩展和管理容器化应用程序的开源系统，由于K和S之间有8个字母，被简称为K8S。Kubernetes 构建在 Google 15 年生产环境经验基础之上，可以将Kubernetes看作为Google内部的容器管理平台Brog的开源版本，当然他们之间是有一些差异的。</p><h3 id="kubernetes系统架构" tabindex="-1">Kubernetes系统架构 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#kubernetes系统架构" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h3><p>Kubernetes被设计为Master和Node两个角色，这类似于OpenStack的架构理念，Master为控制节点，Node为计算节点或者叫工作节点，在Master节点上有一个API Server服务，对外提供标准的RestAPI，这也是Kubernetes集群的入口，意外着只要和集群进行交互必须连接到API Server上。</p><p><img src="http://k8s.unixhot.com/kubernetes/media/4f93fc22b605a967fa54a2491557c04e.png" alt="img"></p><p><strong>Master节点介绍</strong></p><p>Kubernetes Master节点主要有4个组件，API Server、Scheduler、Controller、etcd。如下图所示：</p><p><img src="http://k8s.unixhot.com/kubernetes/media/0786901c59be2f756d7b979619a048b2.png" alt="img"></p><ul><li><strong>API Server</strong>：提供Kubernetes API接口，主要处理 Rest操作以及更新Etcd中的对象。是所有资源增删改查的唯一入口。</li><li><strong>Scheduler</strong>：绑定Pod到Node上，主要做资源调度。</li><li><strong>Controller Manager</strong>：所有其他群集级别的功能，目前由控制器Manager执行。资源对象的自动化控制中心，Kubernetes集群有很多控制器。</li><li><strong>Etcd</strong>：所有持久化的状态信息存储在Etcd中，这个是Kubernetes集群的数据库。</li></ul><p><strong>Node节点介绍</strong></p><p>Node节点是Kubernetes集群的工作节点，在Node节点上主要运行了Docker、Kubelet、kube-proxy三个服务（Fluentd请先忽略），如下图所示：</p><p><img src="http://k8s.unixhot.com/kubernetes/media/ff26ae9ea18c1a93e50b8226abfa2fa7.png" alt="img"></p><ul><li><strong>Docker Engine</strong>：负责节点的容器的管理工作，最终创建出来的是一个Docker容器。</li><li><strong>Kubelet</strong>：安装在Node上的代理服务，用来管理Pods以及容器、镜像、Volume等，实现对集群对节点的管理。</li><li><strong>Kube-proxy</strong>：安装在Node上的网络代理服务，提供网络代理以及负载均衡，实现与Service通讯。</li></ul><h3 id="kubernetes逻辑架构" tabindex="-1">Kubernetes逻辑架构 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#kubernetes逻辑架构" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h3><p>在上面的介绍中提到像Pod、Service这些概念，在Kubernetes的系统架构图中并没有体现出来，这些可以理解为Kubernetes逻辑架构中的组件。也就是在Master和Node上并不具体存在的一个服务或者进程，但却是Kubernetes的组件，也是我们的管理对象。主要有Pod、Service和各种控制器等。</p><p><strong>Pod</strong></p><p>Pod是Kubernetes的最小管理单元，一个Pod可以包含一组容器和卷。虽然一个Pod里面可以包含一个或者多个容器，但是Pod只有一个IP地址，而且Pod重启后，IP地址会发生变化。</p><p><img src="http://k8s.unixhot.com/kubernetes/media/e2a89d5ac819b578808e62d8fee0e960.png" alt="img"></p><p><strong>Controller</strong></p><p>一个应用如果可以有一个或者多个Pod，就像你给某一个应用做集群，集群中的所有Pod是一模一样的。Kubernetes中有很多控制器可以来管理Pod，例如下图的Replication Controller可以控制Pod的副本数量，从而实现横向扩展。</p><p><img src="http://k8s.unixhot.com/kubernetes/media/c4ae2886ff4fdb51b9a0dd20a14c8e50.png" alt="img"></p><p>Kubernetes中有很多控制器，后面的章节我们会一一讲到，常用的控制器如下：</p><ul><li>Replication Controller（新版本已经被ReplicaSet所替代）</li><li>ReplicaSet（新版本被封装在Deployment中）</li><li>Deployment：封装了Pod的副本管理、部署更新、回滚、扩容、缩容等功能。</li><li>DaemonSet：保证所有的Node上有且只有一个Pod在运行。</li><li>StatefulSet：有状态的应用，为 Pod 提供唯一的标识，它可以保证部署和 scale 的顺序。</li><li>Job：使用Kubernetes运行单一任务。</li><li>CronJob：使用Kubernetes运行定时任务。</li></ul><p><strong>Service</strong></p><p>由于Pod的生命周期是短暂的，而且每次重启Pod的IP地址都会发生变化，而且一个Pod有多个副本，也就是说一个集群中有了多个节点，就需要考虑负载均衡的问题。Kubernetes使用Service来实现Pod的访问，而且Service有一个Cluster IP，通常也称之为VIP，是固定不变的。</p><p><img src="http://k8s.unixhot.com/kubernetes/media/2e61328894d1eaf548ad6ff06d85a6a3.png" alt="img"></p><h3 id="kubernetes网络介绍" tabindex="-1">Kubernetes网络介绍 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#kubernetes网络介绍" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h3><p>在Kubernetes集群中存在着三种网络，分别是Node网络、Pod网络和Service网络，这几种网络之间的通信需要依靠网络插件，Kubernetes本身并没有提供，社区提供了像Flannel、Calico、Cannal等，后面章节会详述。</p><p><strong>Node网络</strong></p><p>Node网络指的是Kubernetes Node节点本地的网络，在本实验环境中使用的是192.168.56.0/24这个网段，所有的Node和Master在该网段都可以正常通信。</p><p><strong>Pod网络</strong></p><p>后面创建的Pod，每一个Pod都会有一个IP地址，这个IP地址网络段被称之为Pod网络，如下图所示。</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubectl get pod -o wide</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">nginx-54458cd494-hpn68 1/1 Running 0 9m7s 10.2.1.2 linux-node2.linuxhot.com</span></span>
<span class="line"><span style="color:#a6accd">&lt;none&gt; &lt;none&gt;</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">nginx-54458cd494-r4mfq 1/1 Running 0 7m46s 10.2.1.3 linux-node2.linuxhot.com</span></span>
<span class="line"><span style="color:#a6accd">&lt;none&gt; &lt;none&gt;</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p><strong>Service网络</strong></p><p>Service是为Pod提供访问和负载均衡的网络地址段，如下图所示。</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubectl get service</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">kubernetes ClusterIP 10.1.0.1 &lt;none&gt; 443/TCP 64m</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">nginx NodePort 10.1.216.23 &lt;none&gt; 80:30893/TCP 8m3s</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>Kubernetes的组件和知识绝非如此，快速入门可以先了解这么多，下一章节，我们先快速的部署一个Kubernetes集群。</p><h2 id="使用kubeadm部署kubernetes-v1-16-4" tabindex="-1">使用kubeadm部署Kubernetes v1.16.4 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#使用kubeadm部署kubernetes-v1-16-4" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h2><p>想要快速的体验Kubernetes的功能，官方提供了非常多的部署方案，可以使用官方提供的kubeadm以容器的方式运行Kubernetes集群，也可以使用二进制方式部署更有利于理解Kubernetes的架构，我们先使用kubeadm快速的部署一个Kubernetes集群后，学习Kubernetes的使用，然后动手使用二进制的方式来深入理解Kubernetes架构。</p><blockquote><p>注意：请不要把目光仅仅放在部署上，要慢慢的了解其本质。</p></blockquote><p>Kubernetesv1.13版本发布后，kubeadm才正式进入GA，可以生产使用。目前Kubernetes的对应镜像仓库，在国内阿里云也有了镜像站点，使用kubeadm部署Kubernetes集群变得简单并且容易了很多，本文使用kubeadm带领大家快速部署Kubernetes v1.16.2版本。</p><p><strong>实验环境准备</strong></p><p>在本书的实验环境的基础上，我们如下来分配角色：</p><table><thead><tr><th>主机名</th><th>IP地址（NAT）</th><th>最低配置</th><th>描述</th></tr></thead><tbody><tr><td><a target="_blank" rel="noreferrer" href="http://linux-node1.linuxhot.com"><!--[-->linux-node1.linuxhot.com<!--]--><!----></a></td><td>eth0:192.168.56.11</td><td>1CPU/1G内存</td><td>Kubernets Master/Etcd节点</td></tr><tr><td><a target="_blank" rel="noreferrer" href="http://linux-node2.linuxhot.com"><!--[-->linux-node2.linuxhot.com<!--]--><!----></a></td><td>eth0:192.168.56.12</td><td>1CPU/1G内存</td><td>Kubernets Node节点</td></tr><tr><td><a target="_blank" rel="noreferrer" href="http://linux-node3.linuxhot.com"><!--[-->linux-node3.linuxhot.com<!--]--><!----></a></td><td>eth0:192.168.56.13</td><td>1CPU/1G内存</td><td>Kubernets Node节点</td></tr><tr><td>Service网段</td><td>10.1.0.0/16</td><td></td><td></td></tr><tr><td>Pod网段</td><td>10.2.0.0/16</td><td></td><td></td></tr><tr><td>备注</td><td>如果有条件可以部署多个Kubernets node，实验效果更佳。</td><td></td><td></td></tr></tbody></table><h3 id="部署docker" tabindex="-1">部署Docker <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#部署docker" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h3><p>首先需要在所有Kubernetes集群的节点中安装Docker和kubeadm。</p><p><strong>1.设置使用国内Yum源</strong></p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# cd /etc/yum.repos.d/</span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 yum.repos.d]# wget https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p><strong>2.安装指定的Docker版本</strong></p><p>由于kubeadm对Docker的版本是有要求的，需要安装与Kubernetes匹配的版本，这个对应关系一般在每次发布的Changlog中可以找到，例如1.16.2的CHANGELOG如下：<a target="_blank" rel="noreferrer" href="https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG-1.16.md"><!--[-->CHANGELOG<!--]--><!----></a></p><p>当前v1.16.2支持的Docker版本有v1.13.1, 17.03, 17.06, 17.09, 18.06, 18.09,可以通过下面命令查看：</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# yum list docker-ce.x86_64 --showduplicates | sort -r</span></span>
<span class="line"><span style="color:#a6accd"> * updates: mirror.jdcloud.com</span></span>
<span class="line"><span style="color:#a6accd">Loading mirror speeds from cached hostfile</span></span>
<span class="line"><span style="color:#a6accd">Loaded plugins: fastestmirror</span></span>
<span class="line"><span style="color:#a6accd"> * extras: mirror.jdcloud.com</span></span>
<span class="line"><span style="color:#a6accd"> * epel: mirrors.njupt.edu.cn</span></span>
<span class="line"><span style="color:#a6accd">docker-ce.x86_64            3:19.03.4-3.el7                     docker-ce-stable</span></span>
<span class="line"><span style="color:#a6accd">docker-ce.x86_64            3:19.03.3-3.el7                     docker-ce-stable</span></span>
<span class="line"><span style="color:#a6accd">docker-ce.x86_64            3:19.03.2-3.el7                     docker-ce-stable</span></span>
<span class="line"><span style="color:#a6accd">docker-ce.x86_64            3:19.03.1-3.el7                     docker-ce-stable</span></span>
<span class="line"><span style="color:#a6accd">docker-ce.x86_64            3:19.03.0-3.el7                     docker-ce-stable</span></span>
<span class="line"><span style="color:#a6accd">docker-ce.x86_64            3:18.09.9-3.el7                     docker-ce-stable</span></span>
<span class="line"><span style="color:#a6accd">docker-ce.x86_64            3:18.09.8-3.el7                     docker-ce-stable</span></span>
<span class="line"><span style="color:#a6accd">docker-ce.x86_64            3:18.09.7-3.el7                     docker-ce-stable</span></span>
<span class="line"><span style="color:#a6accd">docker-ce.x86_64            3:18.09.6-3.el7                     docker-ce-stable</span></span>
<span class="line"><span style="color:#a6accd">docker-ce.x86_64            3:18.09.5-3.el7                     docker-ce-stable</span></span>
<span class="line"><span style="color:#a6accd">docker-ce.x86_64            3:18.09.4-3.el7                     docker-ce-stable</span></span>
<span class="line"><span style="color:#a6accd">docker-ce.x86_64            3:18.09.3-3.el7                     docker-ce-stable</span></span>
<span class="line"><span style="color:#a6accd">docker-ce.x86_64            3:18.09.2-3.el7                     docker-ce-stable</span></span>
<span class="line"><span style="color:#a6accd">docker-ce.x86_64            3:18.09.1-3.el7                     docker-ce-stable</span></span>
<span class="line"><span style="color:#a6accd">docker-ce.x86_64            3:18.09.0-3.el7                     docker-ce-stable</span></span>
<span class="line"><span style="color:#a6accd">docker-ce.x86_64            18.06.3.ce-3.el7                    docker-ce-stable</span></span>
<span class="line"><span style="color:#a6accd">docker-ce.x86_64            18.06.2.ce-3.el7                    docker-ce-stable</span></span>
<span class="line"><span style="color:#a6accd">docker-ce.x86_64            18.06.1.ce-3.el7                    docker-ce-stable</span></span>
<span class="line"><span style="color:#a6accd">docker-ce.x86_64            18.06.0.ce-3.el7                    docker-ce-stable</span></span>
<span class="line"><span style="color:#a6accd">docker-ce.x86_64            18.03.1.ce-1.el7.centos             docker-ce-stable</span></span>
<span class="line"><span style="color:#a6accd">docker-ce.x86_64            18.03.0.ce-1.el7.centos             docker-ce-stable</span></span>
<span class="line"><span style="color:#a6accd">docker-ce.x86_64            17.12.1.ce-1.el7.centos             docker-ce-stable</span></span>
<span class="line"><span style="color:#a6accd">docker-ce.x86_64            17.12.0.ce-1.el7.centos             docker-ce-stable</span></span>
<span class="line"><span style="color:#a6accd">docker-ce.x86_64            17.09.1.ce-1.el7.centos             docker-ce-stable</span></span>
<span class="line"><span style="color:#a6accd">docker-ce.x86_64            17.09.0.ce-1.el7.centos             docker-ce-stable</span></span>
<span class="line"><span style="color:#a6accd">docker-ce.x86_64            17.06.2.ce-1.el7.centos             docker-ce-stable</span></span>
<span class="line"><span style="color:#a6accd">docker-ce.x86_64            17.06.1.ce-1.el7.centos             docker-ce-stable</span></span>
<span class="line"><span style="color:#a6accd">docker-ce.x86_64            17.06.0.ce-1.el7.centos             docker-ce-stable</span></span>
<span class="line"><span style="color:#a6accd">docker-ce.x86_64            17.03.3.ce-1.el7                    docker-ce-stable</span></span>
<span class="line"><span style="color:#a6accd">docker-ce.x86_64            17.03.2.ce-1.el7.centos             docker-ce-stable</span></span>
<span class="line"><span style="color:#a6accd">docker-ce.x86_64            17.03.1.ce-1.el7.centos             docker-ce-stable</span></span>
<span class="line"><span style="color:#a6accd">docker-ce.x86_64            17.03.0.ce-1.el7.centos             docker-ce-stable</span></span>
<span class="line"><span style="color:#a6accd"> * base: mirrors.neusoft.edu.cn</span></span>
<span class="line"><span style="color:#a6accd">Available Packages</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p><strong>3.安装Docker18.09版本</strong></p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# yum -y install docker-ce-18.09.9-3.el7 docker-ce-cli-18.09.9-3.el7</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p><strong>4.设置cgroup驱动使用systemd</strong></p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# mkdir /etc/docker</span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# cat &gt; /etc/docker/daemon.json &lt;&lt;EOF</span></span>
<span class="line"><span style="color:#a6accd">    {</span></span>
<span class="line"><span style="color:#a6accd">      "registry-mirrors": ["https://dx5z2hy7.mirror.aliyuncs.com"],</span></span>
<span class="line"><span style="color:#a6accd">      "exec-opts": ["native.cgroupdriver=systemd"]</span></span>
<span class="line"><span style="color:#a6accd">    }</span></span>
<span class="line"><span style="color:#a6accd">EOF</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p><strong>5.启动后台进程</strong></p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# systemctl enable docker &amp;&amp; systemctl start docker</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p><strong>6.查看Docker版本</strong></p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# docker --version</span></span>
<span class="line"><span style="color:#a6accd">Docker version 18.09.9, build 039a7df9ba</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><h3 id="部署kubadm和kubelet" tabindex="-1">部署kubadm和kubelet <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#部署kubadm和kubelet" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h3><p>在Kubernetes集群的所有节点上部署完毕Docker后，还需要全部部署kubeadm和kubelet，其中kubeadm是管理工具，kubelet是一个服务，用于启动Kubernetes对应的服务。</p><p><strong>1.设置kubernetes YUM仓库</strong></p><p>这里在官方文档的基础上修改为了国内阿里云的yum仓库，</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# vim /etc/yum.repos.d/kubernetes.repo</span></span>
<span class="line"><span style="color:#a6accd">[kubernetes]</span></span>
<span class="line"><span style="color:#a6accd">name=Kubernetes</span></span>
<span class="line"><span style="color:#a6accd">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/</span></span>
<span class="line"><span style="color:#a6accd">enabled=1</span></span>
<span class="line"><span style="color:#a6accd">gpgcheck=1</span></span>
<span class="line"><span style="color:#a6accd">repo_gpgcheck=1</span></span>
<span class="line"><span style="color:#a6accd">gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><blockquote><p>注意：最下面一行gpgkey的两个URL地址之间是空格，因为排版问题可能导致换行。</p></blockquote><p><strong>2.安装软件包</strong></p><p>由于版本更新频繁，请指定对应的版本号，本文采用1.16.2版本，其它版本未经测试，如果不指定版本默认安装最新版本。</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# yum install -y kubelet-1.16.2 kubeadm-1.16.2 kubectl-1.16.2 ipvsadm</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p><strong>3.配置kubelet</strong></p><p>默认情况下，Kubelet不允许所在的主机存在交换分区，后期规划的时候，可以考虑在系统安装的时候不创建交换分区，针对已经存在交换分区的可以设置忽略禁止使用Swap的限制，不然无法启动Kubelet。</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# vim /etc/sysconfig/kubelet</span></span>
<span class="line"><span style="color:#a6accd">KUBELET_CGROUP_ARGS="--cgroup-driver=systemd"</span></span>
<span class="line"><span style="color:#a6accd">KUBELET_EXTRA_ARGS="--fail-swap-on=false"</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>在所有节点上关闭SWAP</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# swapoff -a</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p><strong>4.设置内核参数</strong></p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# cat &lt;&lt;EOF &gt;  /etc/sysctl.d/k8s.conf</span></span>
<span class="line"><span style="color:#a6accd">net.bridge.bridge-nf-call-ip6tables = 1</span></span>
<span class="line"><span style="color:#a6accd">net.bridge.bridge-nf-call-iptables = 1</span></span>
<span class="line"><span style="color:#a6accd">net.ipv4.ip_forward = 1</span></span>
<span class="line"><span style="color:#a6accd">EOF</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>使配置生效</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# sysctl --system</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p><strong>5.启动kubelet并设置开机启动</strong></p><p>注意，此时kubelet是无法正常启动的，可以查看/var/log/messages有报错信息，等待执行初始化之后即可正常，为正常现象。</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# systemctl enable kubelet &amp;&amp; systemctl start kubelet</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p><strong>6.使用IPVS进行负载均衡</strong></p><p>在Kubernetes集群中Kube-Proxy组件负载均衡的功能，默认使用iptables，生产环境建议使用ipvs进行负载均衡。在所有节点启用ipvs模块</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# vim /etc/sysconfig/modules/ipvs.modules</span></span>
<span class="line"><span style="color:#a6accd">#!/bin/bash</span></span>
<span class="line"><span style="color:#a6accd">modprobe -- ip_vs</span></span>
<span class="line"><span style="color:#a6accd">modprobe -- ip_vs_rr</span></span>
<span class="line"><span style="color:#a6accd">modprobe -- ip_vs_wrr</span></span>
<span class="line"><span style="color:#a6accd">modprobe -- ip_vs_sh</span></span>
<span class="line"><span style="color:#a6accd">modprobe -- nf_conntrack_ipv4</span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# chmod +x /etc/sysconfig/modules/ipvs.modules</span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# source /etc/sysconfig/modules/ipvs.modules</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>查看模块是否加载正常</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# lsmod | grep -e ip_vs -e nf_conntrack_ipv4</span></span>
<span class="line"><span style="color:#a6accd">ip_vs_sh               12688  0 </span></span>
<span class="line"><span style="color:#a6accd">ip_vs_wrr              12697  0 </span></span>
<span class="line"><span style="color:#a6accd">ip_vs_rr               12600  0 </span></span>
<span class="line"><span style="color:#a6accd">ip_vs                 145497  6 ip_vs_rr,ip_vs_sh,ip_vs_wrr</span></span>
<span class="line"><span style="color:#a6accd">nf_conntrack_ipv4      15053  15 </span></span>
<span class="line"><span style="color:#a6accd">nf_defrag_ipv4         12729  1 nf_conntrack_ipv4</span></span>
<span class="line"><span style="color:#a6accd">nf_conntrack          133095  7 ip_vs,nf_nat,nf_nat_ipv4,xt_conntrack,nf_nat_masquerade_ipv4,nf_conntrack_netlink,nf_conntrack_ipv4</span></span>
<span class="line"><span style="color:#a6accd">libcrc32c              12644  4 xfs,ip_vs,nf_nat,nf_conntrack</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><ul><li>以上步骤请在Kubernetes的所有节点上执行，本实验环境是需要在linux-node1、linux-node2、linux-node3这三台机器上均安装Docker、kubeadm、kubelet，对于以上操作需要自动化可以参考我使用SaltStack完成的salt-kubeadm项目：<a target="_blank" rel="noreferrer" href="https://github.com/unixhot/salt-kubeadm"><!--[-->https://github.com/unixhot/salt-kubeadm<!--]--><!----></a></li></ul><h3 id="初始化集群部署master" tabindex="-1">初始化集群部署Master <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#初始化集群部署master" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h3><p>在所有节点上安装完毕后，在linux-node1这台Master节点上进行集群的初始化工作。</p><p><strong>1.导出所有默认的配置</strong></p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubeadm config print init-defaults &gt; kubeadm.yaml</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>上面的命令会生成一个默认配置的kubeadm配置文件，然后在此基础上进行修改即可。</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# cat kubeadm.yaml </span></span>
<span class="line"><span style="color:#a6accd">apiVersion: kubeadm.k8s.io/v1beta2</span></span>
<span class="line"><span style="color:#a6accd">bootstrapTokens:</span></span>
<span class="line"><span style="color:#a6accd">- groups:</span></span>
<span class="line"><span style="color:#a6accd">  - system:bootstrappers:kubeadm:default-node-token</span></span>
<span class="line"><span style="color:#a6accd">  token: abcdef.0123456789abcdef</span></span>
<span class="line"><span style="color:#a6accd">  ttl: 24h0m0s</span></span>
<span class="line"><span style="color:#a6accd">  usages:</span></span>
<span class="line"><span style="color:#a6accd">  - signing</span></span>
<span class="line"><span style="color:#a6accd">  - authentication</span></span>
<span class="line"><span style="color:#a6accd">kind: InitConfiguration</span></span>
<span class="line"><span style="color:#a6accd">localAPIEndpoint:</span></span>
<span class="line"><span style="color:#a6accd">  advertiseAddress: 192.168.56.11  #修改为API Server的地址</span></span>
<span class="line"><span style="color:#a6accd">  bindPort: 6443</span></span>
<span class="line"><span style="color:#a6accd">nodeRegistration:</span></span>
<span class="line"><span style="color:#a6accd">  criSocket: /var/run/dockershim.sock</span></span>
<span class="line"><span style="color:#a6accd">  name: linux-node1.example.com</span></span>
<span class="line"><span style="color:#a6accd">  taints:</span></span>
<span class="line"><span style="color:#a6accd">  - effect: NoSchedule</span></span>
<span class="line"><span style="color:#a6accd">    key: node-role.kubernetes.io/master</span></span>
<span class="line"><span style="color:#a6accd">---</span></span>
<span class="line"><span style="color:#a6accd">apiServer:</span></span>
<span class="line"><span style="color:#a6accd">  timeoutForControlPlane: 4m0s</span></span>
<span class="line"><span style="color:#a6accd">apiVersion: kubeadm.k8s.io/v1beta2</span></span>
<span class="line"><span style="color:#a6accd">certificatesDir: /etc/kubernetes/pki</span></span>
<span class="line"><span style="color:#a6accd">clusterName: kubernetes</span></span>
<span class="line"><span style="color:#a6accd">controllerManager: {}</span></span>
<span class="line"><span style="color:#a6accd">dns:</span></span>
<span class="line"><span style="color:#a6accd">  type: CoreDNS</span></span>
<span class="line"><span style="color:#a6accd">etcd:</span></span>
<span class="line"><span style="color:#a6accd">  local:</span></span>
<span class="line"><span style="color:#a6accd">    dataDir: /var/lib/etcd</span></span>
<span class="line"><span style="color:#a6accd">imageRepository: registry.aliyuncs.com/google_containers  #修改为阿里云镜像仓库</span></span>
<span class="line"><span style="color:#a6accd">kind: ClusterConfiguration</span></span>
<span class="line"><span style="color:#a6accd">kubernetesVersion: v1.16.2  #修改为具体的版本</span></span>
<span class="line"><span style="color:#a6accd">networking:</span></span>
<span class="line"><span style="color:#a6accd">  dnsDomain: cluster.local</span></span>
<span class="line"><span style="color:#a6accd">  serviceSubnet: 10.1.0.0/16   #修改Service的网络</span></span>
<span class="line"><span style="color:#a6accd">  podSubnet: 10.2.0.0/16      #新增Pod的网络</span></span>
<span class="line"><span style="color:#a6accd">scheduler: {}</span></span>
<span class="line"><span style="color:#a6accd">---   #下面有增加的三行配置，用于设置Kubeproxy使用LVS</span></span>
<span class="line"><span style="color:#a6accd">apiVersion: kubeproxy.config.k8s.io/v1alpha1</span></span>
<span class="line"><span style="color:#a6accd">kind: KubeProxyConfiguration</span></span>
<span class="line"><span style="color:#a6accd">mode: ipvs</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p><strong>2. 执行初始化操作</strong></p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubeadm init --config kubeadm.yaml</span></span>
<span class="line"><span style="color:#a6accd">[init] Using Kubernetes version: v1.16.2</span></span>
<span class="line"><span style="color:#a6accd">[preflight] Running pre-flight checks</span></span>
<span class="line"><span style="color:#a6accd">error execution phase preflight: [preflight] Some fatal errors occurred:</span></span>
<span class="line"><span style="color:#a6accd">        [ERROR NumCPU]: the number of available CPUs 1 is less than the required 2</span></span>
<span class="line"><span style="color:#a6accd">        [ERROR Swap]: running with swap on is not supported. Please disable swa</span></span>
<span class="line"><span style="color:#a6accd">[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`</span></span>
<span class="line"><span style="color:#a6accd">To see the stack trace of this error execute with --v=5 or higher</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>如果遇到上面这样的报错，是因为在实验环境开启了交换分区，以及CPU的核数小于2造成的，可以使用--ignore-preflight-errors=进行忽略。 --ignore-preflight-errors=：忽略运行时的错误，例如上面目前存在[ERROR NumCPU]和[ERROR Swap]，忽略这两个报错就是增加--ignore-preflight-errors=NumCPU 和--ignore-preflight-errors=Swap的配置即可。</p><p>再次执行初始化操作：</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubeadm init --config kubeadm.yaml \</span></span>
<span class="line"><span style="color:#a6accd">  --ignore-preflight-errors=Swap,NumCPU </span></span>
<span class="line"><span style="color:#a6accd">[init] Using Kubernetes version: v1.16.2</span></span>
<span class="line"><span style="color:#a6accd">[preflight] Running pre-flight checks</span></span>
<span class="line"><span style="color:#a6accd">        [WARNING NumCPU]: the number of available CPUs 1 is less than the required 2</span></span>
<span class="line"><span style="color:#a6accd">        [WARNING Swap]: running with swap on is not supported. Please disable swap</span></span>
<span class="line"><span style="color:#a6accd">[preflight] Pulling images required for setting up a Kubernetes cluster</span></span>
<span class="line"><span style="color:#a6accd">[preflight] This might take a minute or two, depending on the speed of your internet connection</span></span>
<span class="line"><span style="color:#a6accd">[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>执行完毕后，会在当前输出下停留，等待下载Kubernetes组件的Docker镜像。根据你的网络情况，可以持续1-5分钟，你也可以使用docker images查看下载的镜像。镜像下载完毕之后，就会进行初始操作：</p><p>这里省略了所有输出，初始化操作主要经历了下面15个步骤，每个阶段均输出均使用[步骤名称]作为开头：</p><ol><li>[init]：指定版本进行初始化操作</li><li>[preflight] ：初始化前的检查和下载所需要的Docker镜像文件。</li><li>[kubelet-start]：生成kubelet的配置文件”/var/lib/kubelet/config.yaml”，没有这个文件kubelet无法启动，所以初始化之前的kubelet实际上启动失败。</li><li>[certificates]：生成Kubernetes使用的证书，存放在/etc/kubernetes/pki目录中。</li><li>[kubeconfig] ：生成 KubeConfig文件，存放在/etc/kubernetes目录中，组件之间通信需要使用对应文件。</li><li>[control-plane]：使用/etc/kubernetes/manifest目录下的YAML文件，安装 Master组件。</li><li>[etcd]：使用/etc/kubernetes/manifest/etcd.yaml安装Etcd服务。</li><li>[wait-control-plane]：等待control-plan部署的Master组件启动。</li><li>[apiclient]：检查Master组件服务状态。</li><li>[uploadconfig]：更新配置</li><li>[kubelet]：使用configMap配置kubelet。</li><li>[patchnode]：更新CNI信息到Node上，通过注释的方式记录。</li><li>[mark-control-plane]：为当前节点打标签，打了角色Master，和不可调度标签，这样默认就不会使用Master节点来运行Pod。</li><li>[bootstrap-token]：生成token记录下来，后边使用kubeadm join往集群中添加节点时会用到</li><li>[addons]：安装附加组件CoreDNS和kube-proxy</li></ol><p>成功执行之后，你会看到下面的输出：</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">Your Kubernetes master has initialized successfully!</span></span>
<span class="line"><span style="color:#a6accd">To start using your cluster, you need to run the following as a regular user:</span></span>
<span class="line"><span style="color:#a6accd">mkdir -p $HOME/.kube</span></span>
<span class="line"><span style="color:#a6accd">sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span></span>
<span class="line"><span style="color:#a6accd">sudo chown $(id -u):$(id -g) $HOME/.kube/config</span></span>
<span class="line"><span style="color:#a6accd">You should now deploy a pod network to the cluster.</span></span>
<span class="line"><span style="color:#a6accd">Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:</span></span>
<span class="line"><span style="color:#a6accd">https://kubernetes.io/docs/concepts/cluster-administration/addons/</span></span>
<span class="line"><span style="color:#a6accd">You can now join any number of machines by running the following on each node</span></span>
<span class="line"><span style="color:#a6accd">as root:</span></span>
<span class="line"><span style="color:#a6accd">kubeadm join 192.168.56.11:6443 --token 19fhhl.3mzkyk16tcgp6vga --discovery-token-ca-cert-hash sha256:76a88c38b673d3b2ac73e33127a809688cb3e58c533512ac6d92ecb66aa57a45</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>如果执行失败，那意味着之前的操作存在问题，检查顺序如下：</p><ul><li>基础环境</li><li>主机名是否可以解析，SELinux，iptables是否关闭。</li><li>交换分区是否存在free -m查看</li><li>内核参数是否修改、IPVS是否修改（目前阶段不会造成失败）</li><li>基础软件</li><li>Docker是否安装并启动</li><li>Kubelet是否安装并启动</li><li>执行kubeadm是否有别的报错是否忽略</li><li>systemctl status kubelet查看kubelet是否启动</li><li>如果kubelet无法启动，查看日志有什么报错，并解决报错。</li><li>以上都解决完毕，需要重新初始化</li><li>kubeadm reset 进行重置（生产千万不要执行，会直接删除集群）</li><li>根据kubeadm reset 提升，清楚iptables和LVS。</li></ul><p>请根据上面输出的要求配置kubectl命令来访问集群。</p><p><strong>3.为kubectl准备Kubeconfig文件。</strong></p><p>kubectl默认会在执行的用户家目录下面的.kube目录下寻找config文件。这里是将在初始化时[kubeconfig]步骤生成的admin.conf拷贝到.kube/config。</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# mkdir -p $HOME/.kube</span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# chown $(id -u):$(id -g) $HOME/.kube/config</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>在该配置文件中，记录了API Server的访问地址，所以后面直接执行kubectl命令就可以正常连接到API Server中。</p><p><strong>4.使用kubectl命令查看组件状态</strong></p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubectl get cs</span></span>
<span class="line"><span style="color:#a6accd">NAME STATUS MESSAGE ERROR</span></span>
<span class="line"><span style="color:#a6accd">scheduler Healthy ok</span></span>
<span class="line"><span style="color:#a6accd">controller-manager Healthy ok</span></span>
<span class="line"><span style="color:#a6accd">etcd-0 Healthy {"health": "true"}</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>**知识回顾：为什么上面的输出没有显示API Server组件的状态</p><p>因为API Server是Kubernetes集群的入口，所有和Kubernetes集群的交互都必须经过APIServer，kubectl命令也是连接到API Server上进行交互，所以如果能够正常使用kubectl执行命令，意味着API Server运行正常。</p><p><strong>5.使用kubectl获取Node信息</strong></p><p>目前只有一个节点，角色是Master，状态是NotReady。</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubectl get node</span></span>
<span class="line"><span style="color:#a6accd">NAME STATUS ROLES AGE VERSION</span></span>
<span class="line"><span style="color:#a6accd">linux-node1.unixhot.com NotReady master 14m v1.16.2</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><h3 id="部署网络插件" tabindex="-1">部署网络插件 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#部署网络插件" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h3><p>Master节点NotReady的原因就是因为没有使用任何的网络插件，此时Node和Master的连接还不正常。目前最流行的Kubernetes网络插件有Flannel、Calico、Canal，这里分别列举了Canal和Flannel，你可以选择其中之一进行部署。 因为基础的Kubernetes集群已经配置完毕，后面的增加组件等操作，几乎都可以使用kubectl和一个YAML配置文件来完成。</p><p>【部署canal网络插件】</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubectl apply -f https://docs.projectcalico.org/v3.3/getting-started/kubernetes/installation/hosted/canal/rbac.yaml</span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubectl apply -f https://docs.projectcalico.org/v3.3/getting-started/kubernetes/installation/hosted/canal/canal.yaml</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>【部署Flannel网络插件】（推荐） 部署Flannel网络插件需要修改Pod的IP地址段，修改为和你初始化一直的网段，可以先下载Flannel的YAML文件修改后，再执行。</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# git clone --depth 1 https://github.com/coreos/flannel.git</span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# cd flannel/Documentation/</span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 Documentation]# vim kube-flannel.yml</span></span>
<span class="line"><span style="color:#a6accd"># 修改"Network": "10.244.0.0/16"为"Network": "10.2.0.0/16",</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">74   net-conf.json: |</span></span>
<span class="line"><span style="color:#a6accd">75     {</span></span>
<span class="line"><span style="color:#a6accd">76       "Network": "10.2.0.0/16",</span></span>
<span class="line"><span style="color:#a6accd">77       "Backend": {</span></span>
<span class="line"><span style="color:#a6accd">78         "Type": "vxlan"</span></span>
<span class="line"><span style="color:#a6accd">79       }</span></span>
<span class="line"><span style="color:#a6accd">80     }</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd"># 请注意，Flannel的镜像拉取速度会比较慢，可以替换为国内镜像</span></span>
<span class="line"><span style="color:#a6accd"># image: quay.io/coreos/flannel:v0.10.0-amd64</span></span>
<span class="line"><span style="color:#a6accd">image: quay-mirror.qiniu.com/coreos/flannel:v0.11.0-amd64</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd"># 如果Node中有多个网卡，可以使用--iface来指定对应的网卡参数。</span></span>
<span class="line"><span style="color:#a6accd">containers:</span></span>
<span class="line"><span style="color:#a6accd">      - name: kube-flannel</span></span>
<span class="line"><span style="color:#a6accd">        image: quay-mirror.qiniu.com/coreos/flannel:v0.11.0-amd64</span></span>
<span class="line"><span style="color:#a6accd">        command:</span></span>
<span class="line"><span style="color:#a6accd">        - /opt/bin/flanneld</span></span>
<span class="line"><span style="color:#a6accd">        args:</span></span>
<span class="line"><span style="color:#a6accd">        - --ip-masq</span></span>
<span class="line"><span style="color:#a6accd">        - --kube-subnet-mgr</span></span>
<span class="line"><span style="color:#a6accd">        - --iface=eth0</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>部署Flannel</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 Documentation]# kubectl create -f kube-flannel.yml</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>查看Pod状态</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 Documentation]# kubectl get pod -n kube-system</span></span>
<span class="line"><span style="color:#a6accd">NAME                                              READY   STATUS     RESTARTS   AGE</span></span>
<span class="line"><span style="color:#a6accd">coredns-58cc8c89f4-cjhdv                          0/1     Pending    0          41m</span></span>
<span class="line"><span style="color:#a6accd">coredns-58cc8c89f4-vdfn2                          0/1     Pending    0          41m</span></span>
<span class="line"><span style="color:#a6accd">etcd-linux-node1.unixhot.com                      1/1     Running    0          41m</span></span>
<span class="line"><span style="color:#a6accd">kube-apiserver-linux-node1.unixhot.com            1/1     Running    0          40m</span></span>
<span class="line"><span style="color:#a6accd">kube-controller-manager-linux-node1.unixhot.com   1/1     Running    1          40m</span></span>
<span class="line"><span style="color:#a6accd">kube-flannel-ds-amd64-bwsxl                       0/1     Init:0/1   0          20s</span></span>
<span class="line"><span style="color:#a6accd">kube-proxy-5qrmh                                  1/1     Running    0          41m</span></span>
<span class="line"><span style="color:#a6accd">kube-scheduler-linux-node1.unixhot.com            1/1     Running    1          41m</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>可以看到此时CoreDNS处于Pending状态，需要等待网络插件canal或者Flannel的Pod状态变成Running之后CoreDNS也会正常。所有Pod的状态都变成Running之后，这个时候再次获取Node，会发现节点变成了Ready状态。</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubectl get node</span></span>
<span class="line"><span style="color:#a6accd">NAME STATUS ROLES AGE VERSION</span></span>
<span class="line"><span style="color:#a6accd">linux-node1.unixhot.com Ready master 29m v1.16.2</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p><em>kubeadm其实使用Kubernetes部署Kubernetes，这样就存在先有鸡还是先有蛋的问题，所以，我们首先手动部署了Docker和kubelet，然后kubeadm调用kubelet以静态Pod的方式部署了Kubernetes集群中的其它组件。静态Pod在后面的章节会讲到。</em></p><h3 id="部署node节点" tabindex="-1">部署Node节点 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#部署node节点" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h3><p>Master节点部署完毕之后，就可以部署Node节点，首先请遵循部署Docker和kubeadm章节为Node节点部署安装好docker、kubeadm和kubelet，此过程这里不再重复列出。</p><p><strong>1.在Master节点输出增加节点的命令</strong></p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubeadm token create --print-join-command</span></span>
<span class="line"><span style="color:#a6accd">kubeadm join 192.168.56.11:6443 --token isggqa.xjwsm3i6nex91d2x --discovery-token-ca-cert-hash sha256:718827895a9a5e63dfa9ff54e16ad6dc0c493139c9c573b67ad66968036cd569</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p><strong>2.在Node节点执行</strong></p><p>注意如果节点有交换分区，需要增加--ignore-preflight-errors=Swap。</p><p>部署linux-node2</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node2 ~]# kubeadm join 192.168.56.11:6443 --token isggqa.xjwsm3i6nex91d2x --discovery-token-ca-cert-hash sha256:718827895a9a5e63dfa9ff54e16ad6dc0c493139c9c573b67ad66968036cd569 --ignore-preflight-errors=Swap</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>部署linux-node3</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node3 ~]# kubeadm join 192.168.56.11:6443 --tokenisggqa.xjwsm3i6nex91d2x --discovery-token-ca-cert-hash sha256:718827895a9a5e63dfa9ff54e16ad6dc0c493139c9c573b67ad66968036cd569 --ignore-preflight-errors=Swap</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>这个时候kubernetes会使用DaemonSet在所有节点上都部署canal/flannel和kube-proxy。部署完毕之后节点即部署完毕。DaemonSet的内容后面会讲解。</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">    [root@linux-node1 ~]# kubectl get daemonset --all-namespaces</span></span>
<span class="line"><span style="color:#a6accd">    NAMESPACE NAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGE</span></span>
<span class="line"><span style="color:#a6accd">    kube-system canal 2 2 1 2 1 beta.kubernetes.io/os=linux 17m</span></span>
<span class="line"><span style="color:#a6accd">    kube-system kube-proxy 2 2 2 2 2 &lt;none&gt; 47m</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>待所有Pod全部启动完毕之后，节点就恢复Ready状态。</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">    [root@linux-node1 ~]# kubectl get pod --all-namespaces</span></span>
<span class="line"><span style="color:#a6accd">    NAMESPACE NAME READY STATUS RESTARTS AGE</span></span>
<span class="line"><span style="color:#a6accd">    kube-system canal-lv92w 3/3 Running 0 8m45s</span></span>
<span class="line"><span style="color:#a6accd">    kube-system canal-rq5n5 3/3 Running 0 23m</span></span>
<span class="line"><span style="color:#a6accd">    kube-system coredns-78d4cf999f-5k4sg 1/1 Running 0 53m</span></span>
<span class="line"><span style="color:#a6accd">    kube-system coredns-78d4cf999f-bnbgf 1/1 Running 0 53m</span></span>
<span class="line"><span style="color:#a6accd">    kube-system etcd-linux-node1.linuxhot.com 1/1 Running 0 52m</span></span>
<span class="line"><span style="color:#a6accd">    kube-system kube-apiserver-linux-node1.linuxhot.com 1/1 Running 0 52m</span></span>
<span class="line"><span style="color:#a6accd">    kube-system kube-controller-manager-linux-node1.linuxhot.com 1/1 Running 0 52m</span></span>
<span class="line"><span style="color:#a6accd">    kube-system kube-proxy-sddlp 1/1 Running 0 53m</span></span>
<span class="line"><span style="color:#a6accd">    kube-system kube-proxy-tw96b 1/1 Running 0 8m45s</span></span>
<span class="line"><span style="color:#a6accd">    kube-system kube-scheduler-linux-node1.linuxhot.com 1/1 Running 0 52m</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p><strong>查看所有节点</strong> `` [root@linux-node1 ~]# kubectl get node NAME STATUS ROLES AGE VERSION <a target="_blank" rel="noreferrer" href="http://linux-node1.linuxhot.com"><!--[-->linux-node1.linuxhot.com<!--]--><!----></a> Ready master 49m v1.13.2 <a target="_blank" rel="noreferrer" href="http://linux-node2.linuxhot.com"><!--[-->linux-node2.linuxhot.com<!--]--><!----></a> Ready 4m48s v1.13.2</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">**如何给Node加上Roles标签**</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">使用kubectl get node能够看到linux-node1.linuxhot.com的ROLES是master这个是在进行集群初始化的时候[mark-control-plane]进行标记的。</span></span>
<span class="line"><span style="color:#a6accd">[mark-control-plane] Marking the node linux-node1.linuxhot.com as control-plane</span></span>
<span class="line"><span style="color:#a6accd">by adding the label "node-role.kubernetes.io/master=''"</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">[mark-control-plane] Marking the node linux-node1.linuxhot.com as control-plane</span></span>
<span class="line"><span style="color:#a6accd">by adding the taints [node-role.kubernetes.io/master:NoSchedule]</span></span>
<span class="line"><span style="color:#a6accd">1.查看节点的标签</span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubectl get nodes --show-labels</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">NAME STATUS ROLES AGE VERSION LABELS</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">linux-node1.linuxhot.com Ready master 48m v1.13.3</span></span>
<span class="line"><span style="color:#a6accd">beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/hostname=linux-node1.linuxhot.com,node-role.kubernetes.io/master=</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">linux-node2.linuxhot.com Ready &lt;none&gt; 7m13s v1.13.3</span></span>
<span class="line"><span style="color:#a6accd">beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/hostname=linux-node2.linuxhot.com</span></span>
<span class="line"><span style="color:#a6accd">2.增加标签</span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubectl label nodes linux-node2.linuxhot.com</span></span>
<span class="line"><span style="color:#a6accd">node-role.kubernetes.io/node=</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">node/linux-node2.linuxhot.com labeled</span></span>
<span class="line"><span style="color:#a6accd">3.查看效果</span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubectl get nodes</span></span>
<span class="line"><span style="color:#a6accd">NAME STATUS ROLES AGE VERSION</span></span>
<span class="line"><span style="color:#a6accd">linux-node1.linuxhot.com Ready master 50m v1.13.3</span></span>
<span class="line"><span style="color:#a6accd">linux-node2.linuxhot.com Ready node 8m41s v1.13.3</span></span>
<span class="line"><span style="color:#a6accd">### 测试Kubernetes集群 {#test}</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">在上面的步骤中，我们创建了一个Kubernetes集群，1个Master和2个Node节点，在生产环境需要考虑Master的高可用，这里先不用考虑，后面会讲到。</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">**1.创建一个单Pod的Nginx应用**</span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubectl create deployment nginx --image=nginx:alpine</span></span>
<span class="line"><span style="color:#a6accd">deployment.apps/nginx created</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubectl get pod</span></span>
<span class="line"><span style="color:#a6accd">NAME READY STATUS RESTARTS AGE</span></span>
<span class="line"><span style="color:#a6accd">nginx-54458cd494-9j7ql 0/1 ContainerCreating 0 10s</span></span>
<span class="line"><span style="color:#a6accd">**2.查看Pod详细信息**</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">待Pod的状态为Running后，可以获取Pod的IP地址，这个IP地址是从Master节点初始化的--pod-network-cidr=10.2.0.0/16地址段中分配的。</span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubectl get pod -o wide</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">nginx-54458cd494-9j7ql 1/1 Running 0 59s 10.2.1.2 linux-node2.linuxhot.com</span></span>
<span class="line"><span style="color:#a6accd">&lt;none&gt; &lt;none&gt;</span></span>
<span class="line"><span style="color:#a6accd">**3.测试Nginx访问**</span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# curl --head http://10.2.1.2</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">HTTP/1.1 200 OK</span></span>
<span class="line"><span style="color:#a6accd">Server: nginx/1.15.8</span></span>
<span class="line"><span style="color:#a6accd">Date: Sun, 13 Jan 2019 01:16:36 GMT</span></span>
<span class="line"><span style="color:#a6accd">Content-Type: text/html</span></span>
<span class="line"><span style="color:#a6accd">Content-Length: 612</span></span>
<span class="line"><span style="color:#a6accd">Last-Modified: Wed, 26 Dec 2018 23:21:49 GMT</span></span>
<span class="line"><span style="color:#a6accd">Connection: keep-alive</span></span>
<span class="line"><span style="color:#a6accd">ETag: "5c240d0d-264"</span></span>
<span class="line"><span style="color:#a6accd">Accept-Ranges: bytes</span></span>
<span class="line"><span style="color:#a6accd">**4.测试扩容**</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">现在将Nginx应用的Pod副本数量拓展到2个节点</span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubectl scale deployment nginx --replicas=2</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">deployment.extensions/nginx scaled</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubectl get pod</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">NAME READY STATUS RESTARTS AGE</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">nginx-54458cd494-9j7ql 1/1 Running 0 2m13s</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">nginx-54458cd494-vnm4f 1/1 Running 0 5s</span></span>
<span class="line"><span style="color:#a6accd">**5.为Nginx增加Service**</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">为Nginx增加Service，会创建一个Cluster</span></span>
<span class="line"><span style="color:#a6accd">IP，从Master初始化的--service-cidr=10.1.0.0/16地址段中进行分配，</span></span>
<span class="line"><span style="color:#a6accd">并开启NodePort是在Node节点上进行端口映射，进行外部访问。</span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubectl expose deployment nginx --port=80</span></span>
<span class="line"><span style="color:#a6accd">--type=NodePort</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">service/nginx exposed</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubectl get service</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE</span></span>
<span class="line"><span style="color:#a6accd">kubernetes ClusterIP 10.1.0.1 &lt;none&gt; 443/TCP 88m</span></span>
<span class="line"><span style="color:#a6accd">nginx NodePort 10.1.147.204 &lt;none&gt; 80:30599/TCP 67m</span></span>
<span class="line"><span style="color:#a6accd">**6.测试Service的VIP**</span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# curl --head http://10.1.147.204/</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">HTTP/1.1 200 OK </span></span>
<span class="line"><span style="color:#a6accd">Server: nginx/1.15.8</span></span>
<span class="line"><span style="color:#a6accd">Date: Sun, 13 Jan 2019 01:26:21 GMT</span></span>
<span class="line"><span style="color:#a6accd">Content-Type: text/html</span></span>
<span class="line"><span style="color:#a6accd">Content-Length: 612</span></span>
<span class="line"><span style="color:#a6accd">Last-Modified: Wed, 26 Dec 2018 23:21:49 GMT</span></span>
<span class="line"><span style="color:#a6accd">Connection: keep-alive</span></span>
<span class="line"><span style="color:#a6accd">ETag: "5c240d0d-264"</span></span>
<span class="line"><span style="color:#a6accd">Accept-Ranges: bytes</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>``` <strong>7.测试NodePort，外部访问。</strong></p><p><img src="http://k8s.unixhot.com/kubernetes/media/1f9d523f359ce6d49515d04703d8e941.png" alt="img"></p><p>这一切看起来似乎不是十分完美，但是现在你已经拥有了一个Kubernetes集群，接下来就可以继续探索Kubernetes的世界了。</p><h2 id="公有云中的kubernetes" tabindex="-1">公有云中的Kubernetes <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#公有云中的kubernetes" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h2><p>截止2019年2月，大多数公有云已经提供了容器Kubernetes的产品服务，对于使用公有云的用户来说，最佳实践是直接购买公有云产品，而非自己部署Kubernetes集群，主要是因为公有云已经将网络和存储与Kubernetes集成好了，解决了生产应用的难题。</p><h3 id="阿里云中的kubernetes" tabindex="-1">阿里云中的Kubernetes <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#阿里云中的kubernetes" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h3><p>国内阿里云提供了容器服务 Kubernetes 版（简称 ACK）提供高性能可伸缩的容器应用管理能力，支持企业级 Kubernetes 容器化应用的全生命周期管理。容器服务 Kubernetes 版简化集群的搭建和扩容等工作，整合阿里云虚拟化、存储、网络和安全能力，打造云端最佳的 Kubernetes 容器化应用运行环境。</p><p><strong>阿里云Kubernetes模式</strong></p><p>容器服务Kubernetes版包含了经典Dedicated Kubernetes以及Serverless两种形态，方便您按需选择。</p><ul><li>经典Dedicated Kubernetes模式：您可以对集群基础设施和容器应用进行更细粒度的控制，比如选择宿主机实例规格和操作系统，指定Kubernetes 版本、自定义 Kubernetes 特性开关设置等。阿里云 Kubernetes 服务负责为集群创建底层云资源，升级等自动化运维操作。而您需要规划、维护、升级服务器集群，手动或自动在集群中添加或删除服务器。</li><li>Serverless 模式：您无需创建底层虚拟化资源，可以利用 Kubernetes 命令指明应用容器镜像、CPU 和内存要求以及对外服务方式，直接启动。</li></ul><p><strong>阿里云Kubernetes产品架构</strong></p><p><img src="http://k8s.unixhot.com/kubernetes/media/43688d33a81f2bd6af354d0715b6b297.png" alt="C:UsersjasonDesktop15447553537457_zh-CN.png"></p><p><strong>阿里云Kubernetes创建</strong></p><p>默认情况下可以在阿里云中自行创建5个集群，每个集群最多可以添加 40 个节点。如需更高配额，需要提交工单申请。</p><p><img src="http://k8s.unixhot.com/kubernetes/media/4c165d0ebc842862595f9fd0f4650d43.png" alt="img"></p><p>阿里云将网络、存储、安全等方面已经进行了深度集成，在创建Kubernetes集群时，阿里云容器服务提供两种网络插件：Terway和Flannel：</p><ul><li>Flannel：使用的是简单稳定的社区的Flannel CNI插件，配合阿里云的VPC的高速网络，能给集群高性能和稳定的容器网络体验，但功能偏简单，支持的特性少，例如：不支持基于Kubernetes标准的Network Policy。</li><li>Terway：是阿里云容器服务自研的网络插件，功能上完全兼容Flannel，支持将阿里云的弹性网卡分配给容器，支持基于Kubernetes标准的NetworkPolicy来定义容器间的访问策略，支持对单个容器做带宽的限流。对于不需要使用Network Policy的用户，可以选择Flannel，其他情况建议选择Terway。了解更多Terway网络插件的相关内容，请参见Terway网络插件。</li></ul><p>最终阿里云会使用kubeadm帮你创建一个指定版本的Kubernetes集群。</p><h3 id="私有云中的kubernetes" tabindex="-1">私有云中的Kubernetes <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#私有云中的kubernetes" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h3><p><strong>内网部署Kubernetes</strong></p><p>很多企业需要内网部署Kubernetes但是内网又无法访问外网，就需要本地化部署，无忘了本地话部署主要包括两个方面，一个是软件仓库的准备，一个是Kubernetes镜像的准备。</p><ol><li>准备内网YUM仓库（略）</li><li>准备Docker Registry（请参考Harbor章节）</li><li>下载并提交镜像到Harbor中，然后将Harbor的镜像部署直接COPY到生产环境中</li></ol><p>下载脚本如下，请根据需求自行修改：</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# vim k8s-images.sh</span></span>
<span class="line"><span style="color:#a6accd">#!/bin/bash</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd"># EVN</span></span>
<span class="line"><span style="color:#a6accd">ALIYUN_REG="registry.aliyuncs.com/google_containers"</span></span>
<span class="line"><span style="color:#a6accd">FLANNEL_REG="quay-mirror.qiniu.com/coreos"</span></span>
<span class="line"><span style="color:#a6accd">LOCAL_REG="192.168.56.11/kubernetes"</span></span>
<span class="line"><span style="color:#a6accd">K8S_VER=v1.15.5</span></span>
<span class="line"><span style="color:#a6accd">PAUSE_VER=3.1</span></span>
<span class="line"><span style="color:#a6accd">ETCD_VER=3.3.10</span></span>
<span class="line"><span style="color:#a6accd">COREDNS_VER=1.3.1</span></span>
<span class="line"><span style="color:#a6accd">FLANNEL_VER=v0.11.0-amd64</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd"># Kubernetes Docker Images</span></span>
<span class="line"><span style="color:#a6accd">IMAGES=(</span></span>
<span class="line"><span style="color:#a6accd">  kube-proxy:${K8S_VER}</span></span>
<span class="line"><span style="color:#a6accd">  kube-scheduler:${K8S_VER}</span></span>
<span class="line"><span style="color:#a6accd">  kube-controller-manager:${K8S_VER}</span></span>
<span class="line"><span style="color:#a6accd">  kube-apiserver:${K8S_VER}</span></span>
<span class="line"><span style="color:#a6accd">  pause:${PAUSE_VER}</span></span>
<span class="line"><span style="color:#a6accd">  etcd-amd64:${ETCD_VER}</span></span>
<span class="line"><span style="color:#a6accd">  coredns:${COREDNS_VER}</span></span>
<span class="line"><span style="color:#a6accd">)</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">for IMAGE in ${IMAGES[@]}</span></span>
<span class="line"><span style="color:#a6accd">do</span></span>
<span class="line"><span style="color:#a6accd">  docker pull ${ALIYUN_REG}/${IMAGE}</span></span>
<span class="line"><span style="color:#a6accd">  docker tag ${ALIYUN_REG}/${IMAGE} ${LOCAL_REG}/${IMAGE}</span></span>
<span class="line"><span style="color:#a6accd">  #docker push ${LOCAL_REG}/${IMAGES}</span></span>
<span class="line"><span style="color:#a6accd">done</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd"># Flannel</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">docker pull ${FLANNEL_REG}/flannel:${FLANNEL_VER}</span></span>
<span class="line"><span style="color:#a6accd">docker tag ${FLANNEL_REG}/flannel:${FLANNEL_VER} ${LOCAL_REG}/flannel:${FLANNEL_VER}</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><h1 id="第五部分-将应用迁移至kubernetes" tabindex="-1">第五部分 将应用迁移至Kubernetes <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#第五部分-将应用迁移至kubernetes" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h1><h1 id="_6-第一步：将应用封装进容器中" tabindex="-1">6 第一步：将应用封装进容器中 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#_6-第一步：将应用封装进容器中" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h1><h2 id="第一步：将应用封装进容器中" tabindex="-1">第一步：将应用封装进容器中 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#第一步：将应用封装进容器中" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h2><p>在之前的容器镜像实战中，我们已经学习了如何将应用容器化，这里我们将下载使用两个官方的Nginx镜像来完成接下来的实验。</p><h3 id="部署harbor镜像仓库" tabindex="-1">部署Harbor镜像仓库 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#部署harbor镜像仓库" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h3><p>生产环境中可以使用Harbor来管理Docker镜像，请参考之前章节的内容完成Harbor镜像仓库的部署工作，并在Harbor中创建一个devopsedu的项目。</p><p><img src="http://k8s.unixhot.com/kubernetes/media/093b4b731c05b54a1b8426e924f93d45.png" alt="img"></p><h3 id="制作实验用的docker镜像" tabindex="-1">制作实验用的Docker镜像 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#制作实验用的docker镜像" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h3><p>这里不再演示Docker镜像的构建，直接下载两个官方镜像作为案例。</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# docker pull nginx:1.13.12</span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# docker pull nginx:1.14.0</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><h3 id="配置docker仓库" tabindex="-1">配置Docker仓库 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#配置docker仓库" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h3><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root\@linux-node1 ~]# vim /etc/docker/daemon.json</span></span>
<span class="line"><span style="color:#a6accd">{</span></span>
<span class="line"><span style="color:#a6accd">    "registry-mirrors": ["https://tdimi5q1.mirror.aliyuncs.com"],</span></span>
<span class="line"><span style="color:#a6accd">    "insecure-registries" : ["http://192.168.56.11"]</span></span>
<span class="line"><span style="color:#a6accd">}</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# systemctl restart docker</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><h3 id="登录harbor镜像仓库" tabindex="-1">登录Harbor镜像仓库 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#登录harbor镜像仓库" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h3><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# docker login 192.168.56.11</span></span>
<span class="line"><span style="color:#a6accd">Username: admin</span></span>
<span class="line"><span style="color:#a6accd">Password:</span></span>
<span class="line"><span style="color:#a6accd">WARNING! Your password will be stored unencrypted in /root/.docker/config.json.</span></span>
<span class="line"><span style="color:#a6accd">    Configure a credential helper to remove this warning. See</span></span>
<span class="line"><span style="color:#a6accd">    https://docs.docker.com/engine/reference/commandline/login/\#credentials-store</span></span>
<span class="line"><span style="color:#a6accd">    Login Succeeded</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><h3 id="提交镜像到registry" tabindex="-1">提交镜像到Registry <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#提交镜像到registry" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h3><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# docker tag nginx:1.13.12</span></span>
<span class="line"><span style="color:#a6accd">192.168.56.11/devopsedu/nginx:1.13.12</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# docker tag nginx:1.14.0</span></span>
<span class="line"><span style="color:#a6accd">192.168.56.11/devopsedu/nginx:1.14.0</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# docker push 192.168.56.11/devopsedu/nginx:1.13.12</span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# docker push 192.168.56.11/devopsedu/nginx:1.14.0</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>在上面的步骤中，模拟了生产环境如何构建和提交镜像，如果对于构建和提交镜像有疑问可以复习第3章的内容。</p><h1 id="_7-第二步：将容器封装到pod中" tabindex="-1">7 第二步：将容器封装到Pod中 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#_7-第二步：将容器封装到pod中" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h1><p>Pod是Kubernetes最小的管理单元，一个Pod可以代表一个运行在集群里的进程。之前是在宿主机上运行不同的进程，现在是运行不同的Pod。前面介绍过Pod是一个逻辑架构的组件，Pod里封装了一个（或者多个）应用容器，存储资源和IP地址。</p><p><strong>为什么要造一个Pod出来？</strong> 学习Kubernetes遇到的最多的名称可能就是Pod了，其它开源的容器管理平台例如Mesos直接管理和调度的是容器，但是Kubernetes确是Pod，它在容器上面做了一层封装，方便用户将一组紧耦合的容器，放置在一个共享资源的单元中。对于很多没有此类场景的初学者，可以暂时将Pod看做是容器的一个壳，你也完全可以只在Pod中运行一个容器，随着学习的深入再慢慢理解。 Kubernetes运行Pod的两种方式：</p><ul><li>Pod里只运行一个单独容器，是Kubernetes最常见的使用场景；在这种情况下，可以把Pod看做是一个单独容器的连接器，Kubernetes通过Pod去管理容器，作为使用者几乎不用关心容器。</li><li>Pod里运行多个有关系容器。例如如果使用Nginx+Tomcat运行Java应用，可以制作一个镜像里面包含了Nginx+Tomcat，也可以分别制作两个镜像Nginx镜像和Tomcat镜像，如果使用Kubernetes就需要使用Pod，如果将Nginx和Tomcat单独放在两个Pod里面来管理，就会面临很多很多问题。这个时候，就可以把这两个容器放置在一个Pod中。</li></ul><h2 id="pod管理" tabindex="-1">Pod管理 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#pod管理" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h2><p>在Kubernetes中使用YAML格式来描述一个Pod。</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# vim nginx-pod.yaml </span></span>
<span class="line"><span style="color:#a6accd">apiVersion: v1</span></span>
<span class="line"><span style="color:#a6accd">kind: Pod</span></span>
<span class="line"><span style="color:#a6accd">metadata:</span></span>
<span class="line"><span style="color:#a6accd">  name: nginx-pod</span></span>
<span class="line"><span style="color:#a6accd">  labels:</span></span>
<span class="line"><span style="color:#a6accd">    app: nginx</span></span>
<span class="line"><span style="color:#a6accd">spec:</span></span>
<span class="line"><span style="color:#a6accd">  containers:</span></span>
<span class="line"><span style="color:#a6accd">  - name: nginx</span></span>
<span class="line"><span style="color:#a6accd">    image: nginx:1.13.12</span></span>
<span class="line"><span style="color:#a6accd">    ports:</span></span>
<span class="line"><span style="color:#a6accd">- containerPort: 80</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>Pod的YAML描述内容还有很多，在使用kubeadm部署Kubernetes的时候，就是使用静态Pod的方式运行的相关服务，YAML文件存放在，当然现在很多配置还是看不懂的，带着问题继续学习。</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# ls -l /etc/kubernetes/manifests/</span></span>
<span class="line"><span style="color:#a6accd">total 16</span></span>
<span class="line"><span style="color:#a6accd">-rw------- 1 root root 2041 Feb 11 20:33 etcd.yaml</span></span>
<span class="line"><span style="color:#a6accd">-rw------- 1 root root 2700 Feb 11 20:33 kube-apiserver.yaml</span></span>
<span class="line"><span style="color:#a6accd">-rw------- 1 root root 2345 Feb 11 20:33 kube-controller-manager.yaml</span></span>
<span class="line"><span style="color:#a6accd">-rw------- 1 root root 1080 Feb 11 20:33 kube-scheduler.yaml</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>创建Pod</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubectl create -f nginx-pod.yaml </span></span>
<span class="line"><span style="color:#a6accd">pod "nginx-pod" created</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>查看Pod</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubectl get pod</span></span>
<span class="line"><span style="color:#a6accd">NAME                                READY     STATUS    RESTARTS   AGE</span></span>
<span class="line"><span style="color:#a6accd">nginx-pod                           1/1       Running   0          49s</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>查看Pod更多信息</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubectl get pod -o wide</span></span>
<span class="line"><span style="color:#a6accd">NAME                                READY     STATUS    RESTARTS   AGE       IP           NODE</span></span>
<span class="line"><span style="color:#a6accd">nginx-pod  1/1       Running   0          1m        10.2.53.18   192.168.56.13</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>查看Pod详情</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubectl describe pod nginx-pod</span></span>
<span class="line"><span style="color:#a6accd">Name:         nginx-pod</span></span>
<span class="line"><span style="color:#a6accd">Namespace:    default</span></span>
<span class="line"><span style="color:#a6accd">Node:         192.168.56.13/192.168.56.13</span></span>
<span class="line"><span style="color:#a6accd">Start Time:   Sat, 02 Jun 2018 06:42:53 +0800</span></span>
<span class="line"><span style="color:#a6accd">Labels:       app=nginx</span></span>
<span class="line"><span style="color:#a6accd">Annotations:  &lt;none&gt;</span></span>
<span class="line"><span style="color:#a6accd">Status:       Running</span></span>
<span class="line"><span style="color:#a6accd">IP:           10.2.53.18</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>查看Pod日志</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubectl logs pod/nginx-pod</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p><strong>Pod中的镜像拉取策略</strong> 当kubelet尝试拉取指定的镜像时，[imagePullPolicy]和镜像的标签会生效。</p><ul><li>imagePullPolicy: IfNotPresent：仅当镜像在本地不存在时镜像才被拉取。</li><li>imagePullPolicy: Always：每次启动 pod 的时候都会拉取镜像。</li></ul><p>省略imagePullPolicy，镜像标签为:latest或被省略，Always被应用。 imagePullPolicy被省略，并且镜像的标签被指定且不是:latest，IfNotPresent被应用。 imagePullPolicy: Never：镜像被假设存在于本地。 没有尝试拉取镜像。</p><h1 id="_7-3-第三步：使用controllers管理pod" tabindex="-1">7.3 第三步：使用Controllers管理Pod <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#_7-3-第三步：使用controllers管理pod" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h1><p>在实际的生产环境中，我们其实很少单独创建Pod，而是通过控制器来进行Pod的管理，Kubernetes提供了很多的控制器，一个 Controllers 可以创建和管理很多个 Pod, 也提供复制、初始化，以及提供集群范围的自我恢复的功能。比如说： 如果一个节点宕机，Controller 将调度一个在其他节点上完全相同的 pod 来自动取代当前的 pod。</p><h1 id="_8-1-replication-controller控制器" tabindex="-1">8.1 Replication Controller控制器 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#_8-1-replication-controller控制器" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h1><h1 id="_8-2-replica-sets控制器" tabindex="-1">8.2 Replica Sets控制器 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#_8-2-replica-sets控制器" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h1><h1 id="_8-3-deployment控制器" tabindex="-1">8.3 Deployment控制器 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#_8-3-deployment控制器" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h1><h1 id="_8-4-daemonset控制器" tabindex="-1">8.4 DaemonSet控制器 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#_8-4-daemonset控制器" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h1><p>DaemonSet 确保全部（或者一些）Node 上运行一个 Pod 的副本。当有 Node 加入集群时，也会为他们新增一个 Pod 。当有 Node 从集群移除时，这些 Pod 也会被回收。删除 DaemonSet 将会删除它创建的所有 Pod。 使用 DaemonSet 的一些典型用法：</p><ul><li>运行集群存储 daemon，例如在每个 Node 上运行 glusterd、ceph。</li><li>在每个 Node 上运行日志收集 daemon，例如filebeat、logstash。</li><li>在每个 Node 上运行监控 daemon，例如 Prometheus Node Exporter、collectd、Datadog 代理、Zabbix Agent。</li></ul><p><strong>创建DaemonSet</strong></p><p>DaemonSet的描述文件和Deployment非常相似，只需要修改Kind，并去掉副本数量的配置即可</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 example]# vim nginx-daemonset.yaml</span></span>
<span class="line"><span style="color:#a6accd">apiVersion: apps/v1</span></span>
<span class="line"><span style="color:#a6accd">kind: DaemonSet</span></span>
<span class="line"><span style="color:#a6accd">metadata:</span></span>
<span class="line"><span style="color:#a6accd">  name: nginx-daemonset</span></span>
<span class="line"><span style="color:#a6accd">  labels:</span></span>
<span class="line"><span style="color:#a6accd">    app: nginx</span></span>
<span class="line"><span style="color:#a6accd">spec:</span></span>
<span class="line"><span style="color:#a6accd">  selector:</span></span>
<span class="line"><span style="color:#a6accd">    matchLabels:</span></span>
<span class="line"><span style="color:#a6accd">      app: nginx</span></span>
<span class="line"><span style="color:#a6accd">  template:</span></span>
<span class="line"><span style="color:#a6accd">    metadata:</span></span>
<span class="line"><span style="color:#a6accd">      labels:</span></span>
<span class="line"><span style="color:#a6accd">        app: nginx</span></span>
<span class="line"><span style="color:#a6accd">    spec:</span></span>
<span class="line"><span style="color:#a6accd">      containers:</span></span>
<span class="line"><span style="color:#a6accd">      - name: nginx</span></span>
<span class="line"><span style="color:#a6accd">        image: nginx:1.13.12</span></span>
<span class="line"><span style="color:#a6accd">        ports:</span></span>
<span class="line"><span style="color:#a6accd">        - containerPort: 80</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>查看Pod在Node上的分布</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubectl get pod -o wide</span></span>
<span class="line"><span style="color:#a6accd">NAME                    READY     STATUS    RESTARTS   AGE       IP           NODE</span></span>
<span class="line"><span style="color:#a6accd">nginx-daemonset-hk28q   1/1       Running   0          1m        10.2.56.10   192.168.56.12</span></span>
<span class="line"><span style="color:#a6accd">nginx-daemonset-wtt68   1/1       Running   0          1m        10.2.53.10   192.168.56.13</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubectl get daemonset</span></span>
<span class="line"><span style="color:#a6accd">NAME              DESIRED   CURRENT   READY     UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE</span></span>
<span class="line"><span style="color:#a6accd">nginx-daemonset   2         2         2         2            2           &lt;none&gt;          1m</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><h1 id="_7-4-第四步：使用service管理pod访问" tabindex="-1">7.4 第四步：使用Service管理Pod访问 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#_7-4-第四步：使用service管理pod访问" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h1><p>在上面的小节，我们通过Deployment可以为一个应用创建多个Pod，而且可以动态的进行增加、或者删除多余的Pod，Kubernetes Pod 是有生命周期的，它们可以被创建，也可以被销毁，但是每次Pod的IP地址就会发生变化，外面如何访问到该Pod呢？总不能每次Pod重启就修改访问的IP地址吧。 每个 Pod 都会获取它自己的 IP 地址，但是每次即使这些 IP 地址不总是稳定可依赖的。 这会导致一个问题：在 Kubernetes 集群中，如果一组 Pod（称为 backend）为其它 Pod （称为 frontend）提供服务，那么那些 frontend 该如何发现，并连接到这组 Pod 中的哪些 backend 呢？</p><h1 id="_9-1-service介绍和管理" tabindex="-1">9.1 Service介绍和管理 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#_9-1-service介绍和管理" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h1><h3 id="创建service" tabindex="-1">创建Service <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#创建service" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h3><p>继续我们Nginx的案例，我们为之前的应用创建一个Service</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# cat nginx-service.yaml </span></span>
<span class="line"><span style="color:#a6accd">kind: Service</span></span>
<span class="line"><span style="color:#a6accd">apiVersion: v1</span></span>
<span class="line"><span style="color:#a6accd">metadata:</span></span>
<span class="line"><span style="color:#a6accd">  name: nginx-service</span></span>
<span class="line"><span style="color:#a6accd">spec:</span></span>
<span class="line"><span style="color:#a6accd">  selector:</span></span>
<span class="line"><span style="color:#a6accd">    app: nginx</span></span>
<span class="line"><span style="color:#a6accd">  ports:</span></span>
<span class="line"><span style="color:#a6accd">  - protocol: TCP</span></span>
<span class="line"><span style="color:#a6accd">    port: 80</span></span>
<span class="line"><span style="color:#a6accd">    targetPort: 80</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><ul><li>第1行：定义资源类型为Service</li><li>第2行：定义当前Service API的版本</li><li>第3行：metadata设置</li><li>第4行：设置Service的名称为nginx-service</li><li>第5行：spec: 开始设置Service的内容</li><li>第6行：selector: 为该Service指定一个匹配的标签</li><li>第7行：app: nginx 所有带有标签app ：nginx的Pod将使用该Service</li><li>第8行：ports: 指定Service需要对外的端口</li><li>第9行：设置端口协议：支持TCP和UDP</li><li>第10行：设置Service的端口</li><li>第11行：设置Pod的端口，Kubernetes会将发送给Service端口的连接，转发到Pod的端口上。</li></ul><p>创建Nginx Service</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubectl create -f nginx-service.yaml </span></span>
<span class="line"><span style="color:#a6accd">service "nginx-service" created</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>查看Nginx Service</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubectl get service</span></span>
<span class="line"><span style="color:#a6accd">NAME            TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)   AGE</span></span>
<span class="line"><span style="color:#a6accd">kubernetes      ClusterIP   10.1.0.1      &lt;none&gt;        443/TCP   7h</span></span>
<span class="line"><span style="color:#a6accd">nginx-service   ClusterIP   10.1.184.53   &lt;none&gt;        80/TCP    25s</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>访问Servce IP</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# curl --head 10.1.181.45</span></span>
<span class="line"><span style="color:#a6accd">HTTP/1.1 200 OK</span></span>
<span class="line"><span style="color:#a6accd">Server: nginx/1.11.10</span></span>
<span class="line"><span style="color:#a6accd">Date: Tue, 21 Feb 2017 08:20:42 GMT</span></span>
<span class="line"><span style="color:#a6accd">Content-Type: text/html</span></span>
<span class="line"><span style="color:#a6accd">Content-Length: 612</span></span>
<span class="line"><span style="color:#a6accd">Last-Modified: Tue, 14 Feb 2017 15:36:04 GMT</span></span>
<span class="line"><span style="color:#a6accd">Connection: keep-alive</span></span>
<span class="line"><span style="color:#a6accd">ETag: "58a323e4-264"</span></span>
<span class="line"><span style="color:#a6accd">Accept-Ranges: bytes</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><h1 id="_9-2-service和endpoint" tabindex="-1">9.2 Service和Endpoint <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#_9-2-service和endpoint" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h1><p>Service作为Kubernetes中为Pod实现负载均衡的组件，几乎在所有的文章中为了方便初学者理解，基本上说的是Service会来监听Pod的变化，然后来更新Pod的IP地址。其实这个事情不是Service干的，而是有一个幕后英雄：Endpoint Endpoints表示了一个Service对应的所有Pod副本的访问地址，而Endpoints Controller负责生成和维护所有Endpoints对象的控制器。它负责监听Service和对应的Pod副本的变化。</p><ul><li>如果监测到Service被删除，则删除和该Service同名的Endpoints对象；</li><li>如果监测到新的Service被创建或修改，则根据该Service信息获得相关的Pod列表，然后创建或更新Service对应的Endpoints对象。</li><li>如果监测到Pod的事件，则更新它对应的Service的Endpoints对象。</li></ul><p>kube-proxy进程获取每个Service的Endpoints，实现Service的负载均衡功能。</p><h3 id="创建一个headless-service" tabindex="-1">创建一个Headless Service <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#创建一个headless-service" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h3><p>编写一个Service不使用clusterip</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# cat mysql-service.yaml </span></span>
<span class="line"><span style="color:#a6accd">kind: Service</span></span>
<span class="line"><span style="color:#a6accd">apiVersion: v1</span></span>
<span class="line"><span style="color:#a6accd">metadata:</span></span>
<span class="line"><span style="color:#a6accd">  name: mysql-service</span></span>
<span class="line"><span style="color:#a6accd">spec:</span></span>
<span class="line"><span style="color:#a6accd">  ports:</span></span>
<span class="line"><span style="color:#a6accd">  - protocol: TCP</span></span>
<span class="line"><span style="color:#a6accd">    port: 3306</span></span>
<span class="line"><span style="color:#a6accd">    targetPort: 3306</span></span>
<span class="line"><span style="color:#a6accd">  clusterIP: None</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubectl create -f mysql-service.yaml </span></span>
<span class="line"><span style="color:#a6accd">service "mysql-service" created</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>查看Service，可以放心CLUSTER-IP为None</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubectl get service mysql-service</span></span>
<span class="line"><span style="color:#a6accd">NAME            TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)    AGE</span></span>
<span class="line"><span style="color:#a6accd">mysql-service   ClusterIP   None         &lt;none&gt;        3306/TCP   17s</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>2.创建一个Endpoint</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# vim mysql-endpoint.yaml </span></span>
<span class="line"><span style="color:#a6accd">apiVersion: v1</span></span>
<span class="line"><span style="color:#a6accd">kind: Endpoints</span></span>
<span class="line"><span style="color:#a6accd">metadata:</span></span>
<span class="line"><span style="color:#a6accd"> name: mysql-service</span></span>
<span class="line"><span style="color:#a6accd">subsets:</span></span>
<span class="line"><span style="color:#a6accd">- addresses:</span></span>
<span class="line"><span style="color:#a6accd">  - ip: 192.168.56.13</span></span>
<span class="line"><span style="color:#a6accd">  ports:</span></span>
<span class="line"><span style="color:#a6accd">  - port: 3306</span></span>
<span class="line"><span style="color:#a6accd">    protocol: TCP</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubectl create -f mysql-endpoint.yaml </span></span>
<span class="line"><span style="color:#a6accd">endpoints "mysql-service" created</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>3.查看Service和Endpoint的关联</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubectl get ep mysql-service</span></span>
<span class="line"><span style="color:#a6accd">NAME            ENDPOINTS            AGE</span></span>
<span class="line"><span style="color:#a6accd">mysql-service   192.168.56.13:3306   42s</span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubectl describe svc mysql-service</span></span>
<span class="line"><span style="color:#a6accd">Name:              mysql-service</span></span>
<span class="line"><span style="color:#a6accd">Namespace:         default</span></span>
<span class="line"><span style="color:#a6accd">Labels:            &lt;none&gt;</span></span>
<span class="line"><span style="color:#a6accd">Annotations:       &lt;none&gt;</span></span>
<span class="line"><span style="color:#a6accd">Selector:          &lt;none&gt;</span></span>
<span class="line"><span style="color:#a6accd">Type:              ClusterIP</span></span>
<span class="line"><span style="color:#a6accd">IP:                None</span></span>
<span class="line"><span style="color:#a6accd">Port:              &lt;unset&gt;  3306/TCP</span></span>
<span class="line"><span style="color:#a6accd">TargetPort:        3306/TCP</span></span>
<span class="line"><span style="color:#a6accd">Endpoints:         192.168.56.13:3306</span></span>
<span class="line"><span style="color:#a6accd">Session Affinity:  None</span></span>
<span class="line"><span style="color:#a6accd">Events:            &lt;none&gt;</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><h1 id="_7-5-第五步：使用ingress提供外部访问" tabindex="-1">7.5 第五步：使用Ingress提供外部访问 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#_7-5-第五步：使用ingress提供外部访问" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h1><p>通过Service可以将Kubernetes集群中的服务以IP：Port的方式暴露出来，我们称之为4层的负载均衡，因为这个是OSI七层模型中传输层的功能。</p><p>那么如何实现七层的负载均衡呢，例如像Nginx那样，可以灵活的进行反向代理的设置，根据不同的URL进行转发等，难道我需要自己部署一个Nginx来做这个事情吗？首先，如果你有这个想法，并没有错，甚至你完全可以自己独立部署一个Nginx来完成，但是Kubernetes提供了更好的解决方案就是Ingress。 Ingress就是从kubernetes集群外访问集群的入口，将用户的URL请求转发到不同的service上。ingress相当于nginx反向代理服务器，它包括的规则定义就是URL的路由信息。</p><h2 id="_10-1-ingress-controller" tabindex="-1">10.1 Ingress Controller <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#_10-1-ingress-controller" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h2><p>在学习Service的时候，我们知道最终的负载均衡由kube-proxy和LVS来完成，那么Ingress靠什么来实现7层的路由机制呢？答案是Ingress Controller。</p><p>Ingress Controller 实质上可以理解为是个监视器，Ingress Controller 通过不断地跟 kubernetes API 打交道，实时的感知后端 service、pod 等变化，比如新增和减少 pod，service 增加与减少等；当得到这些变化信息后，Ingress Controller 再结合下文的 Ingress 生成配置，然后更新反向代理负载均衡器，并刷新其配置，达到服务发现的作用。</p><p>Ingress Controller目前有两大开源项目，一个是Nginx Controller，一个是目前比较流行的Traefik，Traefik是一款开源的反向代理与负载均衡工具。它最大的优点是能够与常见的微服务系统直接整合，可以实现自动化动态配置。目前支持Docker, Swarm, Mesos/Marathon, Mesos, Kubernetes, Consul, Etcd, Zookeeper, BoltDB, Rest API等等后端模型。</p><h2 id="ingress-controller-traefik" tabindex="-1">Ingress Controller Traefik <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#ingress-controller-traefik" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h2><h3 id="部署treafik" tabindex="-1">部署Treafik <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#部署treafik" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h3><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubectl label nodes 192.168.56.12 edgenode=true</span></span>
<span class="line"><span style="color:#a6accd">node "192.168.56.12" labeled</span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubectl create -f /srv/addons/ingress/</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><h1 id="_11-第六步：使用pv和pvc管理数据存储" tabindex="-1">11 第六步：使用PV和PVC管理数据存储 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#_11-第六步：使用pv和pvc管理数据存储" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h1><p>截止目前我们所启动Pod的容器中的数据存储都是临时的，因此Pod重启或者被删除的时候，产生在容器中的数据会发生丢失。实际应用中，我们有些应用是无状态，有些应用则需要保持状态数据，确保Pod重启之后能够读取到之前的状态数据，有些应用则作为集群提供服务。这三种服务归纳为无状态服务、有状态服务以及有状态的集群服务，其中后面两个存在数据保存与共享的需求，因此就要采用容器外的存储方案。 Kubernetes中存储中有四个重要的概念：Volume、PersistentVolume（PV）、PersistentVolumeClaim （PVC）、StorageClass。掌握了这四个概念，就掌握了Kubernetes中存储系统的核心。</p><h1 id="_11-1-kubernetes-volume" tabindex="-1">11.1 Kubernetes Volume <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#_11-1-kubernetes-volume" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h1><h1 id="_11-2-persistentvolume（pv）" tabindex="-1">11.2 PersistentVolume（PV） <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#_11-2-persistentvolume（pv）" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h1><p>PersistentVolume（PV）是由管理员设置的存储，它是群集的一部分。就像节点是集群中的资源一样，PV 也是集群中的资源。 PV 是 Volume 之类的卷插件，但具有独立于使用 PV 的 Pod 的生命周期。此 API 对象包含存储实现的细节，即 NFS、iSCSI 或特定于云供应商的存储系统。</p><p><strong>1.安装并配置NFS</strong></p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# yum install -y nfs-utils rpcbind</span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# mkdir -p /data/k8s-nfs</span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# vim /etc/exports</span></span>
<span class="line"><span style="color:#a6accd">/data/k8s-nfs *(rw,sync,no_root_squash)</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>启动NFS</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# systemctl enable rpcbind nfs</span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# systemctl start rpcbind nfs</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p><strong>2.创建并查看PV</strong></p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# vim nfs-pv.yaml</span></span>
<span class="line"><span style="color:#a6accd">apiVersion: v1</span></span>
<span class="line"><span style="color:#a6accd">kind: PersistentVolume</span></span>
<span class="line"><span style="color:#a6accd">metadata:</span></span>
<span class="line"><span style="color:#a6accd">  name: pv-demo</span></span>
<span class="line"><span style="color:#a6accd">spec:</span></span>
<span class="line"><span style="color:#a6accd">  capacity:</span></span>
<span class="line"><span style="color:#a6accd">storage: 1Gi</span></span>
<span class="line"><span style="color:#a6accd">  volumeMode: Filesystem</span></span>
<span class="line"><span style="color:#a6accd">  accessModes:</span></span>
<span class="line"><span style="color:#a6accd">    - ReadWriteOnce</span></span>
<span class="line"><span style="color:#a6accd">  persistentVolumeReclaimPolicy: Recycle</span></span>
<span class="line"><span style="color:#a6accd">  storageClassName: nfs</span></span>
<span class="line"><span style="color:#a6accd">  nfs:</span></span>
<span class="line"><span style="color:#a6accd">    path: /data/k8s-nfs/pv-demo</span></span>
<span class="line"><span style="color:#a6accd">    server: 192.168.56.11</span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubectl create -f nfs-pv.yaml </span></span>
<span class="line"><span style="color:#a6accd">persistentvolume "pv-demo" created</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>查看创建的PV</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubectl get pv</span></span>
<span class="line"><span style="color:#a6accd">NAME      CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM     STORAGECLASS   REASON    AGE</span></span>
<span class="line"><span style="color:#a6accd">pv-demo   1Gi        RWO            Recycle          Available             nfs                      15s</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><h1 id="_11-3-persistentvolumeclaim（pvc）" tabindex="-1">11.3 PersistentVolumeClaim（PVC） <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#_11-3-persistentvolumeclaim（pvc）" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h1><p>PersistentVolumeClaim（PVC）是用户存储的请求。它与 Pod 相似。Pod 消耗节点资源，PVC 消耗 PV 资源。Pod 可以请求特定级别的资源（CPU 和内存）。声明可以请求特定的大小和访问模式（例如，可以以读/写一次或 只读多次模式挂载）。</p><p>1.创建PVC</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# vim nfs-pvc.yaml</span></span>
<span class="line"><span style="color:#a6accd">apiVersion: v1</span></span>
<span class="line"><span style="color:#a6accd">kind: PersistentVolumeClaim</span></span>
<span class="line"><span style="color:#a6accd">metadata:</span></span>
<span class="line"><span style="color:#a6accd">  name: pvc-demo</span></span>
<span class="line"><span style="color:#a6accd">spec:</span></span>
<span class="line"><span style="color:#a6accd">  accessModes:</span></span>
<span class="line"><span style="color:#a6accd">    - ReadWriteOnce</span></span>
<span class="line"><span style="color:#a6accd">  resources:</span></span>
<span class="line"><span style="color:#a6accd">    requests:</span></span>
<span class="line"><span style="color:#a6accd">      storage: 1Gi</span></span>
<span class="line"><span style="color:#a6accd">  storageClassName: nfs</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>创建并查看PVC</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubectl create -f nfs-pvc.yaml </span></span>
<span class="line"><span style="color:#a6accd">persistentvolumeclaim "pvc-demo" created</span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubectl get pvc</span></span>
<span class="line"><span style="color:#a6accd">NAME       STATUS    VOLUME    CAPACITY   ACCESS MODES   STORAGECLASS   AGE</span></span>
<span class="line"><span style="color:#a6accd">pvc-demo   Bound     pv-demo   1Gi        RWO            nfs            6s</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>2.使用PVC</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# vim nginx-deployment-pvc.yaml</span></span>
<span class="line"><span style="color:#a6accd">apiVersion: apps/v1</span></span>
<span class="line"><span style="color:#a6accd">kind: Deployment</span></span>
<span class="line"><span style="color:#a6accd">metadata:</span></span>
<span class="line"><span style="color:#a6accd">  name: nginx-deployment</span></span>
<span class="line"><span style="color:#a6accd">  labels:</span></span>
<span class="line"><span style="color:#a6accd">    app: nginx</span></span>
<span class="line"><span style="color:#a6accd">spec:</span></span>
<span class="line"><span style="color:#a6accd">  replicas: 3</span></span>
<span class="line"><span style="color:#a6accd">  selector:</span></span>
<span class="line"><span style="color:#a6accd">    matchLabels:</span></span>
<span class="line"><span style="color:#a6accd">      app: nginx</span></span>
<span class="line"><span style="color:#a6accd">  template:</span></span>
<span class="line"><span style="color:#a6accd">    metadata:</span></span>
<span class="line"><span style="color:#a6accd">      labels:</span></span>
<span class="line"><span style="color:#a6accd">        app: nginx</span></span>
<span class="line"><span style="color:#a6accd">    spec:</span></span>
<span class="line"><span style="color:#a6accd">      containers:</span></span>
<span class="line"><span style="color:#a6accd">      - name: nginx</span></span>
<span class="line"><span style="color:#a6accd">        image: nginx:1.13.12</span></span>
<span class="line"><span style="color:#a6accd">        ports:</span></span>
<span class="line"><span style="color:#a6accd">        - containerPort: 80</span></span>
<span class="line"><span style="color:#a6accd">        volumeMounts:</span></span>
<span class="line"><span style="color:#a6accd">        - mountPath: "/usr/share/nginx/html"</span></span>
<span class="line"><span style="color:#a6accd">          name: pvc-demo</span></span>
<span class="line"><span style="color:#a6accd">      volumes:</span></span>
<span class="line"><span style="color:#a6accd">      - name: pvc-demo</span></span>
<span class="line"><span style="color:#a6accd">        persistentVolumeClaim:</span></span>
<span class="line"><span style="color:#a6accd">          claimName: pvc-demo</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><h1 id="_11-4-storageclass" tabindex="-1">11.4 StorageClass <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#_11-4-storageclass" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h1><h1 id="_7-第七步：使用rancher管理kubernetes集群" tabindex="-1">7 第七步：使用Rancher管理Kubernetes集群 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#_7-第七步：使用rancher管理kubernetes集群" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h1><p>现在我们已经具备把应用迁移到Kubernetes中来的能力，那么现在，迁移后，日常的运维工作就发生的变化，截止目前，在生产环境中，我们很少使用官方自带的Dashbaord来完成日常的运维工作，而是使用第三方的运维工具Rancher。</p><h2 id="_7-1-rancher快速入门" tabindex="-1">7.1 Rancher快速入门 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#_7-1-rancher快速入门" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h2><p>快速部署单机版Rancher</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# mkdir /opt/rancher</span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# docker run -d --restart=unless-stopped -v /opt/rancher:/var/lib/rancher/ -p 80:80 -p 443:443 rancher/rancher</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><h2 id="_7-2-使用rancher进行日常管理" tabindex="-1">7.2 使用Rancher进行日常管理 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#_7-2-使用rancher进行日常管理" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h2><h2 id="_7-3-rancher生产集群部署" tabindex="-1">7.3 Rancher生产集群部署 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#_7-3-rancher生产集群部署" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h2><h1 id="第六部分-管理kubernetes中的应用" tabindex="-1">第六部分 管理Kubernetes中的应用 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#第六部分-管理kubernetes中的应用" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h1><h1 id="_13-应用的资源限制和健康检查" tabindex="-1">13 应用的资源限制和健康检查 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#_13-应用的资源限制和健康检查" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h1><h1 id="_13-1-应用的资源限制" tabindex="-1">13.1 应用的资源限制 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#_13-1-应用的资源限制" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h1><h1 id="_13-2-应用的健康检查" tabindex="-1">13.2 应用的健康检查 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#_13-2-应用的健康检查" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h1><h3 id="liveness探测" tabindex="-1">Liveness探测 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#liveness探测" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h3><p>Kubernetes有两种探测机制，Liveness和Readiness，配置都是相似的，只是实现的功能不同。 Liveness探测是针对Pod健康状态的探测，类似于集群中的健康检查，用户可以自定义这个健康检查的条件，如果探测失败，Kubernetes将会重启容器。 如果您希望容器在探测失败时被杀死并重新启动，那么请指定一个Liveness配置，并指定restartPolicy 为 Always 或 OnFailure。 配置案例</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">livenessProbe:</span></span>
<span class="line"><span style="color:#a6accd">exec:</span></span>
<span class="line"><span style="color:#a6accd">    command:</span></span>
<span class="line"><span style="color:#a6accd">    - ps aux | grep nginx</span></span>
<span class="line"><span style="color:#a6accd">initialDelaySeconds: 10</span></span>
<span class="line"><span style="color:#a6accd">periodSeconds: 5</span></span>
<span class="line"><span style="color:#a6accd">timeoutSeconds: 3</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><h3 id="readiness探测" tabindex="-1">Readiness探测 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#readiness探测" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h3><p>Readiness探测是探测Pod是否准备好对外提供访问，例如我们在Pod里面运行一个Tomcat的容器，里面运行了一个Jenkins的应用，那么等Jenkins完全启动能提供服务可能需要1分钟，所以在在1分钟之前是不能提供给用户访问的，也就是不能加入Service的负载均衡中，这个就靠Readiness探测来控制。 Readiness用来控制告诉Kubernetes什么时间可以将容器加入到Service的负载均衡中，配置方法和Liveness一样，只需要修改livennessProbe替换为readinessProbe即可。</p><h2 id="健康检查的方法" tabindex="-1">健康检查的方法 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#健康检查的方法" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h2><p>Kubernetes的健康检查是由运行在各个Node上的kubelet来完成的，kubelet目前支持以下三种健康检查的方法：</p><ul><li>ExecAction：在容器中执行指定的命令。如果命令退出时状态码为0，则认为诊断成功。</li><li>TCPSocketAction:对指定端口上容器的IP地址执行TCP检查。如果端口是打开的，则认为诊断是成功的。</li><li>HTTPGetAction:对指定端口和路径上容器的IP地址执行HTTP Get请求。如果响应的状态码大于或等于200，小于400，则认为诊断是成功的。</li></ul><p>以上三种健康检查的方法会有三种返回结果：</p><ul><li><p>Success：成功，容器通过诊断。</p></li><li><p>Failure：失败，容器诊断失败。</p></li><li><p>Unknown：探测失败，无法执行探测，所以不应该采取任何行动。</p><p>针对于探针有以下配置参数，需要注意不管是Liveness还是Readiness探测，探针的使用都是相同的，唯一的不同是探测完毕后，执行操作的不同。</p></li><li><p>initialDelaySeconds: 探测的延迟时间，单位是秒。也就是说在容器启动多少秒之后开始进行第一次探测，例如你启动一个Java的应用需要50秒，那么这个值就需要大于50s。所以这个值是需要根据应用的具体情况来设置。</p></li><li><p>periodSeconds：探测执行的周期时间，单位是秒。是指每隔多长时间执行一次探测，频率越高，发现故障的时间也就越短，并不是越短越好。如果应用服务不够稳定，太高的频率反而会导致很多你认为的“误报”。默认是10秒，最小值是1秒。</p></li><li><p>timeoutSeconds: 探测超时时间，单位是秒，执行探测如果超过这个时间没有返回结果，变意味着探测的结果是失败。默认为1秒。最小值是1秒。</p></li><li><p>failureThreshold：探测成功后，最少连续探测失败多少次才被认定为失败。这个是Kubernetes将在放弃之前尝试失败阈值时间。放弃生命探测意味着重新启动Pod。一旦准备就绪，Pod将被标记为未准备就绪。默认为3。最小值是1。</p></li><li><p>successThreshold: 在探测失败后，最少连续探测成功多少次才被认定为成功。默认为1，也就是必须探测成功1次，才能认为状态恢复，最小值是1。</p><h1 id="管理应用的dns访问" tabindex="-1">管理应用的DNS访问 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#管理应用的dns访问" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h1></li></ul><h1 id="_14-1-kubernetes中的dns" tabindex="-1"><a target="_blank" rel="noreferrer" href="http://k8s.unixhot.com/"><!--[-->14.1 Kubernetes中的DNS<!--]--><!----></a> <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#_14-1-kubernetes中的dns" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h1><h1 id="应用的dns管理" tabindex="-1">应用的DNS管理 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#应用的dns管理" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h1><h3 id="pod的域名解析策略" tabindex="-1">Pod的域名解析策略 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#pod的域名解析策略" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h3><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubectl run dns-test --generator=run-pod/v1 --image=alpine --replicas=1 sleep 360000</span></span>
<span class="line"><span style="color:#a6accd">pod/dns-test created</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>查看Pod</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubectl get pod dns-test</span></span>
<span class="line"><span style="color:#a6accd">NAME       READY   STATUS    RESTARTS   AGE</span></span>
<span class="line"><span style="color:#a6accd">dns-test   1/1     Running   0          79s</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>Pod默认的DNS配置</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubectl exec -it dns-test /bin/sh</span></span>
<span class="line"><span style="color:#a6accd">/ # cat /etc/resolv.conf </span></span>
<span class="line"><span style="color:#a6accd">nameserver 10.1.0.10</span></span>
<span class="line"><span style="color:#a6accd">search default.svc.cluster.local svc.cluster.local cluster.local</span></span>
<span class="line"><span style="color:#a6accd">options ndots:5</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>如何访问Service名称</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">/ # ping -c 3 wordpress-service.default.svc.cluster.local</span></span>
<span class="line"><span style="color:#a6accd">PING wordpress-service.default.svc.cluster.local (10.1.92.244): 56 data bytes</span></span>
<span class="line"><span style="color:#a6accd">64 bytes from 10.1.92.244: seq=0 ttl=64 time=0.074 ms</span></span>
<span class="line"><span style="color:#a6accd">64 bytes from 10.1.92.244: seq=1 ttl=64 time=0.141 ms</span></span>
<span class="line"><span style="color:#a6accd">64 bytes from 10.1.92.244: seq=2 ttl=64 time=0.187 ms</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">--- wordpress-service.default.svc.cluster.local ping statistics ---</span></span>
<span class="line"><span style="color:#a6accd">3 packets transmitted, 3 packets received, 0% packet loss</span></span>
<span class="line"><span style="color:#a6accd">round-trip min/avg/max = 0.074/0.134/0.187 ms</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>DNS查询策略</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubectl get pod dns-test -o yaml | grep dnsPolicy</span></span>
<span class="line"><span style="color:#a6accd">  dnsPolicy: ClusterFirst</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><ul><li>Default: Pod从其运行的节点中继承名称解析配置。</li><li>ClusterFirst:（默认策略）与配置的群集域名后缀不匹配的任何DNS查询都将转发到从节点继承的上游名称服务器。</li><li>ClusterFirstWithHostNet: 如果Pod使用了hostNetwork（例如Ingress Controller Treafik就是使用了hostNetwok），应显式设置其DNS策略为“ClusterFirstWithHostNet”。</li><li>None: 它允许Pod忽略Kubernetes环境中的DNS设置，这时候会使用Pod Spec中的dnsConfig字段提供的DNS设置。</li></ul><h2 id="应用的dns管理-1" tabindex="-1">应用的DNS管理 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#应用的dns管理-1" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h2><h2 id="_15-1-使用configmap管理应用配置" tabindex="-1">15.1 使用ConfigMap管理应用配置 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#_15-1-使用configmap管理应用配置" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h2><h3 id="通过kubectl命令创建configmap" tabindex="-1">通过kubectl命令创建ConfigMap <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#通过kubectl命令创建configmap" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h3><p><strong>创建一个名称为cmd-config的ConfigMap</strong></p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@k8s-master1 ~]# kubectl create configmap cmd-config --from-literal=host=www.unixhot.com</span></span>
<span class="line"><span style="color:#a6accd">configmap/cmd-config created</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p><strong>查看ConfigMap</strong></p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@k8s-master1 ~]# kubectl get configmap</span></span>
<span class="line"><span style="color:#a6accd">NAME         DATA   AGE</span></span>
<span class="line"><span style="color:#a6accd">cmd-config   1      63s</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p><strong>查看ConfigMap内容</strong></p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@k8s-master1 ~]# kubectl describe configmap cmd-config</span></span>
<span class="line"><span style="color:#a6accd">Name:         cmd-config</span></span>
<span class="line"><span style="color:#a6accd">Namespace:    default</span></span>
<span class="line"><span style="color:#a6accd">Labels:       &lt;none&gt;</span></span>
<span class="line"><span style="color:#a6accd">Annotations:  &lt;none&gt;</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">Data</span></span>
<span class="line"><span style="color:#a6accd">====</span></span>
<span class="line"><span style="color:#a6accd">host:</span></span>
<span class="line"><span style="color:#a6accd">----</span></span>
<span class="line"><span style="color:#a6accd">www.unixhot.com</span></span>
<span class="line"><span style="color:#a6accd">Events:  &lt;none&gt;</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p><strong>ConfigMap中包含多个键值对</strong> 可以多次使用--from-literal为一个ConfigMap创建多个键值对，中间用空格分隔</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@k8s-master1 ~]# kubectl create configmap mcmd-config --from-literal=host=www.unixhot.com --from-literal=port=443 --from-literal=ssl=on</span></span>
<span class="line"><span style="color:#a6accd">configmap/mcmd-config created</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><h3 id="通过yaml文件创建configmap" tabindex="-1">通过YAML文件创建ConfigMap <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#通过yaml文件创建configmap" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h3><p>查看已创建的ConfigMap生成的YAML文件</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@k8s-master1 ~]# kubectl get configmap mcmd-config -o yaml</span></span>
<span class="line"><span style="color:#a6accd">apiVersion: v1</span></span>
<span class="line"><span style="color:#a6accd">data:</span></span>
<span class="line"><span style="color:#a6accd">  host: www.unixhot.com</span></span>
<span class="line"><span style="color:#a6accd">  port: "443"</span></span>
<span class="line"><span style="color:#a6accd">  ssl: "on"</span></span>
<span class="line"><span style="color:#a6accd">kind: ConfigMap</span></span>
<span class="line"><span style="color:#a6accd">metadata:</span></span>
<span class="line"><span style="color:#a6accd">  creationTimestamp: "2019-11-05T01:45:13Z"</span></span>
<span class="line"><span style="color:#a6accd">  name: mcmd-config</span></span>
<span class="line"><span style="color:#a6accd">  namespace: default</span></span>
<span class="line"><span style="color:#a6accd">  resourceVersion: "5394993"</span></span>
<span class="line"><span style="color:#a6accd">  selfLink: /api/v1/namespaces/default/configmaps/mcmd-config</span></span>
<span class="line"><span style="color:#a6accd">  uid: 02012d69-e324-4e9d-ba04-7132e9f6ecd8</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>只需要将metadata中无需指定的字段去掉即可生成一个YAML文件。</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@k8s-master1 ~]# kubectl get configmap mcmd-config -o yaml &gt; mcmd-config-v2.yaml</span></span>
<span class="line"><span style="color:#a6accd">[root@k8s-master1 ~]# vim mcmd-config-v2.yaml </span></span>
<span class="line"><span style="color:#a6accd">apiVersion: v1</span></span>
<span class="line"><span style="color:#a6accd">data:</span></span>
<span class="line"><span style="color:#a6accd">  host: www.unixhot.com</span></span>
<span class="line"><span style="color:#a6accd">  port: "443"</span></span>
<span class="line"><span style="color:#a6accd">  ssl: "on"</span></span>
<span class="line"><span style="color:#a6accd">kind: ConfigMap</span></span>
<span class="line"><span style="color:#a6accd">metadata:</span></span>
<span class="line"><span style="color:#a6accd">  name: mcmd-config-v2</span></span>
<span class="line"><span style="color:#a6accd">  namespace: default</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p><a target="_blank" rel="noreferrer" href="http://xn--metadata-0n3mp82lcujlhxj58f8qvb.name"><!--[-->注意需要修改metadata.name<!--]--><!----></a>,修改完毕后直接创建即可</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@k8s-master1 ~]# kubectl create -f mcmd-config-v2.yaml </span></span>
<span class="line"><span style="color:#a6accd">configmap/mcmd-config-v2 created</span></span>
<span class="line"><span style="color:#a6accd">[root@k8s-master1 ~]# kubectl get configmap</span></span>
<span class="line"><span style="color:#a6accd">NAME             DATA   AGE</span></span>
<span class="line"><span style="color:#a6accd">cmd-config       1      24m</span></span>
<span class="line"><span style="color:#a6accd">mcmd-config      3      16m</span></span>
<span class="line"><span style="color:#a6accd">mcmd-config-v2   3      9s</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><h3 id="通过文件创建configmap" tabindex="-1">通过文件创建ConfigMap <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#通过文件创建configmap" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h3><p>ConfigMap除了可以存储单个或者多个键值对之外，可以存储完整的配置文件，将单个配置文件直接转换为ConfigMap在生产中十分常用</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@k8s-master1 ~]# kubectl create configmap file-config --from-file=/etc/hosts</span></span>
<span class="line"><span style="color:#a6accd">configmap/file-config created</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>可以看到ConfigMap直接存储了文件的内容，Key名称为文件名hosts，也可以手动指定Key的名称。</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@k8s-master1 ~]# kubectl describe configmap file-config</span></span>
<span class="line"><span style="color:#a6accd">Name:         file-config</span></span>
<span class="line"><span style="color:#a6accd">Namespace:    default</span></span>
<span class="line"><span style="color:#a6accd">Labels:       &lt;none&gt;</span></span>
<span class="line"><span style="color:#a6accd">Annotations:  &lt;none&gt;</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">Data</span></span>
<span class="line"><span style="color:#a6accd">====</span></span>
<span class="line"><span style="color:#a6accd">hosts:</span></span>
<span class="line"><span style="color:#a6accd">----</span></span>
<span class="line"><span style="color:#a6accd">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span></span>
<span class="line"><span style="color:#a6accd">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span></span>
<span class="line"><span style="color:#a6accd">192.168.99.27 k8s-master1 k8s-master1.dianjoy.com </span></span>
<span class="line"><span style="color:#a6accd">192.168.99.28 k8s-master2 k8s-master2.dianjoy.com</span></span>
<span class="line"><span style="color:#a6accd">192.168.99.29 k8s-master3 k8s-master3.dianjoy.com</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">Events:  &lt;none&gt;</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>将Key手动指定为host-hosts</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@k8s-master1 ~]# kubectl create configmap file-config-v2 --from-file=host-hosts=/etc/hosts</span></span>
<span class="line"><span style="color:#a6accd">configmap/file-config-v2 created</span></span>
<span class="line"><span style="color:#a6accd">[root@k8s-master1 ~]# kubectl describe configmap file-config-v2</span></span>
<span class="line"><span style="color:#a6accd">Name:         file-config-v2</span></span>
<span class="line"><span style="color:#a6accd">Namespace:    default</span></span>
<span class="line"><span style="color:#a6accd">Labels:       &lt;none&gt;</span></span>
<span class="line"><span style="color:#a6accd">Annotations:  &lt;none&gt;</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">Data</span></span>
<span class="line"><span style="color:#a6accd">====</span></span>
<span class="line"><span style="color:#a6accd">host-hosts:</span></span>
<span class="line"><span style="color:#a6accd">----</span></span>
<span class="line"><span style="color:#a6accd">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span></span>
<span class="line"><span style="color:#a6accd">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span></span>
<span class="line"><span style="color:#a6accd">192.168.99.27 k8s-master1 k8s-master1.dianjoy.com </span></span>
<span class="line"><span style="color:#a6accd">192.168.99.28 k8s-master2 k8s-master2.dianjoy.com</span></span>
<span class="line"><span style="color:#a6accd">192.168.99.29 k8s-master3 k8s-master3.dianjoy.com</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">Events:  &lt;none&gt;</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><h3 id="从目录创建configmap" tabindex="-1">从目录创建ConfigMap <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#从目录创建configmap" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h3><p>ConfigMap还支持通过目录创建，kubectl会为目录中的每个文件单独创建条目，需要注意的是如果目录下面包含子目录，会忽略这些子目录和子目录里面的内容。</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@k8s-master1 ~]# kubectl create configmap dir-config --from-file=/etc/kubernetes</span></span>
<span class="line"><span style="color:#a6accd">configmap/dir-config created</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><h3 id="混合选项创建configmap" tabindex="-1">混合选项创建ConfigMap <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#混合选项创建configmap" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h3><p>同时使用命令行、文件、目录创建ConfigMap也是支持的，只需要使用不同的选项即可。</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@k8s-master1 ~]# kubectl create configmap mycp --from-literal=env=test \</span></span>
<span class="line"><span style="color:#a6accd"> --from-file=/etc/hosts \</span></span>
<span class="line"><span style="color:#a6accd"> --from-file=myhosts=/etc/hosts \</span></span>
<span class="line"><span style="color:#a6accd"> --from-file=/etc/kubernetes</span></span>
<span class="line"><span style="color:#a6accd">configmap/mycp created</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>ConfigMap的内容可以通过环境变量的形成传递给容器，也可通过和Volume的形式挂载到容器中。</p><h3 id="通过环境变量给容器传递configmap" tabindex="-1">通过环境变量给容器传递ConfigMap <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#通过环境变量给容器传递configmap" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h3><p>可以将ConfigMap中的键值对数据通过环境变量的形式传递到容器中，这样在配置容器的时候有一些数据可以使用环境变量，然后使用ConfigMap进行填充，这样就可以实现配置和Pod的分离。</p><h2 id="_15-2-使用secret管理敏感数据" tabindex="-1">15.2 使用Secret管理敏感数据 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#_15-2-使用secret管理敏感数据" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h2><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">在应用启动过程中经常会有一些敏感信息需要存储，例如用户名和密码等，如果直接明文的方式保存会有安全风险。在Kubernetes中Secret这个资源对象类型用来保存敏感信息，例如密码、密钥、访问令牌、SSH Key等你认为需要保密的敏感信息。相对于将这些内容保存到容器镜像或者Pod的定义文件中，更加的灵活和安全。</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><h3 id="配置pod使用harbor镜像" tabindex="-1">配置Pod使用Harbor镜像 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#配置pod使用harbor镜像" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h3><p>1．docker login得到 docker密码文件</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# docker login 192.168.56.11</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>2.对密码文件进行加密</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# cat /root/.docker/config.json |base64</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>3.创建harbor使用的Secret YAML文件：</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# vim harbor-secret.yaml </span></span>
<span class="line"><span style="color:#a6accd">apiVersion: v1</span></span>
<span class="line"><span style="color:#a6accd">kind: Secret</span></span>
<span class="line"><span style="color:#a6accd">metadata:</span></span>
<span class="line"><span style="color:#a6accd">  name: harbor-secret</span></span>
<span class="line"><span style="color:#a6accd">  namespace: default</span></span>
<span class="line"><span style="color:#a6accd">data:</span></span>
<span class="line"><span style="color:#a6accd">  .dockerconfigjson: 'ewoJImF1dGhzIjogewoJCSJyZWcuZ3JlYXRvcHMubmV0IjogewoJCQkiYXV0aCI6ICJZV1J0YVc0Nk1YRmhlbmh6ZHpJPSIKCQl9Cgl9Cn0='</span></span>
<span class="line"><span style="color:#a6accd">type: kubernetes.io/dockerconfigjson</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>4.创建Secret</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@jenkins k8s-deploy]# kubectl create -f reg-harbor.yaml </span></span>
<span class="line"><span style="color:#a6accd">secret "reg-harbor" created</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>5.创建pod并挂载资源</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">apiVersion: v1</span></span>
<span class="line"><span style="color:#a6accd">kind: Pod</span></span>
<span class="line"><span style="color:#a6accd">metadata:</span></span>
<span class="line"><span style="color:#a6accd">  name: sectest</span></span>
<span class="line"><span style="color:#a6accd">spec:</span></span>
<span class="line"><span style="color:#a6accd">  containers:</span></span>
<span class="line"><span style="color:#a6accd">  - name: sectest</span></span>
<span class="line"><span style="color:#a6accd">    image: 123.207.154.16/base/redis:alpine</span></span>
<span class="line"><span style="color:#a6accd">    ports:</span></span>
<span class="line"><span style="color:#a6accd">    - containerPort: 6379</span></span>
<span class="line"><span style="color:#a6accd">  imagePullSecrets:</span></span>
<span class="line"><span style="color:#a6accd">    - name: harbor-secret</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><h1 id="使用helm管理kubernetes应用" tabindex="-1">使用Helm管理Kubernetes应用 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#使用helm管理kubernetes应用" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h1><p>通过前面的学习，掌握了将应用迁移至Kubernetes的步骤和技巧，过程比较艰辛。例如我们创建一个应用，涉及到Deployment、Service、Ingress、PV、PVC，如何有效的管理这些资源呢，Kubernetes给出了一个最佳实践就是Helm。 Helm是一个kubernetes应用的包管理工具，用来管理charts——预先配置好的安装包资源，有点类似于Ubuntu的APT和CentOS中的yum。 Helm chart是用来封装kubernetes原生应用程序的yaml文件，可以在你部署应用的时候自定义应用程序的一些metadata，便与应用程序的分发。</p><p>Helm和charts的主要作用：</p><ul><li>应用程序封装</li><li>版本管理</li><li>依赖检查</li><li>便于应用程序分发</li></ul><h2 id="helm部署" tabindex="-1">Helm部署 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#helm部署" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h2><h3 id="安装helm" tabindex="-1">安装Helm <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#安装helm" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h3><p>1.部署Helm客户端</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# cd /usr/local/src</span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 src]# wget https://get.helm.sh/helm-v3.0.2-linux-amd64.tar.gz</span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 src]# tar zxf helm-v3.0.2-linux-amd64.tar.gz</span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 src]# mv linux-amd64/helm /usr/local/bin/</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>2.验证安装是否成功</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# helm version</span></span>
<span class="line"><span style="color:#a6accd">version.BuildInfo{Version:"v3.0.2", GitCommit:"19e47ee3283ae98139d98460de796c1be1e3975f", GitTreeState:"clean", GoVersion:"go1.13.5"}</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><h3 id="使用helm部署第一个应用" tabindex="-1">使用Helm部署第一个应用 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#使用helm部署第一个应用" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h3><p>4.搜索Helm应用</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# helm search jenkins</span></span>
<span class="line"><span style="color:#a6accd">NAME              CHART VERSION    APP VERSION    DESCRIPTION                                       </span></span>
<span class="line"><span style="color:#a6accd">stable/jenkins    0.13.5           2.73           Open source continuous integration server. It s...</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>5.查看仓库</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# helm repo list</span></span>
<span class="line"><span style="color:#a6accd">NAME      URL                                                   </span></span>
<span class="line"><span style="color:#a6accd">stable    https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts</span></span>
<span class="line"><span style="color:#a6accd">local     http://127.0.0.1:8879/charts</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>6.安装第一个应用</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# helm install stable/jenkins</span></span>
<span class="line"><span style="color:#a6accd">NAME:   viable-seal</span></span>
<span class="line"><span style="color:#a6accd">LAST DEPLOYED: Thu Jul 26 19:21:07 2018</span></span>
<span class="line"><span style="color:#a6accd">NAMESPACE: default</span></span>
<span class="line"><span style="color:#a6accd">STATUS: DEPLOYED</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">RESOURCES:</span></span>
<span class="line"><span style="color:#a6accd">==&gt; v1/ConfigMap</span></span>
<span class="line"><span style="color:#a6accd">NAME                       DATA  AGE</span></span>
<span class="line"><span style="color:#a6accd">viable-seal-jenkins        3     1s</span></span>
<span class="line"><span style="color:#a6accd">viable-seal-jenkins-tests  1     1s</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">==&gt; v1/PersistentVolumeClaim</span></span>
<span class="line"><span style="color:#a6accd">NAME                 STATUS   VOLUME  CAPACITY  ACCESS MODES  STORAGECLASS  AGE</span></span>
<span class="line"><span style="color:#a6accd">viable-seal-jenkins  Pending  1s</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">==&gt; v1/Service</span></span>
<span class="line"><span style="color:#a6accd">NAME                       TYPE          CLUSTER-IP   EXTERNAL-IP  PORT(S)         AGE</span></span>
<span class="line"><span style="color:#a6accd">viable-seal-jenkins-agent  ClusterIP     10.1.154.54  &lt;none&gt;       50000/TCP       1s</span></span>
<span class="line"><span style="color:#a6accd">viable-seal-jenkins        LoadBalancer  10.1.63.24   &lt;pending&gt;    8080:20031/TCP  0s</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">==&gt; v1beta1/Deployment</span></span>
<span class="line"><span style="color:#a6accd">NAME                 DESIRED  CURRENT  UP-TO-DATE  AVAILABLE  AGE</span></span>
<span class="line"><span style="color:#a6accd">viable-seal-jenkins  1        1        1           0          0s</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">==&gt; v1/Pod(related)</span></span>
<span class="line"><span style="color:#a6accd">NAME                                  READY  STATUS   RESTARTS  AGE</span></span>
<span class="line"><span style="color:#a6accd">viable-seal-jenkins-7f5c7bd8d4-gc5hv  0/1    Pending  0         0s</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">==&gt; v1/Secret</span></span>
<span class="line"><span style="color:#a6accd">NAME                 TYPE    DATA  AGE</span></span>
<span class="line"><span style="color:#a6accd">viable-seal-jenkins  Opaque  2     1s</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">NOTES:</span></span>
<span class="line"><span style="color:#a6accd">1. Get your 'admin' user password by running:</span></span>
<span class="line"><span style="color:#a6accd">  printf $(kubectl get secret --namespace default viable-seal-jenkins -o jsonpath="{.data.jenkins-admin-password}" | base64 --decode);echo</span></span>
<span class="line"><span style="color:#a6accd">2. Get the Jenkins URL to visit by running these commands in the same shell:</span></span>
<span class="line"><span style="color:#a6accd">  NOTE: It may take a few minutes for the LoadBalancer IP to be available.</span></span>
<span class="line"><span style="color:#a6accd">        You can watch the status of by running 'kubectl get svc --namespace default -w viable-seal-jenkins'</span></span>
<span class="line"><span style="color:#a6accd">  export SERVICE_IP=$(kubectl get svc --namespace default viable-seal-jenkins --template "{{ range (index .status.loadBalancer.ingress 0) }}{{ . }}{{ end }}")</span></span>
<span class="line"><span style="color:#a6accd">  echo http://$SERVICE_IP:8080/login</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">3. Login with the password from step 1 and the username: admin</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">For more information on running Jenkins on Kubernetes, visit:</span></span>
<span class="line"><span style="color:#a6accd">https://cloud.google.com/solutions/jenkins-on-container-engine</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><h1 id="_15-2-深入理解helm" tabindex="-1">15.2 深入理解Helm <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#_15-2-深入理解helm" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h1><h3 id="helm组件" tabindex="-1">Helm组件 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#helm组件" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h3><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# tree ~/.helm/</span></span>
<span class="line"><span style="color:#a6accd">/root/.helm/</span></span>
<span class="line"><span style="color:#a6accd">├── cache</span></span>
<span class="line"><span style="color:#a6accd">│   └── archive</span></span>
<span class="line"><span style="color:#a6accd">│       └── jenkins-0.13.5.tgz</span></span>
<span class="line"><span style="color:#a6accd">├── plugins</span></span>
<span class="line"><span style="color:#a6accd">├── repository</span></span>
<span class="line"><span style="color:#a6accd">│   ├── cache</span></span>
<span class="line"><span style="color:#a6accd">│   │   ├── local-index.yaml -&gt; /root/.helm/repository/local/index.yaml</span></span>
<span class="line"><span style="color:#a6accd">│   │   └── stable-index.yaml</span></span>
<span class="line"><span style="color:#a6accd">│   ├── local</span></span>
<span class="line"><span style="color:#a6accd">│   │   └── index.yaml</span></span>
<span class="line"><span style="color:#a6accd">│   └── repositories.yaml</span></span>
<span class="line"><span style="color:#a6accd">└── starters</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">7 directories, 5 files</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>默认缓存的文件</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# cd .helm/cache/archive/</span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 archive]# ls -l</span></span>
<span class="line"><span style="color:#a6accd">total 16</span></span>
<span class="line"><span style="color:#a6accd">-rw-r--r-- 1 root root 12650 Jul 26 19:21 jenkins-0.13.5.tgz</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 archive]# tar zxf jenkins-0.13.5.tgz</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 archive]# mv jenkins ~/.helm/repository/local/</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# cd ~/.helm/repository/local/jenkins/</span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 jenkins]# tree</span></span>
<span class="line"><span style="color:#a6accd">.</span></span>
<span class="line"><span style="color:#a6accd">├── Chart.yaml</span></span>
<span class="line"><span style="color:#a6accd">├── OWNERS</span></span>
<span class="line"><span style="color:#a6accd">├── README.md</span></span>
<span class="line"><span style="color:#a6accd">├── templates</span></span>
<span class="line"><span style="color:#a6accd">│   ├── config.yaml</span></span>
<span class="line"><span style="color:#a6accd">│   ├── _helpers.tpl</span></span>
<span class="line"><span style="color:#a6accd">│   ├── home-pvc.yaml</span></span>
<span class="line"><span style="color:#a6accd">│   ├── jenkins-agent-svc.yaml</span></span>
<span class="line"><span style="color:#a6accd">│   ├── jenkins-master-deployment.yaml</span></span>
<span class="line"><span style="color:#a6accd">│   ├── jenkins-master-ingress.yaml</span></span>
<span class="line"><span style="color:#a6accd">│   ├── jenkins-master-networkpolicy.yaml</span></span>
<span class="line"><span style="color:#a6accd">│   ├── jenkins-master-svc.yaml</span></span>
<span class="line"><span style="color:#a6accd">│   ├── jenkins-test.yaml</span></span>
<span class="line"><span style="color:#a6accd">│   ├── jobs.yaml</span></span>
<span class="line"><span style="color:#a6accd">│   ├── NOTES.txt</span></span>
<span class="line"><span style="color:#a6accd">│   ├── rbac.yaml</span></span>
<span class="line"><span style="color:#a6accd">│   ├── secret.yaml</span></span>
<span class="line"><span style="color:#a6accd">│   ├── service-account.yaml</span></span>
<span class="line"><span style="color:#a6accd">│   └── test-config.yaml</span></span>
<span class="line"><span style="color:#a6accd">└── values.yaml</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">1 directory, 19 files</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><h3 id="自定义jenkins的chart" tabindex="-1">自定义Jenkins的Chart <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#自定义jenkins的chart" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h3><p>修改为NodePort</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 jenkins]# vim values.yaml</span></span>
<span class="line"><span style="color:#a6accd">ServiceType: NodePort</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>检查</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# helm lint ~/.helm/repository/local/jenkins/</span></span>
<span class="line"><span style="color:#a6accd">==&gt; Linting /root/.helm/repository/local/jenkins/</span></span>
<span class="line"><span style="color:#a6accd">Lint OK</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">1 chart(s) linted, no failures</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>查看有哪些应用</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# helm list</span></span>
<span class="line"><span style="color:#a6accd">NAME           REVISION    UPDATED                     STATUS      CHART          NAMESPACE</span></span>
<span class="line"><span style="color:#a6accd">viable-seal    1           Thu Jul 26 19:21:07 2018    DEPLOYED    jenkins-0.13.5 default</span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# helm delete --purge viable-seal</span></span>
<span class="line"><span style="color:#a6accd">release "viable-seal" deleted</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# helm install ~/.helm/repository/local/jenkins/ --name devops-jenkins </span></span>
<span class="line"><span style="color:#a6accd">NAME:   devops-jenkins</span></span>
<span class="line"><span style="color:#a6accd">LAST DEPLOYED: Thu Jul 26 19:36:10 2018</span></span>
<span class="line"><span style="color:#a6accd">NAMESPACE: default</span></span>
<span class="line"><span style="color:#a6accd">STATUS: DEPLOYED</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">RESOURCES:</span></span>
<span class="line"><span style="color:#a6accd">==&gt; v1/Secret</span></span>
<span class="line"><span style="color:#a6accd">NAME            TYPE    DATA  AGE</span></span>
<span class="line"><span style="color:#a6accd">devops-jenkins  Opaque  2     0s</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">==&gt; v1/ConfigMap</span></span>
<span class="line"><span style="color:#a6accd">NAME                  DATA  AGE</span></span>
<span class="line"><span style="color:#a6accd">devops-jenkins        3     0s</span></span>
<span class="line"><span style="color:#a6accd">devops-jenkins-tests  1     0s</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">==&gt; v1/PersistentVolumeClaim</span></span>
<span class="line"><span style="color:#a6accd">NAME            STATUS   VOLUME  CAPACITY  ACCESS MODES  STORAGECLASS  AGE</span></span>
<span class="line"><span style="color:#a6accd">devops-jenkins  Pending  0s</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">==&gt; v1/Service</span></span>
<span class="line"><span style="color:#a6accd">NAME                  TYPE       CLUSTER-IP   EXTERNAL-IP  PORT(S)         AGE</span></span>
<span class="line"><span style="color:#a6accd">devops-jenkins-agent  ClusterIP  10.1.74.175  &lt;none&gt;       50000/TCP       0s</span></span>
<span class="line"><span style="color:#a6accd">devops-jenkins        NodePort   10.1.3.112   &lt;none&gt;       8080:23558/TCP  0s</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">==&gt; v1beta1/Deployment</span></span>
<span class="line"><span style="color:#a6accd">NAME            DESIRED  CURRENT  UP-TO-DATE  AVAILABLE  AGE</span></span>
<span class="line"><span style="color:#a6accd">devops-jenkins  1        1        1           0          0s</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">==&gt; v1/Pod(related)</span></span>
<span class="line"><span style="color:#a6accd">NAME                            READY  STATUS   RESTARTS  AGE</span></span>
<span class="line"><span style="color:#a6accd">devops-jenkins-64d54b79c-pwjfb  0/1    Pending  0         0s</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">NOTES:</span></span>
<span class="line"><span style="color:#a6accd">1. Get your 'admin' user password by running:</span></span>
<span class="line"><span style="color:#a6accd">  printf $(kubectl get secret --namespace default devops-jenkins -o jsonpath="{.data.jenkins-admin-password}" | base64 --decode);echo</span></span>
<span class="line"><span style="color:#a6accd">2. Get the Jenkins URL to visit by running these commands in the same shell:</span></span>
<span class="line"><span style="color:#a6accd">  export NODE_PORT=$(kubectl get --namespace default -o jsonpath="{.spec.ports[0].nodePort}" services devops-jenkins)</span></span>
<span class="line"><span style="color:#a6accd">  export NODE_IP=$(kubectl get nodes --namespace default -o jsonpath="{.items[0].status.addresses[0].address}")</span></span>
<span class="line"><span style="color:#a6accd">  echo http://$NODE_IP:$NODE_PORT/login</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">3. Login with the password from step 1 and the username: admin</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">For more information on running Jenkins on Kubernetes, visit:</span></span>
<span class="line"><span style="color:#a6accd">https://cloud.google.com/solutions/jenkins-on-container-engine</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>查看状态</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# helm status devops-jenkins</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><h2 id="创建自己的chart" tabindex="-1">创建自己的Chart <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#创建自己的chart" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h2><h3 id="创建自定义nginx的chart" tabindex="-1">创建自定义Nginx的Chart <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#创建自定义nginx的chart" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h3><p>1.创建自定义Chart Nginx的结构</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# helm create helm-nginx</span></span>
<span class="line"><span style="color:#a6accd">Creating helm-nginx</span></span>
<span class="line"><span style="color:#a6accd"> [root@linux-node1 ~]# tree helm-nginx/</span></span>
<span class="line"><span style="color:#a6accd">opencmdb/</span></span>
<span class="line"><span style="color:#a6accd">├── charts       #依赖的chart</span></span>
<span class="line"><span style="color:#a6accd">├── Chart.yaml   #本chart的信息</span></span>
<span class="line"><span style="color:#a6accd">├── templates    #模板目录</span></span>
<span class="line"><span style="color:#a6accd">│   ├── deployment.yaml</span></span>
<span class="line"><span style="color:#a6accd">│   ├── _helpers.tpl</span></span>
<span class="line"><span style="color:#a6accd">│   ├── ingress.yaml</span></span>
<span class="line"><span style="color:#a6accd">│   ├── NOTES.txt</span></span>
<span class="line"><span style="color:#a6accd">│   └── service.yaml</span></span>
<span class="line"><span style="color:#a6accd">└── values.yaml   #模板赋值</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>2.编辑Chart配置</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# cd helm-nginx/</span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 helm-nginx]# vim values.yaml</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>3.验证Chart配置，最后面的点表示当前目录</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 helm-nginx]# helm install --dry-run --debug --name helm-nginx .</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>4.安装自定义Chart，最后面的点表示当前目录</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 helm-nginx]# helm install --name helm-nginx .</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><h3 id="查看helm实例" tabindex="-1">查看Helm实例 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#查看helm实例" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h3><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# helm list</span></span>
<span class="line"><span style="color:#a6accd">NAME          REVISION    UPDATED                     STATUS      CHART                 NAMESPACE</span></span>
<span class="line"><span style="color:#a6accd">helm-nginx    1           Sun Sep 16 19:32:19 2018    DEPLOYED    helm-nginx-0.1.0      default  </span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubectl get pod</span></span>
<span class="line"><span style="color:#a6accd">NAME                          READY     STATUS    RESTARTS   AGE</span></span>
<span class="line"><span style="color:#a6accd">helm-nginx-6975f8dbcd-htvtd   1/1       Running   0          51s</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubectl get ingress</span></span>
<span class="line"><span style="color:#a6accd">NAME         HOSTS                ADDRESS   PORTS     AGE</span></span>
<span class="line"><span style="color:#a6accd">helm-nginx   www.helm-nginx.com             80        1m</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><h1 id="_17-应用的日志采集与分析" tabindex="-1">17 应用的日志采集与分析 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#_17-应用的日志采集与分析" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h1><h2 id="prometheus快速入门" tabindex="-1">Prometheus快速入门 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#prometheus快速入门" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h2><h3 id="prometheus架构介绍" tabindex="-1">Prometheus架构介绍 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#prometheus架构介绍" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h3><p>在学习Prometheus之前我们需要清晰的掌握其架构，Prometheus是由多个组件组成的的监控系统，主要有：Prometheus Server、Alertmanager、Pushgateway组成，这三个组件均为独立的应用服务，独立部署和运行，其中Prometheus Server中内置了Prometheus web UI。</p><p><img src="http://k8s.unixhot.com/kubernetes/media/2ada1ece66fcc81d704c2ba46f9dd7d3.png" alt="architecture"></p><p><strong>Prometheus Server：</strong></p><p>Promethedus Server是核心组件，负责数据的获取、存储、查询。Prometheus通过Pull的方式定期的从Jobs/Exporters中获取数据，并保存在内置的TSDB中；内置的Prometheus web UI可以让用户通过PromQL的方式进行数据的检索。</p><p><strong>Exporters：</strong></p><p>Exporters也是一个独立的组件，有官方提供的Exporters也有社区贡献的Exportes，它将监控采集的数据通过HTTP的方式暴露给Prometheus Server，Server定期获取数据。例如有一个Exporters叫做Node Exporter，它安装在受采集的主机上，为Server提供数据，有点类似于Zabbix监控系统中的Zabbix Agent。</p><p><strong>Prometheus web UI：</strong></p><p>Prometheus web UI是Server启动后内置的一个Web界面，通过该Web界面我们可以进行数据查询工作，不包含设置的相关功能。</p><p><img src="http://k8s.unixhot.com/kubernetes/media/cc11e0cf02ff729fb905ac3648af18f7.png" alt="img"></p><p><strong>PromQL：</strong></p><p>PromQL是Prometheus内置的自定义的查询语言，提供对Prometheus Server中的TSDB这个时间序列数据库进行数据查询，支持数据聚合和一些逻辑运算，是一个相对简单的查询语言，而且PromQL也提供了一些内置函数，帮助我们进行数据处理。</p><p><strong>Alertmanager：</strong></p><p>Alertmanager是Promethedus的告警管理组件，它支持基于PromQL来创建告警规则，类似于Zabbix中的告警表达式，对获取到的数据进行计算和比较，如果满足PromQL定义的规则条件，就会产生报警。</p><p><strong>Pushgateway：</strong></p><p>Pushgateway可以理解为数据的一个中转站，例如当Prometheus Server不能直接和Exporters进行通信的场景下。</p><h3 id="安装prometheus" tabindex="-1">安装Prometheus <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#安装prometheus" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h3><p>学习Prometheus的第一步就是先部署一个实验环境，官方提供了多种方式进行Prometheus安装：</p><ul><li>源码编译安装</li><li>下载预编译好的二进制文件</li><li>使用Docker部署</li><li>使用第三方工具：Ansible、SaltStack、Puppet、Chef。</li></ul><p>为了方便学习，首先我们使用二进制方式部署，可以在这里<a target="_blank" rel="noreferrer" href="https://prometheus.io/download/%E4%B8%8B%E8%BD%BD%E5%AF%B9%E5%BA%94%E7%9A%84%E9%A2%84%E7%BC%96%E8%AF%91%E7%9A%84%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%96%87%E4%BB%B6%E3%80%82"><!--[-->https://prometheus.io/download/下载对应的预编译的二进制文件。<!--]--><!----></a></p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# cd /usr/local/src</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 src]# wget</span></span>
<span class="line"><span style="color:#a6accd">https://github.com/prometheus/prometheus/releases/download/v2.7.1/prometheus-2.7.1.linux-amd64.tar.gz</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 src]# tar zxf prometheus-2.7.1.linux-amd64.tar.gz</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 src]# mv prometheus-2.7.1.linux-amd64 /usr/local/</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 src]# ln -s /usr/local/prometheus-2.7.1.linux-amd64/</span></span>
<span class="line"><span style="color:#a6accd">/usr/local/prometheus</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p><strong>Prometheus配置</strong></p><p>Prometheus的配置文件在prometheus.yml中，直接启动也会到命令的当前目录下寻找该文件。</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# cd /usr/local/prometheus</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 prometheus]# vim prometheus.yml</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd"># my global config</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">global:</span></span>
<span class="line"><span style="color:#a6accd">scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.</span></span>
<span class="line"><span style="color:#a6accd">evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.</span></span>
<span class="line"><span style="color:#a6accd"># scrape_timeout is set to the global default (10s).</span></span>
<span class="line"><span style="color:#a6accd"># Alertmanager configuration</span></span>
<span class="line"><span style="color:#a6accd">alerting:</span></span>
<span class="line"><span style="color:#a6accd">alertmanagers:</span></span>
<span class="line"><span style="color:#a6accd">- static_configs:</span></span>
<span class="line"><span style="color:#a6accd">- targets:</span></span>
<span class="line"><span style="color:#a6accd"># - alertmanager:9093</span></span>
<span class="line"><span style="color:#a6accd"># Load rules once and periodically evaluate them according to the global</span></span>
<span class="line"><span style="color:#a6accd">'evaluation_interval'.</span></span>
<span class="line"><span style="color:#a6accd">rule_files:</span></span>
<span class="line"><span style="color:#a6accd"># - "first_rules.yml"</span></span>
<span class="line"><span style="color:#a6accd"># - "second_rules.yml"</span></span>
<span class="line"><span style="color:#a6accd"># A scrape configuration containing exactly one endpoint to scrape:</span></span>
<span class="line"><span style="color:#a6accd"># Here it's Prometheus itself.</span></span>
<span class="line"><span style="color:#a6accd">scrape_configs:</span></span>
<span class="line"><span style="color:#a6accd"># The job name is added as a label `job=&lt;job_name&gt;` to any timeseries</span></span>
<span class="line"><span style="color:#a6accd">scraped from this config.</span></span>
<span class="line"><span style="color:#a6accd">- job_name: 'prometheus'</span></span>
<span class="line"><span style="color:#a6accd"># metrics_path defaults to '/metrics'</span></span>
<span class="line"><span style="color:#a6accd"># scheme defaults to 'http'.</span></span>
<span class="line"><span style="color:#a6accd">static_configs:</span></span>
<span class="line"><span style="color:#a6accd">- targets: ['localhost:9090']</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p><strong>启动Prometheus</strong></p><p>默认情况下Prometheus会把数据写在启动目录的./data目录下，可以通过启动参数指定目录：--storage.tsdb.path="data/"，更多参数可以通过—help查看</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 prometheus]# ./prometheus –help</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 prometheus]# ./prometheus</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">…</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">level=info ts=2019-02-12T08:04:03.799169159Z caller=main.go:620 msg="Starting</span></span>
<span class="line"><span style="color:#a6accd">TSDB ..."</span></span>
<span class="line"><span style="color:#a6accd">level=info ts=2019-02-12T08:04:03.835497463Z caller=main.go:635 msg="TSDB</span></span>
<span class="line"><span style="color:#a6accd">started"</span></span>
<span class="line"><span style="color:#a6accd">level=info ts=2019-02-12T08:04:03.835598421Z caller=main.go:695 msg="Loading</span></span>
<span class="line"><span style="color:#a6accd">configuration file" filename=prometheus.yml</span></span>
<span class="line"><span style="color:#a6accd">level=info ts=2019-02-12T08:04:03.83756508Z caller=main.go:722 msg="Completed</span></span>
<span class="line"><span style="color:#a6accd">loading of configuration file" filename=prometheus.yml</span></span>
<span class="line"><span style="color:#a6accd">level=info ts=2019-02-12T08:04:03.83760078Z caller=main.go:589 msg="Server is</span></span>
<span class="line"><span style="color:#a6accd">ready to receive web requests."</span></span>
<span class="line"><span style="color:#a6accd">level=info ts=2019-02-12T08:04:03.837641772Z caller=web.go:416 component=web</span></span>
<span class="line"><span style="color:#a6accd">msg="Start listening for connections" address=0.0.0.0:9090</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>默认会在前台启动，并监听9090端口，会自动创建data目录，并存放数据。注意如何服务器时间不正确会有警告提示，请保证服务器时间同步。</p><p><img src="http://k8s.unixhot.com/kubernetes/media/266a101825cbabc2782820895e161f59.png" alt="img"></p><p><strong>放置在后台运行</strong></p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# groupadd prometheus</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# useradd -g prometheus -d /var/lib/prometheus -s</span></span>
<span class="line"><span style="color:#a6accd">/sbin/nologin prometheus</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# vim /usr/lib/systemd/system/prometheus.service</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">[Unit]</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">Description=prometheus</span></span>
<span class="line"><span style="color:#a6accd">After=network.target</span></span>
<span class="line"><span style="color:#a6accd">[Service]</span></span>
<span class="line"><span style="color:#a6accd">Type=simple</span></span>
<span class="line"><span style="color:#a6accd">User=prometheus</span></span>
<span class="line"><span style="color:#a6accd">ExecStart=/usr/local/prometheus/prometheus</span></span>
<span class="line"><span style="color:#a6accd">--config.file=/usr/local/prometheus/prometheus.yml</span></span>
<span class="line"><span style="color:#a6accd">--storage.tsdb.path=/var/lib/prometheus</span></span>
<span class="line"><span style="color:#a6accd">Restart=on-failure</span></span>
<span class="line"><span style="color:#a6accd">[Install]</span></span>
<span class="line"><span style="color:#a6accd">WantedBy=multi-user.target</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>后台启动</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# systemctl enable prometheus</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# systemctl start prometheus</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>查看启动状态</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# netstat -ntlp | grep 9090</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">tcp6 0 0 :::9090 :::* LISTEN 61333/prometheus</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><h3 id="使用node-exporter采集主机数据" tabindex="-1">使用Node Exporter采集主机数据 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#使用node-exporter采集主机数据" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h3><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# cd /usr/local/src</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 src]# wget</span></span>
<span class="line"><span style="color:#a6accd">&lt;https://github.com/prometheus/node_exporter/releases/download/v0.17.0/node_exporter-0.17.0.linux-amd64.tar.gz&gt;</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 src]# tar zxf node_exporter-0.17.0.linux-amd64.tar.gz</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 src]# mv node_exporter-0.17.0.linux-amd64 /usr/local/</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 src]# ln -s /usr/local/node_exporter-0.17.0.linux-amd64/</span></span>
<span class="line"><span style="color:#a6accd">/usr/local/node_exporter</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# vim /usr/lib/systemd/system/node_exporter.service</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">[Unit]</span></span>
<span class="line"><span style="color:#a6accd">Description=node_exporter</span></span>
<span class="line"><span style="color:#a6accd">After=network.target</span></span>
<span class="line"><span style="color:#a6accd">[Service]</span></span>
<span class="line"><span style="color:#a6accd">Type=simple</span></span>
<span class="line"><span style="color:#a6accd">User=prometheus</span></span>
<span class="line"><span style="color:#a6accd">ExecStart=/usr/local/prometheus/node_exporter/node_exporter</span></span>
<span class="line"><span style="color:#a6accd">Restart=on-failure</span></span>
<span class="line"><span style="color:#a6accd">[Install]</span></span>
<span class="line"><span style="color:#a6accd">WantedBy=multi-user.target</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>启动Node Exporter</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# systemctl enable node_exporter</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# systemctl start node_exporter</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>查看状态 [root@linux-node1 ~]# netstat -ntlp | grep 9100</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">tcp6 0 0 :::9100 :::* LISTEN 66239/node_exporter</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>默认情况下Node Exporter监听9100端口，通过/metrics暴露采集到的监控数据，Prometheus默认也从该地址获取数据。</p><p><img src="http://k8s.unixhot.com/kubernetes/media/1004a69a33423c72a2989005be5a790e.png" alt="img"></p><p><strong>配置Prometheus读取Node Exporter数据</strong></p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# vim /usr/local/prometheus/prometheus.yml</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">scrape_configs:</span></span>
<span class="line"><span style="color:#a6accd"># The job name is added as a label `job=&lt;job_name&gt;` to any timeseries</span></span>
<span class="line"><span style="color:#a6accd">scraped from this config.</span></span>
<span class="line"><span style="color:#a6accd">- job_name: 'prometheus'</span></span>
<span class="line"><span style="color:#a6accd"># metrics_path defaults to '/metrics'</span></span>
<span class="line"><span style="color:#a6accd"># scheme defaults to 'http'.</span></span>
<span class="line"><span style="color:#a6accd">static_configs:</span></span>
<span class="line"><span style="color:#a6accd">- targets: ['localhost:9090']</span></span>
<span class="line"><span style="color:#a6accd">- job_name: 'linux-node1'</span></span>
<span class="line"><span style="color:#a6accd">static_configs:</span></span>
<span class="line"><span style="color:#a6accd">- targets: ['192.168.56.11:9100']</span></span>
<span class="line"><span style="color:#a6accd">labels:</span></span>
<span class="line"><span style="color:#a6accd">instance: linux-node1</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p><strong>重启prometheus</strong></p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# systemctl restart prometheus</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p><strong>查看监控状态</strong></p><p>登录Prometheus的Web控制台，StatusTargets如果可以linux-node1并且状态是UP的状态即为配置成功。</p><p><img src="http://k8s.unixhot.com/kubernetes/media/8c3da60dbf5558dc649de1fd6ce43bf0.png" alt="img"></p><h3 id="使用prometheus-ui查看数据" tabindex="-1">使用Prometheus UI查看数据 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#使用prometheus-ui查看数据" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h3><p>现在Prometheus会定期的从<a target="_blank" rel="noreferrer" href="http://192.168.56.11:9100/metrics%E8%8E%B7%E5%8F%96%E6%95%B0%E6%8D%AE%EF%BC%8C%E5%B9%B6%E5%AD%98%E5%82%A8%EF%BC%8C%E6%88%91%E4%BB%AC%E5%8F%AF%E4%BB%A5%E4%BD%BF%E7%94%A8Prometheus"><!--[-->http://192.168.56.11:9100/metrics获取数据，并存储，我们可以使用Prometheus<!--]--><!----></a> UI来查看监控数据。</p><h3 id="使用grafana进行数据可视化" tabindex="-1">使用Grafana进行数据可视化 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#使用grafana进行数据可视化" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h3><p><strong>1.安装Grafana</strong></p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# vim /etc/yum.repos.d/grafana.repo</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">[grafana]</span></span>
<span class="line"><span style="color:#a6accd">name=grafana</span></span>
<span class="line"><span style="color:#a6accd">baseurl=https://packages.grafana.com/oss/rpm</span></span>
<span class="line"><span style="color:#a6accd">repo_gpgcheck=1</span></span>
<span class="line"><span style="color:#a6accd">enabled=1</span></span>
<span class="line"><span style="color:#a6accd">gpgcheck=1</span></span>
<span class="line"><span style="color:#a6accd">gpgkey=https://packages.grafana.com/gpg.key</span></span>
<span class="line"><span style="color:#a6accd">sslverify=1</span></span>
<span class="line"><span style="color:#a6accd">sslcacert=/etc/pki/tls/certs/ca-bundle.crt</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# yum install -y grafana</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p><strong>2.配置Grafana</strong></p><p>Grafana的配置文件在/etc/grafana/grafana.ini，默认情况下Grafana监听3000端口</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# vim /etc/grafana/grafana.ini</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p><strong>3.启动Grafana</strong></p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# systemctl enable grafana-server</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# systemctl start grafana-server</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# netstat -ntlp | grep 3000</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">tcp6 0 0 :::3000 :::* LISTEN 81427/grafana-serve</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p><strong>4.访问Grafana</strong></p><p>访问<a target="_blank" rel="noreferrer" href="http://192.168.56.11:3000/"><!--[-->http://192.168.56.11:3000<!--]--><!----></a>，用户名和密码默认为admin/admin，第一次登陆会要求修改密码，请使用安全密码。</p><p><strong>5.增加Prometheus数据源</strong></p><p>点击</p><p><img src="http://k8s.unixhot.com/kubernetes/media/b681a9b528d2ff21ba66666ce2452e51.png" alt="img"></p><p>，然后选择</p><p><img src="http://k8s.unixhot.com/kubernetes/media/d3e83ac4f090a51c5b5e0c341b99dda5.png" alt="img"></p><p>。</p><p>配置URL为：<a target="_blank" rel="noreferrer" href="http://192.168.56.11:9090/"><!--[-->http://192.168.56.11:9090<!--]--><!----></a>，并点击Save&amp;Test。</p><p><img src="http://k8s.unixhot.com/kubernetes/media/e35d8aaebedd7e168ebd1b29b65b30bb.png" alt="img"></p><p><strong>6.设置Dashboard</strong></p><p>数据源设置完毕后，就可以设置Dashboard图形展示，可以手动添加，也可以直接下载别人配置好保持的Json文件直接导入即可。</p><p>下载地址：<a target="_blank" rel="noreferrer" href="https://grafana.com/dashboards/405%EF%BC%8C%E5%9C%A8%E5%8F%B3%E4%BE%A7%E6%9C%89Download"><!--[-->https://grafana.com/dashboards/405，在右侧有Download<!--]--><!----></a> Json按钮，下载该Json文件。</p><p><img src="http://k8s.unixhot.com/kubernetes/media/d9ab69b29a964a12df52512a7b128b5b.png" alt="img"></p><p>点击Home下的Import Dashboard</p><p><img src="http://k8s.unixhot.com/kubernetes/media/53ffc0e739ca7b9421f9568ae4cbf117.png" alt="img"></p><p>然后直接上传刚才下载的JSON文件。</p><p><img src="http://k8s.unixhot.com/kubernetes/media/500958891a82067b0c987d514239ffb0.png" alt="img"></p><p>导入完毕后，就可以在Grafana上查看对应节点的监控数据图表。你可以通过鼠标拖拽进行图表的自定义大小和位置的修改，效果如下：</p><p><img src="http://k8s.unixhot.com/kubernetes/media/698a6241faa0adc1af6c09cc369b259b.png" alt="img"></p><h1 id="第七部分-kubernetes高级进阶" tabindex="-1">第七部分 Kubernetes高级进阶 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#第七部分-kubernetes高级进阶" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h1><h1 id="kubernetes的权限控制rbac" tabindex="-1">Kubernetes的权限控制RBAC <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#kubernetes的权限控制rbac" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h1><p><strong>角色</strong></p><ul><li><p>Role: 角色，命名空间范围内的一个权限集合。</p></li><li><p>ClusterRole：集群角色，集群范围内的一个权限的集合，</p><p>Role和ClusterROle在Kubernetes中都被定义为集群内部的 API 资源，和我们前面学习过的 Pod、ConfigMap 这些类似，都是我们集群的资源对象，所以同样的可以使用我们前面的kubectl相关的命令来进行操作 Subject：主题，对应在集群中尝试操作的对象，集群中定义了3种类型的主题资源：</p></li></ul><p>User Account：用户，这是有外部独立服务进行管理的，管理员进行私钥的分配，用户可以使用 KeyStone或者 Goolge 帐号，甚至一个用户名和密码的文件列表也可以。对于用户的管理集群内部没有一个关联的资源对象，所以用户不能通过集群内部的 API 来进行管理 Group：组，这是用来关联多个账户的，集群中有一些默认创建的组，比如cluster-admin Service Account：服务帐号，通过Kubernetes API 来管理的一些用户帐号，和 namespace 进行关联的，适用于集群内部运行的应用程序，需要通过 API 来完成权限认证，所以在集群内部进行权限操作，我们都需要使用到 ServiceAccount，这也是我们这节课的重点 RoleBinding 和 ClusterRoleBinding：角色绑定和集群角色绑定，简单来说就是把声明的 Subject 和我们的 Role 进行绑定的过程(给某个用户绑定上操作的权限)，二者的区别也是作用范围的区别：RoleBinding 只会影响到当前 namespace 下面的资源操作权限，而 ClusterRoleBinding 会影响到所有的 namespace。</p><p><strong>创建用户凭证</strong></p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# openssl genrsa -out jenkins.key 2048</span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# openssl req -new -key jenkins.key -out jenkins.csr -subj "/CN=jenkins/O=vmware"</span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# openssl x509 -req -in jenkins.csr -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out jenkins.crt -days 365</span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubectl config set-credentials jenkins --client-certificate=jenkins.crt  --client-key=jenkins.key</span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubectl config set-context jenkins-context --cluster=kubernetes --namespace=jenkins --user=jenkins  </span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubectl get pods --context=jenkins-context</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p><strong>创建角色</strong></p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# vim jenkins-role.yml</span></span>
<span class="line"><span style="color:#a6accd">apiVersion: rbac.authorization.k8s.io/v1</span></span>
<span class="line"><span style="color:#a6accd">kind: Role</span></span>
<span class="line"><span style="color:#a6accd">metadata:</span></span>
<span class="line"><span style="color:#a6accd">  name: jenkins-role</span></span>
<span class="line"><span style="color:#a6accd">  namespace: jenkins</span></span>
<span class="line"><span style="color:#a6accd">rules:</span></span>
<span class="line"><span style="color:#a6accd">- apiGroups: ["", "extensions", "apps"]</span></span>
<span class="line"><span style="color:#a6accd">  resources: ["deployments", "replicasets", "pods"]</span></span>
<span class="line"><span style="color:#a6accd">  verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p><strong>创建角色绑定</strong></p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# vim jenkins-role-binding.yml</span></span>
<span class="line"><span style="color:#a6accd">apiVersion: rbac.authorization.k8s.io/v1</span></span>
<span class="line"><span style="color:#a6accd">kind: RoleBinding</span></span>
<span class="line"><span style="color:#a6accd">metadata:</span></span>
<span class="line"><span style="color:#a6accd">  name: jenkins-rolebinding</span></span>
<span class="line"><span style="color:#a6accd">  namespace: jenkins</span></span>
<span class="line"><span style="color:#a6accd">subjects:</span></span>
<span class="line"><span style="color:#a6accd">- kind: User</span></span>
<span class="line"><span style="color:#a6accd">  name: jenkins</span></span>
<span class="line"><span style="color:#a6accd">  apiGroup: ""</span></span>
<span class="line"><span style="color:#a6accd">roleRef:</span></span>
<span class="line"><span style="color:#a6accd">  kind: Role</span></span>
<span class="line"><span style="color:#a6accd">  name: jenkins-role</span></span>
<span class="line"><span style="color:#a6accd">  apiGroup: ""</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><h1 id="_22-深入理解pod调度" tabindex="-1">22 深入理解Pod调度 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#_22-深入理解pod调度" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h1><h1 id="深入理解pod调度" tabindex="-1">深入理解Pod调度 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#深入理解pod调度" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h1><p>在前面的章节我们已经知道在Kubernetes中使用kube-scheduler进行Pod调度，它的目标是将Pod绑定到对应的Node上，经过一系列的条件和算法尽可能的让每个Pod都满意。kube-scheduler是Kubernetes默认的调度器。</p><p>kube-scheduler的代码位于<a target="_blank" rel="noreferrer" href="https://github.com/kubernetes/kubernetes/tree/master/pkg/scheduler"><!--[-->GitHub<!--]--><!----></a></p><p>可以将代码克隆到本地方便查看</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# git clone --depth 1 https://github.com/kubernetes/kubernetes.git</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>在algorithm下有调度算法，调度算法分为两个阶段：Predicates和priorities，首先对Node进行过滤看哪些Node符合调度要求，然后在符合调度要求的Node上进行优先级计算，判断调度到哪个Node最合适。</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 algorithm]# pwd</span></span>
<span class="line"><span style="color:#a6accd">/root/kubernetes/pkg/scheduler/algorithm</span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 algorithm]# ls -l</span></span>
<span class="line"><span style="color:#a6accd">total 20</span></span>
<span class="line"><span style="color:#a6accd">-rw-r--r-- 1 root root 1256 Dec 17 22:52 BUILD</span></span>
<span class="line"><span style="color:#a6accd">-rw-r--r-- 1 root root  735 Dec 17 22:52 doc.go</span></span>
<span class="line"><span style="color:#a6accd">drwxr-xr-x 2 root root  276 Dec 17 22:52 predicates</span></span>
<span class="line"><span style="color:#a6accd">drwxr-xr-x 3 root root 4096 Dec 17 22:52 priorities</span></span>
<span class="line"><span style="color:#a6accd">-rw-r--r-- 1 root root 3278 Dec 17 22:52 scheduler_interface.go</span></span>
<span class="line"><span style="color:#a6accd">-rw-r--r-- 1 root root 3383 Dec 17 22:52 types.go</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>官方文档详细的介绍了所有的步骤：<a target="_blank" rel="noreferrer" href="https://kubernetes.io/docs/concepts/scheduling/kube-scheduler/"><!--[-->https://kubernetes.io/docs/concepts/scheduling/kube-scheduler/<!--]--><!----></a></p><p><strong>设置调度器</strong></p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubectl get pod kube-proxy-5wbtf -n kube-system -o yaml | grep schedulerName</span></span>
<span class="line"><span style="color:#a6accd">  schedulerName: default-scheduler</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><h2 id="taints（污点）" tabindex="-1">Taints（污点） <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#taints（污点）" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h2><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubectl describe node linux-node1.unixhot.com | grep Taints</span></span>
<span class="line"><span style="color:#a6accd">Taints:             node-role.kubernetes.io/master:NoSchedule</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>Taints的表现形式为</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">&lt;key&gt;=&lt;value&gt;:&lt;effect&gt;</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>effect的三种类型：</p><ul><li>NoSchedule: 如果Pod没有容忍该污点，不调度到该节点上。</li><li>PreferNoSchedule：尽量阻止Pod被调度到这个节点上，但是如果没有其它节点能够调度，可以调度到该节点。</li><li>NoExecute： NoScheduler和PreferNoSchedule只是在调度阶段起作用，但是NoExecute会影响正常运行的Pod，如果一个节点被打了NoExecute的污点，而运行在该节点的Pod没有容忍会直接被这个节点移除。</li></ul><p>查看Flannel为何能调度到Master节点</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubectl get po -n kube-system | grep flannel</span></span>
<span class="line"><span style="color:#a6accd">kube-flannel-ds-amd64-f2jrk                       1/1     Running   2          22h</span></span>
<span class="line"><span style="color:#a6accd">kube-flannel-ds-amd64-mh75v                       1/1     Running   2          22h</span></span>
<span class="line"><span style="color:#a6accd">kube-flannel-ds-amd64-n52zm                       1/1     Running   4          22h</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubectl describe pod kube-flannel-ds-amd64-f2jrk -n kube-system</span></span>
<span class="line"><span style="color:#a6accd">...</span></span>
<span class="line"><span style="color:#a6accd">Tolerations:     :NoSchedule</span></span>
<span class="line"><span style="color:#a6accd">                 node.kubernetes.io/disk-pressure:NoSchedule</span></span>
<span class="line"><span style="color:#a6accd">                 node.kubernetes.io/memory-pressure:NoSchedule</span></span>
<span class="line"><span style="color:#a6accd">                 node.kubernetes.io/network-unavailable:NoSchedule</span></span>
<span class="line"><span style="color:#a6accd">                 node.kubernetes.io/not-ready:NoExecute</span></span>
<span class="line"><span style="color:#a6accd">                 node.kubernetes.io/pid-pressure:NoSchedule</span></span>
<span class="line"><span style="color:#a6accd">                 node.kubernetes.io/unreachable:NoExecute</span></span>
<span class="line"><span style="color:#a6accd">                 node.kubernetes.io/unschedulable:NoSchedule</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><h3 id="自定义污点" tabindex="-1">自定义污点 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#自定义污点" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h3><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@linux-node1 ~]# kubectl taint node linux-node2.example.com node-ytpe=gpu:NoSchedule       </span></span>
<span class="line"><span style="color:#a6accd">node/linux-node2.example.com tainted</span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 example]# cat nginx-deployment-taint.yaml    </span></span>
<span class="line"><span style="color:#a6accd">apiVersion: apps/v1</span></span>
<span class="line"><span style="color:#a6accd">kind: Deployment</span></span>
<span class="line"><span style="color:#a6accd">metadata:</span></span>
<span class="line"><span style="color:#a6accd">  name: nginx-deployment</span></span>
<span class="line"><span style="color:#a6accd">  labels:</span></span>
<span class="line"><span style="color:#a6accd">    app: nginx</span></span>
<span class="line"><span style="color:#a6accd">spec:</span></span>
<span class="line"><span style="color:#a6accd">  replicas: 3</span></span>
<span class="line"><span style="color:#a6accd">  selector:</span></span>
<span class="line"><span style="color:#a6accd">    matchLabels:</span></span>
<span class="line"><span style="color:#a6accd">      app: nginx</span></span>
<span class="line"><span style="color:#a6accd">  template:</span></span>
<span class="line"><span style="color:#a6accd">    metadata:</span></span>
<span class="line"><span style="color:#a6accd">      labels:</span></span>
<span class="line"><span style="color:#a6accd">        app: nginx</span></span>
<span class="line"><span style="color:#a6accd">    spec:</span></span>
<span class="line"><span style="color:#a6accd">      containers:</span></span>
<span class="line"><span style="color:#a6accd">      - name: nginx</span></span>
<span class="line"><span style="color:#a6accd">        image: nginx:1.13.12</span></span>
<span class="line"><span style="color:#a6accd">        ports:</span></span>
<span class="line"><span style="color:#a6accd">        - containerPort: 80</span></span>
<span class="line"><span style="color:#a6accd">      tolerations:</span></span>
<span class="line"><span style="color:#a6accd">      - key: node-type</span></span>
<span class="line"><span style="color:#a6accd">        operator: Equal</span></span>
<span class="line"><span style="color:#a6accd">        value: gpu</span></span>
<span class="line"><span style="color:#a6accd">        effect: Noschedule</span></span>
<span class="line"><span style="color:#a6accd">[root@linux-node1 example]# kubectl get po -o wide</span></span>
<span class="line"><span style="color:#a6accd">NAME                                READY   STATUS    RESTARTS   AGE     IP          NODE                      NOMINATED NODE   READINESS GATES</span></span>
<span class="line"><span style="color:#a6accd">dns-test                            1/1     Running   1          6h15m   10.2.2.23   linux-node3.example.com   &lt;none&gt;           &lt;none&gt;</span></span>
<span class="line"><span style="color:#a6accd">nginx-deployment-77564d4546-2jkw9   1/1     Running   0          13s     10.2.2.26   linux-node3.example.com   &lt;none&gt;           &lt;none&gt;</span></span>
<span class="line"><span style="color:#a6accd">nginx-deployment-77564d4546-4hrbf   1/1     Running   0          13s     10.2.2.24   linux-node3.example.com   &lt;none&gt;           &lt;none&gt;</span></span>
<span class="line"><span style="color:#a6accd">nginx-deployment-77564d4546-s2r4h   1/1     Running   0          13s     10.2.2.25   linux-node3.example</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><h2 id="亲缘性调度" tabindex="-1">亲缘性调度 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#亲缘性调度" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h2><h1 id="_23-kubernetes-api介绍" tabindex="-1">23 Kubernetes API介绍 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#_23-kubernetes-api介绍" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h1><p>查看集群状态</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@k8s-master1 ~]# kubectl cluster-info</span></span>
<span class="line"><span style="color:#a6accd">Kubernetes master is running at https://192.168.56.11:6443</span></span>
<span class="line"><span style="color:#a6accd">KubeDNS is running at https://192.168.56.11:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>直接访问Kubernetes API需要验证，无法直接访问。</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@k8s-master1 ~]# curl -k https://192.168.56.11:6443</span></span>
<span class="line"><span style="color:#a6accd">{</span></span>
<span class="line"><span style="color:#a6accd">  "kind": "Status",</span></span>
<span class="line"><span style="color:#a6accd">  "apiVersion": "v1",</span></span>
<span class="line"><span style="color:#a6accd">  "metadata": {</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">  },</span></span>
<span class="line"><span style="color:#a6accd">  "status": "Failure",</span></span>
<span class="line"><span style="color:#a6accd">  "message": "forbidden: User \"system:anonymous\" cannot get path \"/\"",</span></span>
<span class="line"><span style="color:#a6accd">  "reason": "Forbidden",</span></span>
<span class="line"><span style="color:#a6accd">  "details": {</span></span>
<span class="line"><span style="color:#a6accd"></span></span>
<span class="line"><span style="color:#a6accd">  },</span></span>
<span class="line"><span style="color:#a6accd">  "code": 403</span></span>
<span class="line"><span style="color:#a6accd">}</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p><strong>通过Proxy访问Kubernetes API</strong></p><p>使用kubectl proxy可以在Master本地启动一个代理</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@k8s-master1 ~]# kubectl proxy</span></span>
<span class="line"><span style="color:#a6accd">Starting to serve on 127.0.0.1:8001</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>可以通过127.0.0.1:8001与API Server进行交互</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@k8s-master1 ~]# curl http://127.0.0.1:8001</span></span>
<span class="line"><span style="color:#a6accd">{</span></span>
<span class="line"><span style="color:#a6accd">  "paths": [</span></span>
<span class="line"><span style="color:#a6accd">    "/api",</span></span>
<span class="line"><span style="color:#a6accd">    "/api/v1",</span></span>
<span class="line"><span style="color:#a6accd">    "/apis",</span></span>
<span class="line"><span style="color:#a6accd">    "/apis/",</span></span>
<span class="line"><span style="color:#a6accd">    "/apis/admissionregistration.k8s.io",</span></span>
<span class="line"><span style="color:#a6accd">    "/apis/admissionregistration.k8s.io/v1beta1",</span></span>
<span class="line"><span style="color:#a6accd">    "/apis/apiextensions.k8s.io",</span></span>
<span class="line"><span style="color:#a6accd">    "/apis/apiextensions.k8s.io/v1beta1",</span></span>
<span class="line"><span style="color:#a6accd">    "/apis/apiregistration.k8s.io",</span></span>
<span class="line"><span style="color:#a6accd">    "/apis/apiregistration.k8s.io/v1",</span></span>
<span class="line"><span style="color:#a6accd">    "/apis/apiregistration.k8s.io/v1beta1",</span></span>
<span class="line"><span style="color:#a6accd">    "/apis/apps",</span></span>
<span class="line"><span style="color:#a6accd">...（省略其它输出）</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>可以通过修改监听地址，并关闭过滤，实现在其它地方登录和查看，这样就可以在本地浏览器访问API。切记不要再生产环境将代理地址暴露在外网。</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@k8s-master1 ~]# kubectl proxy --address=0.0.0.0 --disable-filter=true</span></span>
<span class="line"><span style="color:#a6accd">W1105 16:18:45.669591   16730 proxy.go:142] Request filter disabled, your proxy is vulnerable to XSRF attacks, please be cautious</span></span>
<span class="line"><span style="color:#a6accd">Starting to serve on [::]:8001</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><h3 id="使用swagger-ui进行api交互" tabindex="-1">使用Swagger UI进行API交互 <a aria-current="page" href="/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5#使用swagger-ui进行api交互" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h3><p>Kubernetes支持Swagger UI访问API，需要在API Server开启，如果已经根据本书使用kubeadm部署的集群，可以通过修改Pod的YAML文件，重建Pod来开启</p><p><strong>修改API Server的Pod定义文件</strong></p><p>在- kube-apiserver下面一行增加--enable-swagger-ui=true</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@k8s-master1 ~]# vim /etc/kubernetes/manifests/kube-apiserver.yaml </span></span>
<span class="line"><span style="color:#a6accd">apiVersion: v1</span></span>
<span class="line"><span style="color:#a6accd">kind: Pod</span></span>
<span class="line"><span style="color:#a6accd">metadata:</span></span>
<span class="line"><span style="color:#a6accd">  creationTimestamp: null</span></span>
<span class="line"><span style="color:#a6accd">  labels:</span></span>
<span class="line"><span style="color:#a6accd">    component: kube-apiserver</span></span>
<span class="line"><span style="color:#a6accd">    tier: control-plane</span></span>
<span class="line"><span style="color:#a6accd">  name: kube-apiserver</span></span>
<span class="line"><span style="color:#a6accd">  namespace: kube-system</span></span>
<span class="line"><span style="color:#a6accd">spec:</span></span>
<span class="line"><span style="color:#a6accd">  containers:</span></span>
<span class="line"><span style="color:#a6accd">  - command:</span></span>
<span class="line"><span style="color:#a6accd">    - kube-apiserver</span></span>
<span class="line"><span style="color:#a6accd">    - --enable-swagger-ui=true</span></span>
<span class="line"><span style="color:#a6accd">    - --advertise-address=192.168.56.11</span></span>
<span class="line"><span style="color:#a6accd">    - --allow-privileged=true</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>删除Pod，kubelet会通过该YAML重建Pod</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@k8s-master1 ~]# kubectl get pod -n kube-system | grep api</span></span>
<span class="line"><span style="color:#a6accd">kube-apiserver-linux-node1.unixhot.com            1/1     Running   0          55m</span></span>
<span class="line"><span style="color:#a6accd">[root@k8s-master1 ~]# kubectl delete pod kube-apiserver-linux-node1.unixhot.com -n kube-system</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>可以看到配置已经生效</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@k8s-master1 ~]# kubectl describe pod kube-apiserver-linux-node1.unixhot.com -n kube-system </span></span>
<span class="line"><span style="color:#a6accd">...</span></span>
<span class="line"><span style="color:#a6accd">    Command:</span></span>
<span class="line"><span style="color:#a6accd">      kube-apiserver</span></span>
<span class="line"><span style="color:#a6accd">      --enable-swagger-ui=true</span></span>
<span class="line"><span style="color:#a6accd">      --advertise-address=192.168.99.27</span></span>
<span class="line"><span style="color:#a6accd">....</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>部署一个Swagger UI服务查看API</p><div class="language-"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">[root@k8s-master1 ~]# kubectl run swagger-ui --image=swaggerapi/swagger-ui:latest</span></span>
<span class="line"><span style="color:#a6accd">[root@k8s-master1 ~]# kubectl expose deployment swagger-ui --port=8080 --type=NodePort</span></span>
<span class="line"><span style="color:#a6accd">[root@k8s-master1 ~]# kubectl get service</span></span>
<span class="line"><span style="color:#a6accd">NAME         TYPE        CLUSTER-IP    EXTERNAL-IP     PORT(S)          AGE</span></span>
<span class="line"><span style="color:#a6accd">kubernetes   ClusterIP   10.1.0.1      &lt;none&gt;          443/TCP          43d</span></span>
<span class="line"><span style="color:#a6accd">swagger-ui   NodePort    10.1.205.94   &lt;none&gt;   8080:30410/TCP   34s</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p>因为我们部署的Swagger UI和API Server不在一个域名下，所以会有跨域的问题，Chrome浏览器需要提前安装Allow CROS插件解决</p><hr><hr><p>摘录自赵班长--------</p><!--]--><!--[--><!--]--><!--]--><div text="center"><!----></div><!----></article><!--]--><!--[--><!--[--><!--[--><div class="yun-sponsor-container flex-center flex-col" m="t-6"><button class="sponsor-button yun-icon-btn shadow hover:shadow-md" title="我很可爱，请给我钱！" text="red-400"><div i-ri-heart-line=""></div></button><div m="y-4" class="qrcode-container qrcode flex-center flex-col"><div class="sponsor-description" mb="4" text="sm">这是关于赞助的一些描述</div><div class="flex justify-around"><!--[--><a class="flex-center flex-col animate-iteration-1 animate-fade-in" href="https://cos.vlinux.cn/www-vlinux-cn-blog-img/WechatIMG203.jpeg" target="_blank" style="color:#00a3ee"><img class="sponsor-method-img" border="~ rounded" p="1" loading="lazy" src="https://cos.vlinux.cn/www-vlinux-cn-blog-img/WechatIMG203.jpeg" title="支付宝"><div text="xl" m="2" class="i-ri-alipay-line"></div></a><a class="flex-center flex-col animate-iteration-1 animate-fade-in" href="https://cos.vlinux.cn/www-vlinux-cn-blog-img/WechatIMG205.jpeg" target="_blank" style="color:#12b7f5"><img class="sponsor-method-img" border="~ rounded" p="1" loading="lazy" src="https://cos.vlinux.cn/www-vlinux-cn-blog-img/WechatIMG205.jpeg" title="QQ 支付"><div text="xl" m="2" class="i-ri-qq-line"></div></a><a class="flex-center flex-col animate-iteration-1 animate-fade-in" href="https://cos.vlinux.cn/www-vlinux-cn-blog-img/WechatIMG204.jpeg" target="_blank" style="color:#2dc100"><img class="sponsor-method-img" border="~ rounded" p="1" loading="lazy" src="https://cos.vlinux.cn/www-vlinux-cn-blog-img/WechatIMG204.jpeg" title="微信支付"><div text="xl" m="2" class="i-ri-wechat-pay-line"></div></a><!--]--></div></div></div><ul class="post-copyright" m="y-4"><li class="post-copyright-author"><strong>本文作者：</strong><span>卷饼</span></li><li class="post-copyright-link"><strong>本文链接：</strong><a href="https://www.vlinux.cn/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5">https://www.vlinux.cn/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5</a></li><li class="post-copyright-license"><strong>版权声明：</strong><span>本博客所有文章除特别声明外，均默认采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" target="_blank" rel="noopener" title="CC BY-NC-SA 4.0 ">CC BY-NC-SA</a> 许可协议。</span></li></ul><!--]--><!--]--><!--]--></div><!--]--><!----></div><!--[--><!--]--><!--[--><div class="post-nav"><div class="post-nav-item"><a href="/posts/gitlab%E8%AE%BE%E8%AE%A1%E4%B8%8E%E9%83%A8%E7%BD%B2" class="post-nav-prev" title="GItlab设计与部署"><div class="icon" i-ri-arrow-left-s-line=""></div><span class="title truncate" text="sm">GItlab设计与部署</span></a></div><div class="post-nav-item"><a href="/posts/docker+k8s%E5%AE%9E%E8%B7%B5%E6%8C%87%E5%8D%97" class="post-nav-next" title="Docker+K8s实践指南"><span class="title truncate" text="sm">Docker+K8s实践指南</span><div class="icon" i-ri-arrow-right-s-line=""></div></a></div></div><!--]--><!--[--><!--]--><!--[--><div class="yun-card comment sm:p-6 lg:px-12 xl:px-16" w="full" p="4"><!----><!----><!--[--><!----><!--]--><!----></div><!--]--><!--[--><!--]--><footer class="va-footer p-4 text-$va-c-text-light" text="center sm"><div class="beian" m="y-2"><a href="https://beian.miit.gov.cn/" target="_blank" rel="noopener">豫ICP备20001100号-3</a></div><div class="copyright flex justify-center items-center gap-2" p="1"><span>©<!--[--> 2016 -<!--]--> 2023</span><a class="animate-pulse inline-flex" href="https://sponsors.yunyoujun.cn" target="_blank" title="Sponsor YunYouJun"><div class="i-ri-cloud-line"></div></a><span>卷饼</span></div><div class="powered" m="2"><span>由 <a href="https://github.com/YunYouJun/valaxy" target="_blank" rel="noopener">Valaxy</a> v0.14.28 驱动</span> | <span>主题 - <a href="https://github.com/YunYouJun/valaxy/tree/main/packages/valaxy-theme-yun" title="valaxy-theme-yun" target="_blank">Yun</a> v0.14.28</span></div><!--[--> 由 <a href="https://www.netdun.net" target="_blank" title="网盾星球">网盾星球</a> 提供 CDN 支持<!--]--></footer><!--[--><!--]--></div><!--]--><!--[--><!--[--><button class="xl:hidden toc-btn shadow fixed yun-icon-btn z-350" opacity="75" right="2" bottom="19"><div i-ri-file-list-line=""></div></button><!----><!--  --><aside class="va-card yun-aside" m="l-4" text="center"><div class="aside-container" flex="~ col" overflow="auto"><h2 m="t-6 b-2" font="serif black">文章目录</h2><div style="display:none" data-v-e1350763=""><div class="content" data-v-e1350763=""><div class="outline-title" data-v-e1350763="">On this page</div><div class="outline-marker" data-v-e1350763=""></div><nav aria-labelledby="doc-outline-aria-label" data-v-e1350763=""><span id="doc-outline-aria-label" class="visually-hidden" data-v-e1350763="">Table of Contents for current page</span><ul class="root va-toc relative z-1" data-v-e1350763="" data-v-e736e6e6=""><!--[--><!--]--></ul></nav></div></div><div class="flex-grow"></div><div class="custom-container"><!--[--><!--]--></div></div></aside><!--]--><!--]--></div></main><a href="#" class="back-to-top yun-icon-btn"><div w="8" h="8" i-ri-arrow-up-s-line=""></div><svg class="progress-circle-container" viewBox="0 0 100 100"><circle stroke-dasharray="301.59289474462014 301.59289474462014" stroke-dashoffset="301.59289474462014" class="progress-circle" cx="50" cy="50" r="48" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"></circle></svg></a><!--]--><!--]--></div><script>window.__INITIAL_STATE__='{"pinia":{"app":{"isSidebarOpen":false,"isRightSidebarOpen":false},"site":{}}}'</script><script type="application/ld+json" id="schema-org-graph" data-h-3437552="">{
  "@context": "https://schema.org",
  "@graph": [
    {
      "@id": "https://www.vlinux.cn/#identity",
      "@type": "Person",
      "name": "卷饼",
      "url": "https://www.vlinux.cn/",
      "image": {
        "@id": "https://www.vlinux.cn/#/schema/image/b8ad69b"
      },
      "sameAs": [
        "https://wpa.qq.com/msgrd?v=3&uin=38867033&site=qq&menu=yes&jumpflag=1",
        "https://github.com/vlinux",
        "https://repo.vlinux.cn/",
        "https://cos.vlinux.cn/www-vlinux-cn-blog-img/WechatIMG18.jpeg",
        "https://www.vlinux.cn/music/",
        "mailto:ilinux@88.com",
        "https://www.vlinux.cn/play"
      ]
    },
    {
      "@id": "https://www.vlinux.cn/#website",
      "@type": "WebSite",
      "dateModified": "2023-03-01T14:13:54+08:00",
      "datePublished": "2020-03-09T17:16:00+08:00",
      "inLanguage": "zh-CN",
      "name": "K8S(kubernetes)实践认知",
      "url": "https://www.vlinux.cn/",
      "publisher": {
        "@id": "https://www.vlinux.cn/#identity"
      }
    },
    {
      "@id": "https://www.vlinux.cn/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5/#webpage",
      "@type": "WebPage",
      "description": "那你终将成为别人的一条裤衩",
      "name": "K8S(kubernetes)实践认知",
      "url": "https://www.vlinux.cn/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5",
      "about": {
        "@id": "https://www.vlinux.cn/#identity"
      },
      "isPartOf": {
        "@id": "https://www.vlinux.cn/#website"
      },
      "potentialAction": [
        {
          "@type": "ReadAction",
          "target": [
            "https://www.vlinux.cn/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5"
          ]
        }
      ]
    },
    {
      "@id": "https://www.vlinux.cn/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5/#article",
      "description": "那你终将成为别人的一条裤衩",
      "headline": "K8S(kubernetes)实践认知",
      "inLanguage": "zh-CN",
      "thumbnailUrl": "https://www.vlinux.cn/favicon.svg",
      "@type": [
        "Article",
        "BlogPosting"
      ],
      "author": {
        "@id": "https://www.vlinux.cn/#/schema/person/e914eae"
      },
      "image": {
        "@id": "https://www.vlinux.cn/#/schema/image/a0d155d"
      },
      "isPartOf": {
        "@id": "https://www.vlinux.cn/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5/#webpage"
      },
      "mainEntityOfPage": {
        "@id": "https://www.vlinux.cn/posts/k8s(kubernetes)%E5%AE%9E%E8%B7%B5%E8%AE%A4%E7%9F%A5/#webpage"
      },
      "publisher": {
        "@id": "https://www.vlinux.cn/#identity"
      }
    },
    {
      "@id": "https://www.vlinux.cn/#/schema/person/e914eae",
      "@type": "Person",
      "name": "卷饼",
      "url": "https://valaxy.site"
    },
    {
      "@id": "https://www.vlinux.cn/#/schema/image/b8ad69b",
      "@type": "ImageObject",
      "contentUrl": "https://cos.vlinux.cn/vlinux-logo/user.jpg",
      "inLanguage": "zh-CN",
      "url": "https://cos.vlinux.cn/vlinux-logo/user.jpg"
    },
    {
      "@id": "https://www.vlinux.cn/#/schema/image/a0d155d",
      "@type": "ImageObject",
      "contentUrl": "https://www.vlinux.cn/favicon.svg",
      "inLanguage": "zh-CN",
      "url": "https://www.vlinux.cn/favicon.svg"
    }
  ]
}</script><link rel="stylesheet" href="/assets/ValaxyMain-3beb7542.css"><link rel="stylesheet" href="/assets/index-c2c57308.css"><link rel="stylesheet" href="/assets/post-b195884f.css"></body></html>